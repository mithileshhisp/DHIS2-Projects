
select table_name from information_schema.tables where table_name like 'analytics%' and table_type = 'BASE TABLE'

// get all orgUnit with all children
http://127.0.0.1:8090/dhis/api/organisationUnits/ANGhR1pa8I5.json?fields=id,displayName,code&includeDescendants=true&paging=false



security training HISP-INDIA 22/08/2019

Firefox Lightbeam by mozilla add plugin
https://10minutemail.com/10MinuteMail/index.html
https://haveibeenpwned.com/
https://cybersafegirl.com

privacy Badger -- plugin


Threat Modelling

What do you want to protect ?
From whom do you want to protect it ?
How likely is that you need to protect it ?
How bad are the consequences of failure ?
How much trouble are you willing to go through ?

Welcome to Zoom

e-mail - mithilesh.thakur@hispindia.org




Password Hygiene

Set Strong passwrds.
Do not share your passwords! Rule #1.
Set a password on your phone,laptop,computer
Use diffrent passwords
Change password often
Do not re-use passwords Use a password vault/manager,e.g.BitWarden LockWise

Verify Master Pasword



Passphrases

Easy to remember.
Hard for computers to guess.
eg. 2CatsRCrying
Use Diceware -- http://world.std.com/~reinhold/diceware.html

Two-Factor Authentication (2FA)

Prevent Malware Infection

Do not open unknow links.
Do not open unknow images or videos.
Do not download fiels from untrusted sources.
Don't use untrusted storage and devices (e.g Stuxnet ).


Update Everythings!.

Udate all software on all devices.
Check support duration for security updates before buying

Mind your permissions!

Do not use public WiFi.

torproject.org
tor -- browser is safe browser (tor network encrepted)

Mozilla Firefox

duckDuckGo! -- search engine
startpage

Encryption

Ciphers
Substitution Ciphers

https

FOSS --- 

Signal Private Messenger  WhatsApp use Signal Encraption ( End to End Encraption )

Facebook
WhatsApp
Instagram
telegram

haveibeenpwned.com

Warp Up!

Use common sense!
Do not share security credentials.
Invest for security.
Never stop learning!

security.sflc.in/dst40-ff

secutry.stackexchange.com

sflc.in








https://github.com/hispindia/dhis-tracker-capture-app/commits/ICMR_Leprosy_2.28

FRU -- GpEwBknDwF9

delivery-point -- FIaGENXR3c5
delivery point if Yes- fqM6fGLUqVD


nepali calendar change after 31/01/2019

// api/29/dataAnalysis/validationRules/report.xls
5590218502846345803063

083883

location of file

C:\Program Files\PostgreSQL\10\data\ postgresql.conf
in side 

#------------------------------------------------------------------------------
# LOCK MANAGEMENT
#------------------------------------------------------------------------------

#deadlock_timeout = 1s
max_locks_per_transaction = 100		# min 10
					# (change requires restart)
#max_pred_locks_per_transaction = 64	# min 10
					# (change requires restart)
#max_pred_locks_per_relation = -2	# negative values mean
					# (max_pred_locks_per_transaction
					#  / -max_pred_locks_per_relation) - 1
#max_pred_locks_per_page = 2            # min 0



select setting,pending_restart from pg_settings where name= 'max_locks_per_transaction'; // set 200

select * from pg_settings

update pg_settings set setting = 100 where name= 'max_locks_per_transaction';

// trim and split string QUERY in postgresSQL

SELECT optionsetid,uid,code,TRIM(split_part(code, '-', 1)) from optionset where code Ilike '%awc%';
SELECT split_part('ordno-#-orddt-#-ordamt', '-#-', 2);




-- Install PostGIS extension

create extension if not exists postgis;


analytics tables generation script manually
bat file window
#!/bin/sh
curl "http://202.166.205.218/suaahara2/api/resourceTables/analytics?skipResourceTables=true&lastYears=2" -X POST -u admin:district 
linex

analytics

#!/bin/sh 
/usr/bin/curl "http://103.31.80.242:8080/greenstar_crm/api/resourceTables/analytics?skipResourceTables=true&lastYears=2" -X POST -u admin:district >/dev/null 2>&1



pg_dump -U postgres -d msf_23_07_2018 -T analytics* > C:\Users\HISP\Desktop\msf_updated_db.sql


pg_dump -U postgres -d msf_23_07_2018 -T analytics* -T datavalue -T datavalueaudit > C:\Users\HISP\Desktop\msf_updated_db.sql

http://localhost:8080/dhis

password reset in MY_SQL

SET PASSWORD FOR 'root'@'localhost' = PASSWORD('MyNewPass');


dhis -- trunk

username -- hispdev
password -- $2a$10$FyFfOyfzQDKoJ6hs9Kr4WOfh7jp4H.LxMVQDcf1h4sJciYH1Y0meu

update users set password = '$2a$10$FyFfOyfzQDKoJ6hs9Kr4WOfh7jp4H.LxMVQDcf1h4sJciYH1Y0meu' where username = 'hispdev'; // Devhisp@1

update users set password = '$2a$10$ygJzpL.g054Z9RSPF1w6Y.SI3FhlqpPO4Hut690n6aHQG1BdvWKsa' where username = 'admin'; // district

set publicaccess = 'rw------' //for meta-data read write
set publicaccess = 'rwrw----' // for data and meta-data reade write

set publicaccess = 'r-rw----' //for meta-data read data read write
set publicaccess = 'r-r-----' // for data and meta-data read

rwrw----  // write access  204275
update dataelementcategoryoption set publicaccess = 'rwrw----'

public access no access update dataset set publicaccess = '--------';


// api filter of dataSets attribute value

http://localhost:8091/libia/api/29/dataSets.json?fields=name,id,attributeValues[attribute[id,name],value],&filter=attributeValues.attribute.id:eq:c50z8yjWVTD

// postgres SQL Query alter the database sequence id

SELECT c.relname FROM pg_class c WHERE c.relkind = 'S';

SELECT last_value FROM hibernate_sequence;

ALTER SEQUENCE hibernate_sequence RESTART WITH 4412;

// for insert ' replace ' to '' in name coloumn

="update organisationunit set shortname  = '"&F2&"' where uid = '"&D2&"';"

="update organisationunit set featuretype = '"&F2&"', coordinates  = '"&G2&"' where uid = '"&B2&"';"

="update organisationunit set name  = '"&B2&"' where organisationunitid = "&A2&";"

="update organisationunit set name  = '"&B2&"', shortname  = '"&B2&"' where organisationunitid = "&A2&";"

update program_attributes set mandatory = true;

select * FROM public.program_attributes where mandatory is false;


="update attributevalue set value  = '"&B2&"', lastupdated  = '2018-11-30' where attributevalueid = "&C2&" and attributeid = "&D2&";"

="update dataelement set code = '"&C1&"' where uid = '"&B1&"';"

="update dataelement set name  = '"&C2&"' where dataelementid = "&A2&" and uid = '"&B2&"';"

="update dataelement set name  = '"&D2&"', shortname  = '"&E2&"', formname  = '"&F2&"', code  = '"&C2&"' where dataelementid = "&A2&" and uid = '"&B2&"';"

="update dataelement set name  = '"&C2&"', valuetype = '"&D2&"' where dataelementid = "&A2&" and uid = '"&B2&"';"

="update optionset set code = '"&C2&"' where optionsetid = "&G2&";"


="update dataelementcategoryoption set code = '"&B2&"' where uid = '"&A2&"';"	

="update programstagedataelement set sort_order  = "&D2&" where programstagedataelementid = "&A2&" and dataelementid = "&C2&";"

="update programstageinstance set longitude  = "&D2&", latitude = "&E2&" where programstageinstanceid = "&A2&" and organisationunitid = "&C2&";"


insert into datavalue (dataelementid,periodid,sourceid,categoryoptioncomboid,attributeoptioncomboid,value,storedby,created,lastupdated,followup,deleted) values
="("&D2&","&G2&","&B2&","&E2&","&F2&",'"&C2&"','"&H2&"','2018-03-23','2018-03-23',false,false),"

update datavalue set created = now()::timestamp where created ='2019-02-13';
update datavalue set lastupdated = now()::timestamp where lastupdated ='2019-02-13';


insert into trackedentityattributevalue (trackedentityinstanceid,trackedentityattributeid,created,lastupdated,value) values
="("&A2&",93,'2018-04-27','2018-04-27','"&C2&"'),"

insert into datasetelement (datasetelementid, datasetid, dataelementid, categorycomboid ) values
="(nextval('hibernate_sequence'),"&A2&", "&B2&","&C2&"),"

insert into dataelement (dataelementid, uid, created, lastupdated, lastupdatedby, name, shortname, valuetype, domaintype, aggregationtype, categorycomboid, zeroissignificant, userid, publicaccess) values
="(nextval('hibernate_sequence'),'"&B2&"', '2018-12-19', '2018-12-19', 50, '"&C2&"','"&D2&"','INTEGER_ZERO_OR_POSITIVE','AGGREGATE','SUM',"&I2&",'TRUE',50,'rw------'),"

update dataelement  set created = now()::timestamp where created ='2018-12-19';
update dataelement  set lastupdated = now()::timestamp where lastupdated ='2018-12-19';


insert into indicator (indicatorid, created, lastupdated, lastupdatedby, name, shortname, annualized, indicatortypeid, numerator,numeratordescription, denominator, denominatordescription, userid, publicaccess) values
="(nextval('hibernate_sequence'), '2019-06-04', '2019-06-04', 50, '"&A2&"','"&B2&"',false,"&H2&",'"&D2&"','"&C2&"', '"&F2&"','"&E2&"', 50,'rw------'),"
	
update indicator  set created = now()::timestamp where created ='2019-03-19';
update indicator  set lastupdated = now()::timestamp where lastupdated ='2019-03-19';

insert into indicatorgroupmembers (indicatorid,indicatorgroupid) values
="("&A2&","&B2&"),"	


insert into programinstance (programinstanceid,  created, lastupdated, incidentdate, enrollmentdate, followup, status, trackedentityinstanceid, programid, organisationunitid, createdatclient, lastupdatedatclient, deleted, storedby) values
="(nextval('hibernate_sequence'),'2019-07-04','2019-07-04','2019-07-04','2019-07-04','false','ACTIVE',"&A2&","&C2&","&B2&", '2019-07-04','2019-07-04','false','maricel.mendina'),"



insert into attributevalue (attributevalueid,created, lastupdated, value, attributeid ) values
="(nextval('hibernate_sequence'),'2019-01-14','2019-01-14','"&B2&"',38115164),"

update attributevalue  set created = now()::timestamp where created ='2019-01-14';
update attributevalue set lastupdated = now()::timestamp where lastupdated ='2019-01-14';


insert into keyjsonvalue (keyjsonvalueid,created, lastupdated, namespace, namespacekey ) values
="(nextval('hibernate_sequence'),'2019-02-26','2019-02-26','"&A2&"','"&B2&"'),"

update keyjsonvalue set created = now()::timestamp where created ='2019-02-01';
update keyjsonvalue set lastupdated = now()::timestamp where lastupdated ='2019-02-01';


insert into organisationunitattributevalues ( organisationunitid, attributevalueid ) values
="("&C2&","&F2&"),"

insert into datasetusergroupaccesses (datasetid,usergroupaccessid) values
="("&A2&","&B2&"),"


insert into userrolemembers (userroleid,userid) values
="("&D2&","&A2&"),"

insert into userdatavieworgunits ( userinfoid, organisationunitid ) values
="("&A2&","&B2&"),"

insert into userteisearchorgunits ( userinfoid, organisationunitid ) values
="("&H2&","&F2&"),"

insert into usergroupmembers (userid,usergroupid) values
="("&A2&","&B2&"),"

insert into datasetusergroupaccesses ( datasetid, usergroupaccessid ) values
="("&B2&","&D2&"),"

insert into organisationunit (organisationunitid,name,shortname,parentid,openingdate,created,lastupdated,hierarchylevel) values
="(nextval('hibernate_sequence'),'"&C2&"','"&C2&"',"&B2&",'1990-01-01','2018-03-20','2018-03-20',3),"


insert into organisationunit (organisationunitid,uid,code,name,shortname,parentid,openingdate,created,lastupdated,hierarchylevel,featuretype) values
="(nextval('hibernate_sequence'),'"&E2&"','"&F2&"','"&G2&"','"&H2&"',"&D2&",'"&J2&"','2018-05-25','2018-05-25',"&I2&",'"&K2&"' ),"



insert into organisationunit (organisationunitid,uid,code,name,shortname,parentid,openingdate,created,lastupdated,hierarchylevel,featuretype, coordinates) values
="(nextval('hibernate_sequence'),'"&E2&"','"&F2&"','"&G2&"','"&H2&"',"&D2&",'"&J2&"','2018-05-29','2018-05-29',"&I2&",'"&K2&"', '"&M2&"'),"

="update organisationunit set featuretype  = '"&G2&"', coordinates  = '"&H2&"' where organisationunitid = "&C2&";"

update organisationunit set created = now()::timestamp where created ='2018-12-14';
update organisationunit set lastupdated = now()::timestamp where lastupdated ='2018-12-14';


update organisationunit set created = now()::timestamp where created ='2018-12-13';
update organisationunit set lastupdated = now()::timestamp where lastupdated ='2018-12-13';


update programindicator set lastupdated = now()::timestamp where lastupdated ='2018-12-06';

update datavalue set created = now()::timestamp where created is null;

="update trackedentityattributevalue set value  = '"&D2&"', lastupdated  = '2018-12-31' where trackedentityattributeid = "&B2&" and trackedentityinstanceid = "&A2&";"
update trackedentityattributevalue set lastupdated = now()::timestamp where lastupdated = '2018-12-31';


update trackedentityattributevalue set created = now()::timestamp where created = '2018-07-03';
update trackedentityattributevalue set lastupdated = now()::timestamp where lastupdated = '2018-07-03';

="update organisationunit set  name  = '"&C2&"', shortname  = '"&C2&"' where organisationunitid = "&B2&";"

insert into dataelement (dataelementid, created, lastupdated,name, shortname, formname, valuetype, domaintype, aggregationtype, categorycomboid, zeroissignificant, optionsetid, publicaccess) values
="(nextval('hibernate_sequence'),'2018-10-03','2018-10-03', '"&A2&"','"&C2&"','"&D2&"','"&F2&"','"&E2&"','"&G2&"',"&H2&",'false',"&L2&", 'rw------'),"

insert into optionset (optionsetid, uid, code, created, lastupdated, lastupdatedby name, valuetype, userid, publicaccess) values
="(nextval('hibernate_sequence'),'"&B2&"','"&C2&"','2019-06-12','2019-06-12',57,'"&A2&"','TEXT',57,'rw------'),"


insert into trackedentitydatavalue (programstageinstanceid, dataelementid, value, created, lastupdated,providedelsewhere, storedby ) values
="("&C2&","&E2&",'"&D2&"','2019-01-14','2019-01-14',false,'admin'),"

insert into objecttranslation (objecttranslationid, locale, property, value ) values
="(nextval('hibernate_sequence'),'es', 'NAME','"&E2&"' ),"

insert into dataelementtranslations (dataelementid, objecttranslationid ) values
="( "&A2&", "&B2&" ),"	



update trackedentitydatavalue set created = now()::timestamp where created ='2019-01-14';
update trackedentitydatavalue set lastupdated = now()::timestamp where lastupdated ='2019-01-14';

insert into optionset (optionsetid, uid, code, created, lastupdated, lastupdatedby, name, valuetype, userid, publicaccess) values
="(nextval('hibernate_sequence'),'"&B2&"','"&C2&"','2019-06-12','2019-06-12',57,'"&A2&"','TEXT',57,'rw------'),"

update optionset set created = now()::timestamp where created ='2019-06-12';
update optionset set lastupdated = now()::timestamp where lastupdated ='2019-06-12';

insert into optionvalue (optionvalueid, uid, code, name, created, lastupdated, sort_order, optionsetid ) values
="(nextval('hibernate_sequence'),'"&F2&"','"&G2&"','"&E2&"', '2019-06-12','2019-06-12',"&C2&","&B2&" ),"

update optionvalue set created = now()::timestamp where created ='2019-06-12';
update optionvalue set lastupdated = now()::timestamp where lastupdated ='2019-06-12';

insert into period ( periodid, periodtypeid, startdate, enddate ) values
="(nextval('hibernate_sequence'),"&C2&",'"&A2&"','"&B2&"'),"



insert into datavalue (dataelementid,periodid,sourceid,categoryoptioncomboid,attributeoptioncomboid,value,storedby,created,lastupdated,followup,deleted) values

="("&B3&","&C3&","&A3&","&D3&","&E3&",'"&F3&"','hispdev','2019-06-28','2019-06-28',false,false),"

update datavalue  set created = now()::timestamp where created ='2019-06-28';
update datavalue set lastupdated = now()::timestamp where lastupdated ='2019-06-28';

insert into datavalue (dataelementid,periodid,sourceid,categoryoptioncomboid,attributeoptioncomboid,value,storedby,created,lastupdated,deleted) values
="("&H2&","&K2&","&C2&","&I2&","&J2&",'"&G2&"','priyanka','2019-07-02','2019-07-02',false),"



update dataelement set  publicaccess = 'rw------'

="'"&C2&"'"&","

=A2&","

=TEXT(E2,"YYYY-MM-DD HH:MM:SS")

=TEXT(E2,"YYYY-MM-DD")

=LEFT(B2,FIND(",",B2)-1)

=RIGHT(B2,LEN(B2)-FIND(",",B2))

=RIGHT(B2,LEN(B2)-FIND("|",B2))

=CONCAT(D2,"-","health worker")


test string	=LEFT( B2, FIND( ",", B2 ) - 1 )	  - returns the result   "test"


test string	=RIGHT( B2, LEN( B2 ) - FIND( ",", B2 ) )	  - returns the result   "string"


=RIGHT(A1, LEN(A1)-14)


MY-SQL District1 -- 59ef69feca1a172a17384b14a7a8529a


$S2i0;h1d6

Liq. Lugol's

$2a$10$ygJzpL.g054Z9RSPF1w6Y.SI3FhlqpPO4Hut690n6aHQG1BdvWKsa

$2a$10$ygJzpL.g054Z9RSPF1w6Y.SI3FhlqpPO4Hut690n6aHQG1BdvWKsa



Password : <s3cur1ty>
haryana production 2.17

http://117.239.178.184/hry_pro
adminAES
Haryana@12345


Kerla Production Linkippf

http://103.251.43.80/dhis (Production Link)

admin
Neymar10


Orissa Production
http://dhis.nrhmodisha.in/
admin
0KaGSH0x

Maharshtra Production
https://dhis.maharashtra.gov.in/mh/dhis-web-commons/security/login.action;jsessionid=4CA92FDF73F06F9FD5453CA0E76D8D62
admin
M@ha$dhi$2


https://docs.jboss.org/hibernate/orm/3.3/reference/en/html/persistent-classes.html
http://javapapers.com/core-java/hashcode-and-equals-methods-override/

Before commit first :

bzr up

then:

Bazar Status:
bzr st

Bazar Resolve:
bzr resolve filename
// for take other
bzr resolve --take-other file-name

eg:
bzr resolve --take-other dhis-2/dhis-web/dhis-web-apps/src/main/webapp/dhis-web-tracker-capture/styles/style.css

Bazar Revert:
bzr revert dhis-2/dhis-i18n

Bazar Delete:
bzr remove in --force (here in is the folder which i want to remove)

bzr remove  --force file name


if you make new file then before commit first add this file using command

bzr add file name(after go to root that directoy or folder)

Bazar Commit:

bzr whoami "Your Name <email@example.com>"
bzr commit -m "Comment to Display"

To Commit specified files:
Goto Root folder and give command
bzr commit modulename/ -m "Comment to Display"


// for find diffrence and downlaod in file before commit

$ bzr diff > myDiff.txt


If conflicts occurs after "bzr conflicts" command runs then either resolve or revert  

Bazar Resolve:
bzr resolve filename (Goto that path)
  OR

bzr resolve conflict filename/path on which conflicts ocurs

Bazar Login:
bzr lp-login chbharathk

Bazar Add:
bzr add in (here we can add in folder)

bzrwhoami "Mithilesh Kumar Thakur <mithilesh.hisp@gmail.com>"

Steps to work with Bazar

 - First Register in launchpad.
 - Download Bazar and install.
 - Then download cygwin (be sure to select the package OPENSSH)
 - type this command in cygwin window : ssh-keygen -t rsa
 - it will create publickey files in cygwin\home\.ssh 
 - login to launchpad and import this public key there.
 - after that login in cygwin with the command: bzr lp-login mithilesh-hisp
 - then goto the directory where u want to checkout and type the following command: 

	trunk : bzr checkout lp:dhis2

	india:  bzr checkout lp:~dhis2-devs-india/dhis2/dhis2-in
	
	Any Revision : bzr checkout lp:~dhis2-devs-core/dhis2/2.1


	//command for check out the code for dhis2/2.1

	bzr checkout lp:~dhis2-devs-core/dhis2/2.21

	//command for break lock:
	
	$ bzr break-lock


// command for increase the form size for download xls

mvn clean -Dorg.mortbay.jetty.Request.maxFormContentSize=-1 jetty:run-war
mvn clean -Dmaven.test.skip=true -Dorg.mortbay.jetty.Request.maxFormContentSize=-1 jetty:run-war

// set in tomcat also inside port no
<Connector port="8090" protocol="HTTP/1.1"
               connectionTimeout="20000"
               redirectPort="8443" maxPostSize="0"/>


// set in tomcat also inside port no for tomcat 7
<Connector port="8090" protocol="HTTP/1.1"
               connectionTimeout="20000"
               redirectPort="8443" maxPostSize="-1"/>

maxPostSize="0"/>

Launchpad userID : mithilesh.hisp@gmail.com



ONLINE-FEED-SIMULATOR

bzr checkout lp:~sagarb-4488/ofsindia/OFSFrame




bzr checkout lp:~dhis2-devs-core/dhis2/2.24
bzr checkout lp:~dhis2-devs-core/dhis2/2.23
bzr checkout lp:~dhis2-devs-core/dhis2/2.22

// 





// for IPPF 2.23

bzr branch lp:~dhis2-devs-core/dhis2/2.23 lp:~dhis2-devs-core/dhis2/ippf2.23
bzr checkout lp:~dhis2-devs-core/dhis2/ippf2.23
bzr merge lp:~dhis2-devs-core/dhis2/2.23


// for minagri Rowanda
bzr checkout lp:~dhis2-devs-core/dhis2/minagri


// create Branch for PLAN 2.23 and 2.24

bzr checkout lp:~dhis2-devs-core/dhis2/plan2.24


bzr branch lp:~dhis2-devs-core/dhis2/2.23 lp:~dhis2-devs-core/dhis2/plan2.23
bzr checkout lp:~dhis2-devs-core/dhis2/plan2.23
bzr merge lp:~dhis2-devs-core/dhis2/2.23





// create Branch for PLAN

bzr branch lp:~dhis2-devs-core/dhis2/trunk lp:~dhis2-devs-core/dhis2/plan
bzr checkout lp:~dhis2-devs-core/dhis2/plan
bzr merge lp:~dhis2-devs-core/dhis2/trunk
bzr merge lp:~dhis2-devs-core/dhis2/2.23


bzr merge lp:~dhis2-devs-core/dhis2/2.22
bzr revert -r 21558


// DHIS 2.23 for State

bzr branch lp:~dhis2-devs-core/dhis2/2.23 lp:~dhis2-devs-core/dhis2/dhis2.23_in
bzr checkout lp:~dhis2-devs-core/dhis2/dhis2.23_in
bzr merge lp:~dhis2-devs-core/dhis2/2.23








// DHIS 2.20 for State

bzr branch lp:~dhis2-devs-core/dhis2/2.20 lp:~dhis2-devs-core/dhis2/dhis2.20_in
bzr checkout lp:~dhis2-devs-core/dhis2/dhis2.20_in
bzr merge lp:~dhis2-devs-core/dhis2/2.20

 // for SPIS

 bzr branch lp:~dhis2-devs-core/dhis2/trunk lp:~dhis2-devs-core/dhis2/ccei_tracker

 bzr checkout lp:~dhis2-devs-core/dhis2/ccei_tracker

 http://bazaar.launchpad.net/~dhis2-devs-core/dhis2/ccei_tracker/changes


// for maleria ccmp2.17

bzr checkout lp:~dhis2-devs-core/dhis2/ccmp2.17

// for remove branch // to remove ccmp_2.17

bzr remove-branch lp:~dhis2-devs-core/dhis2/ccmp_2.17


bzr checkout lp:~dhis2-devs-core/dhis2/greenstar


// Creating New Branch  command from trunk

// for Emro right to left
 bzr branch lp:~dhis2-devs-core/dhis2/trunk lp:~dhis2-devs-core/dhis2/asha

 bzr checkout lp:~dhis2-devs-core/dhis2/asha	
 
 bzr checkout lp:~dhis2-devs-core/dhis2/spis_v2
 // for SPIS
 bzr branch lp:~dhis2-devs-core/dhis2/trunk lp:~dhis2-devs-core/dhis2/spis

 bzr checkout lp:~dhis2-devs-core/dhis2/spis

http://bazaar.launchpad.net/~dhis2-devs-core/dhis2/spis/changes


// for Emro right to left
 bzr branch lp:~dhis2-devs-core/dhis2/trunk lp:~dhis2-devs-core/dhis2/trunk_rtol

 bzr checkout lp:~dhis2-devs-core/dhis2/trunk_rtol	


// for Emro indicator report
 bzr branch lp:~dhis2-devs-core/dhis2/2.18 lp:~dhis2-devs-core/dhis2/emro_ir

 bzr checkout lp:~dhis2-devs-core/dhis2/emro_ir



 bzr branch lp:~dhis2-devs-core/dhis2/trunk lp:~dhis2-devs-core/dhis2/dqa

// Creating New Branch  command from 2.9

bzr branch lp:~dhis2-devs-core/dhis2/2.9 lp:~dhis2-devs-core/dhis2/cac


// for state

bzr branch lp:~dhis2-devs-core/dhis2/2.12 lp:~dhis2-devs-core/dhis2/dhis2.12_in
bzr checkout lp:~dhis2-devs-core/dhis2/dhis2.12_in


bzr branch lp:~dhis2-devs-core/dhis2/2.13 lp:~dhis2-devs-core/dhis2/dhis2.13_in
bzr checkout lp:~dhis2-devs-core/dhis2/dhis2.13_in


bzr branch lp:~dhis2-devs-core/dhis2/2.17 lp:~dhis2-devs-core/dhis2/dhis2.17_in
bzr checkout lp:~dhis2-devs-core/dhis2/dhis2.17_in
bzr merge lp:~dhis2-devs-core/dhis2/2.17


// create branch for CCEI 2.18 //10/04/2015

bzr branch lp:~dhis2-devs-core/dhis2/2.18 lp:~dhis2-devs-core/dhis2/dhis2-ccei-2.18
bzr checkout lp:~dhis2-devs-core/dhis2/dhis2-ccei-2.18


bzr branch lp:~dhis2-devs-core/dhis2/2.14 lp:~dhis2-devs-core/dhis2/dhis2-ccei-2.14
bzr checkout lp:~dhis2-devs-core/dhis2/dhis2-ccei-2.14




bzr branch lp:~dhis2-devs-core/dhis2/2.14 lp:dhis2-ccei/ccei

$ bzr push lp:~sample-developers/sample/trunk
  bzr push lp:~dhis2-devs-core/dhis2/2.14

bzr push lp:dhis2-ccei

// to push the code in launchpad
bzr push lp:~mithilesh-hisp/dhis2-ccei/ccei
bzr push lp:~dhis2-ccei-dev/dhis2-ccei/ccei

bzr checkout lp:~dhis2-ccei-dev/dhis2-ccei/ccei
bzr checkout lp:dhis2-ccei  

// for FAO

bzr branch lp:~dhis2-devs-core/dhis2/2.12 lp:~dhis2-devs-core/dhis2/fsnis_2.12
bzr checkout lp:~dhis2-devs-core/dhis2/fsnis_2.12



bzr checkout lp:~dhis2-devs-core/dhis2/dhis2.13_in

// now checkout created new branch

 bzr checkout lp:~dhis2-devs-core/dhis2/dqa
 
 bzr checkout lp:~dhis2-devs-core/dhis2/DHIS_IHRIS_SYNC_2.12
 

// for 2.16 south africa

bzr branch lp:~dhis2-devs-core/dhis2/2.16 lp:~dhis2-devs-core/dhis2/syncmanager_2.16
bzr checkout lp:~dhis2-devs-core/dhis2/syncmanager_2.16

// for 2.18 south africa merge the commit to this branch
bzr branch lp:~dhis2-devs-core/dhis2/2.18 lp:~dhis2-devs-core/dhis2/synchmanager_2.18
bzr checkout lp:~dhis2-devs-core/dhis2/synchmanager_2.18


// for 2.19 south africa merge the commit to this branch
bzr branch lp:~dhis2-devs-core/dhis2/2.19 lp:~dhis2-devs-core/dhis2/synchmanager_2.19
bzr checkout lp:~dhis2-devs-core/dhis2/synchmanager_2.19


// for 2.20 south africa merge the commit to this branch 01/09/2015
bzr branch lp:~dhis2-devs-core/dhis2/2.20 lp:~dhis2-devs-core/dhis2/synchmanager_2.20
bzr checkout lp:~dhis2-devs-core/dhis2/synchmanager_2.20



bzr merge lp:~dhis2-devs-core/dhis2/2.18
bzr commit  -m "Merge with parent Branch 2.18"


// for 2.21 ivb // 23/11/2015




psql -U postgres ivb_07_06_2017 < C:\Users\HISP\Desktop\ivb_pg_07062017.sql

psql -U postgres ivb_06_06_2017 < C:\Users\HISP\Desktop\ivb_pg_28042017.sql

psql -U postgres ivb_28_03_2017 < C:\Users\HISP\Desktop\ivb_pos_280317.sql
$ bzr branch lp:~dhis2-devs-core/dhis2/2.21 lp:~dhis2-devs-core/dhis2/ivb2.21

bzr checkout lp:~dhis2-devs-core/dhis2/ivb2.21


// for 2.16 ivb
$ bzr branch lp:~dhis2-devs-core/dhis2/2.16 lp:~dhis2-devs-core/dhis2/ivb2.16

bzr checkout lp:~dhis2-devs-core/dhis2/ivb2.16


// for 2.17 trukey

bzr branch lp:~dhis2-devs-core/dhis2/2.17 lp:~dhis2-devs-core/dhis2/imc2.17
bzr checkout lp:~dhis2-devs-core/dhis2/imc2.17

// for merging from parent branch trunk to local branch 
bzr merge lp:~dhis2-devs-core/dhis2/trunk


// for merging from parent branch to local branch

bzr merge lp:~dhis2-devs-core/dhis2/2.16
bzr merge lp:~dhis2-devs-core/dhis2/2.18




// for making diff file

bzr diff > file name
bzr diff > diff.txt



//29/06/2011
// build with india pom file

$ mvn clean -f india-pom.xml -Dmaven.test.skip=true install


//command for building project

mvn clean -Dmaven.test.skip=true install

or

mvn clean install -Dskip.test=true

//for eclipse

mvn clean eclipse:eclipse

//for run war file

mvn clean jetty:run-war

	
commit Link-- check for india

http://bazaar.launchpad.net/%7Edhis2-devs-india/dhis2/dhis2-in/changes/1096?start_revid=1096
or
http://bazaar.launchpad.net/~dhis2-devs-india/dhis2/dhis2-in/changes/


commit Link-- check for Global
https://code.launchpad.net/~dhis2-devs-core/dhis2/trunk/
or
http://bazaar.launchpad.net/~dhis2-devs-core/dhis2/trunk/changes


for ccei 

http://bazaar.launchpad.net/~dhis2-ccei-dev/dhis2-ccei/trunk/changes

for viewing the code which ever is  changes after commited
http://bazaar.launchpad.net/~dhis2-devs-core/dhis2/trunk/revision/1992


mysql command

// for taking backup
c:\mysqldump databasename(name of data base which backup is to be done) -u username -p > c:/nameofsqlfile(.sql file in which backup to be store and from this file you can import data base)

c:\mysqldump dhis_demo -u root -p > c:/dhis_demo_backup.sql


mysqldump asha_hry_15_05_2014 -u root -p >C:/asha_hry17052014.sql
Ex:-C:\mysqldump bihar_new -u root -p >C:/bhiar06092010.sql

C:\Users\HISP>mysqldump -u root -p bihar_metadata_09_07_2013 > bihar_database.sql

mysqldump -u root -p ivb_2.21_14_02_2017 > ivb.sql


// for importing

First create the Database in MySql say name "bihar06092010" on which you can import database from .sql dump file

C:\mysql -u root -p -h localhost databasename(your newely created data base name) < completepath(where your sql dump file is located--your .sql file from which you import database)


Example:
C:\mysql -u root -p -h localhost bihar06092010(your newely created data base name) < C:/bihar06092010.sql(your .sql file from which you import database)
      



// for Building War file including India Module

	copy it and paste in "pom.xml" of dhis-web-portal and also comment thes module which are repeted in this pom.xml.

    <!-- India modules -->
    
    
    <dependency>
      <groupId>org.hisp.dhis</groupId>
      <artifactId>dhis-web-dashboard</artifactId>
      <version>${version}</version>
      <type>war</type>
    </dependency>
    <dependency>
      <groupId>org.hisp.dhis</groupId>
      <artifactId>dhis-web-reports-national</artifactId>
      <version>${version}</version>
      <type>war</type>
    </dependency>


	<dependency>
      <groupId>org.hisp.dhis</groupId>
      <artifactId>dhis-web-dataentry-national</artifactId>
      <version>${version}</version>
      <type>war</type>
    </dependency> 
	
    <dependency>
      <groupId>org.hisp.dhis</groupId>
      <artifactId>dhis-web-excelimport</artifactId>
      <version>${version}</version>
      <type>war</type>
    </dependency>

    <dependency>
      <groupId>org.hisp.dhis</groupId>
      <artifactId>dhis-web-maintenance-in</artifactId>
      <version>${version}</version>
      <type>war</type>
    </dependency>

// after paste first go to dhis2/local/in/dhis-in-api
	and executr the command.

 $ mvn clean -Dmaven.test.skip=true install
	then bulid local/in/dhis-in-services and local/in

the finally build dhis2\dhis-2\dhis-web\dhis-web-portal.

the war file created in target folde of dhis2\dhis-2\dhis-web\dhis-web-portal



About DHIS 2

Current user:
    admin
Version:
    2.0.6-SNAPSHOT
Build revision:
    1977 
Build date:
    2010-10-30 16:21
User agent:
    Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.2.12) Gecko/20101026 Firefox/3.6.12
External configuration directory:
    C:\Documents and Settings\hisp\dhis
Environment variable:
    DHIS2_HOME
Database type:
    MySQL
Database name:
    bihar
Database user:
    root
Java Opts:
    -Xmx512m -Xms512m -XX:PermSize=256m -XX:MaxPermSize=256m -XX:NewSize=128m
Java version:
    1.6.0_21
Java vendor:
    Sun Microsystems Inc.
OS name:
    Windows XP
OS architecture:
    x86
OS version:
    5.1

24/03/2011

command for check out the code for dhis2/2.1

bzr checkout lp:~dhis2-devs-core/dhis2/2.1

command for break lock:

$ bzr break-lock
$ bzr break-lock --f

//29/06/2011
// build with india pom file

$ mvn clean -f india-pom.xml -Dmaven.test.skip=true install


// for create patch 

$ bzr diff > dataEntry.patch (dataEntry.patch is file name)


Bazar Resolve:
bzr resolve filename (Goto that path)
 OR

bzr resolve conflict filename/path on which conflicts ocurs

// OR do like this

bzr diff >  ./update.patch(file name with location)
(all changes in update.patch file )

then
bzr revert

then patch -p0 <  ./update.patch(file name with location)

System variable

Variable name : JAVA_HOME
variable path : C:\Program Files\Java\jdk1.6.0_17

Variable name : DHIS2_HOME
variable path : C:\Documents and Settings\hisp\dhis

Variable name : JAVA_OPTS
variable path : -Xmx512m -Xms512m -XX:PermSize=256m -XX:MaxPermSize=256m -XX:NewSize=128m

Variable name : MAVEN_HOME
variable path : C:\maven

Variable name : MAVEN_OPTS
variable path : -Xms256m -Xmx512m -XX:MaxPermSize=512m

Variable name : Path
variable path : %SystemRoot%\system32;%SystemRoot%;%SystemRoot%\System32\Wbem;C:\Program Files\Java\jdk1.6.0_17\bin;C:\Program Files\apache-maven-3.0.3\bin;C:\Program Files\MySQL\MySQL Server 5.0\bin;C:\Program Files\Bazaar


TOMCAT:

-Xmx512m
-Xms512m
-XX:PermSize=256m
-XX:MaxPermSize=256m
-XX:NewSize=128m



for MYSQL Backup in DHIS for Unix Server

MySQL Path : /usr/bin/
Backup Data Path : /tmp
Report Folder : ra_national

for MYSQL Backup in DHIS for Window Server

MySQL Path : C:/DHIS2/mysql/bin/
Backup Data Path : C:/dhisdata/
Report Folder : ra_national


Postgres data base import command


C:\Program Files\PostgreSQL\9.2\bin>psql -U postgres -d ovc_13_05_2013 -f "c:\Documents and Settings\Mithilesh\Desktop\OVC\warFile_13_05_2013\ovc_13-05-2013.backup"

// postgres SQL Query alter the database sequence id

SELECT c.relname FROM pg_class c WHERE c.relkind = 'S';

SELECT last_value FROM hibernate_sequence;

ALTER SEQUENCE hibernate_sequence RESTART WITH 4412;


// Path of Env Variable 10/09/2013  system variable

variable name : Variable value
DHIS2_HOME  :  C:\DHIS2_HOME

JAVA_HOME  : C:\Program Files\Java\jdk1.7.0_05

JAVA_OPTS :  -Xmx1024m -Xms1024m -XX:PermSize=256m -XX:MaxPermSize=256m -XX:NewSize=128m

MAVEN_OPTS : -Xmx512m

MAVEN_HOME : C:\Program Files\maven

take postGres backup for 1 table

pg_dump -U dbuser -d dbname -t tablename > outputfilename.sql

pg_dump -U postgres -d mp_23_02_2016 -t sqlview > C:\Users\HISP\Desktop\sqlview_14_04_2016.sql

pg_dump -U postgres -d nepal_hmis_12_04_2019 -t report > C:\Users\Mithilesh Thakur\Desktop\report.sql

pg_dump -U postgres -d sa_data_sync_10_03_2016 > C:\Users\HISP\Desktop\latest_db_11_03_2016.sql


pg_dump -U postgres -d hpa_08_03_2016 > C:\Users\HISP\Desktop\hpa_updated_09_03_2016.sql

// postgres SQL query for import one table in database

psql  -U postgres -d hp_07_04_2016_2.20 -t sqlview < C:\Users\HISP\Desktop\sqlview_14_04_2016.sql

psql  -U postgres -d mp_13_11_2015_v20 -t sqlview < C:\Users\HISP\Desktop\sqlview.sql


IMIS

psql -U postgres imis_20_06_2019 <


Tanzania

tanzania_31_07_2019
psql -U postgres tanzania_31_07_2019 <


PUNJAB_hmis

psql -U postgres tb_demo_22_05_2019 <

tb_demo_22_05_2019



psql -U postgres training_land_22_07_2019 <


psql -U postgres punjab_hmis_22_07_2019 <


INTPART 


psql -U postgres intpart_230_balari_04_09_2019 <

pg_dump -U postgres -d intpart_230_balari_04_09_2019 > "C:\Users\Mithilesh Thakur\Desktop\intpart_khera_232.sql"



psql -U postgres quic_siera_leone_12_06_2015 < C:\Users\HISP\Desktop\quic_siera_leone_12_06_2015.sql


ICMR

psql -U postgres icmr_gbd_10_06_2019 < 

test_db_orgUnit


nepal_hmis_28_03_2019


psql -U postgres nepal_hmis_22_04_2019 < 

pg_dump -U postgres -d nepal_hmis_22_04_2019 > C:\Users\Mithilesh Thakur\Desktop\nepal_hmis_2.30_23_04_2019.sql

pg_dump -U postgres -d nepal_hmis_12_04_2019 -t report > C:\Users\Mithilesh Thakur\Desktop\report.sql

pg_dump -U postgres -d nepal_hmis_12_04_2019 -t report > "C:\Users\Mithilesh Thakur\Desktop\report.sql" 

pg_dump -U postgres -d nepal_hmis_12_04_2019 > "C:\Users\Mithilesh Thakur\Desktop\nepal_hmis_12_04_2019.sql"

psql -U postgres hearing_20_07_2018 < "C:\Users\Mithilesh Thakur\Desktop\dhis_libya_Jun-04-18.sql"


LIBIA

libya_06_03_2019

libya_230_23_07_2019

pg_dump -U postgres -d libya_14_09_2018 > "C:\Users\Mithilesh Thakur\Desktop\libya_db_2.30_after_delete.sql"


psql -U postgres libya_230_23_07_2019 < "C:\Users\Mithilesh Thakur\Desktop\dhis_libya_Jun-04-18.sql"

psql -U postgres libia_28_05_2018 < "C:\Users\Mithilesh Thakur\Desktop\dhis_libya_May-28-18.sql"




psql -U postgres libia_2.29_30_04_2018 < C:\Users\HISP\Desktop\dhis_libya_Apr-30-18.sql


etbreg_24_05_2019

etbreg_01_08_2019

pg_dump -U postgres -d etbreg_01_08_2019 > "C:\Users\Mithilesh Thakur\Desktop\etbreg_232.sql"

psql -U postgres etbreg_01_08_2019 < "C:\Users\Mithilesh Thakur\Desktop\etbreg_22_May_2019.sql"



indonesia_leprosy_28_08_2019

indonesia_leprosy_06_09_2019

pg_dump -U postgres -d indonesia_leprosy_28_08_2019 > "C:\Users\Mithilesh Thakur\Desktop\indonesia_leprosy_232.sql"


psql -U postgres indonesia_leprosy_06_09_2019 < "C:\Users\Mithilesh Thakur\Desktop\indonesia_leprosy_10_08_2019.sql"

leprosy

who_leprosy_10_04_2109

who_lep_24_05_2019

who_lep_09_07_2019

psql -U postgres who_lep_09_07_2019 < "C:\Users\Mithilesh Thakur\Desktop\who_leprosy_08_04_2019.sql"


pg_dump -U postgres -d who_leprosy_03_04_2109 > "C:\Users\Mithilesh Thakur\Desktop\who_leprosy_04_04_2019.sql"


C:\Users\Mithilesh Thakur\Downloads>pg_restore -U postgres -d who_leprosy_03_04_2109 DHIS_LEP_03Apr2019.backup

psql -U postgres who_leprosy_27_03_2109 < 

who_leprosy_08_08_2107

leprosy_12_06_2018

leprosy_24_07_2018

who_leprosy_22_10_2018


icmr_leprosy_29_03_2019


icmr_leprosy_28_08_2019

psql -U postgres icmr_leprosy_28_08_2019 <

pg_dump -U postgres -d icmr_leprosy_27_08_2019 > "C:\Users\Mithilesh Thakur\Desktop\icmr_leprosy_232.sql"


icmr_amr_26_08_2019

psql -U postgres icmr_amr_26_08_2019 <

pg_dump -U postgres -d icmr_amr_14_01_2019 > "C:\Users\Mithilesh Thakur\Desktop\icmr_amr.sql"

psql -U postgres icmr_amr_2.29_18_12_2018 <

psql -U postgres icmr_amr_2.30_13_12_2018 < "C:\Users\Mithilesh Thakur\Desktop\leprosy_db_May-09-18.sql"

psql -U postgres icmr_leprosy_06_12_2018 < "C:\Users\Mithilesh Thakur\Desktop\leprosy_db_May-09-18.sql"

psql -U postgres who_leprosy_22_10_2018 < "C:\Users\Mithilesh Thakur\Desktop\leprosy_db_May-09-18.sql"


psql -U postgres who_leprosy_23_03_2108 < C:\Users\HISP\Desktop\leprosy_2018-03-08.sql


pg_dump -U postgres -d who_leprosy_20_03_2108 > C:\Users\HISP\Desktop\leprosy_updated.sql

psql -U postgres who_leprosy_20_03_2108 < C:\Users\HISP\Desktop\leprosy_db_Mar-20-18_destination.sql

psql -U postgres who_leprosy_08_08_2107 < C:\Users\HISP\Desktop\leprosy_2017-08-07.sql


psql -U postgres bhutan_maleria <


psql -U postgres bhutan_hmis_2.29_16_04_2019 <

pg_dump -U postgres -d bhutan_hmis_2.29_13_02_2019 > "C:\Users\Mithilesh Thakur\Desktop\bhutan_hmis_2.29_15_02_2019.sql"



psql -U postgres bhutan_hmis_2.26_20_02_2019 <



pg_dump -U postgres -d bhutan_hmis_2.26_20_02_2019 > "C:\Users\Mithilesh Thakur\Desktop\bhutan_hmis_2.29.sql"

psql -U postgres bhutan_maleria_28_09_2018 < C:\Users\HISP\Desktop\drukhmis_hmisdb_20180320_1900.sql

psql -U postgres bhutan_hmis_24_07_2018 < C:\Users\HISP\Desktop\drukhmis_hmisdb_20180320_1900.sql

psql -U postgres bhutan_server_27_09_2017 < C:\Users\HISP\Desktop\drukhmis_hmisdb_20170918_1900_1.sql



HIV-TRACKER


hiv_tracker_17_08_2019
psql -U postgres hiv_tracker_17_08_2019 < "C:\Users\Mithilesh Thakur\Desktop\hivtracker_18052018-21052018_1.sql"


pg_dump -U postgres -d hiv_tracker_17_08_2019 > "C:\Users\Mithilesh Thakur\Desktop\hivtracker_232.sql"

hiv_tracker_28_01_2019

psql -U postgres hiv_tracker_28_01_2019 < "C:\Users\Mithilesh Thakur\Desktop\hivtracker_18052018-21052018_1.sql"

psql -U postgres hiv_tracker_15_10_2018 < "C:\Users\Mithilesh Thakur\Desktop\hivtracker_18052018-21052018_1.sql"

psql -U postgres hiv_tracker_12_09_2018 < "C:\Users\Mithilesh Thakur\Desktop\hivtracker_18052018-21052018_1.sql"

psql -U postgres hiv_tracker_23_05_2018 < "C:\Users\Mithilesh Thakur\Desktop\hivtracker_18052018_May-23-18_1.sql"


psql -U postgres hiv_tracker_2.27_10_04_2018 < C:\Users\HISP\Desktop\hiv-virtual-machine_hivtracker_jan_19_2018_20180218_2000.sql

psql -U postgres hiv_tracker_2.27_19_02_2018 < C:\Users\HISP\Desktop\hiv-virtual-machine_hivtracker.sql

psql -U postgres hiv_tracker_2.27_06_11_2017 < C:\Users\HISP\Desktop\hivtracker_22102017_Nov-03-17.sql

psql -U postgres hiv_tracker_2.27_03_11_2017 < C:\Users\HISP\Desktop\hivtracker_22102017_Nov-03-17.sql

psql -U postgres hiv_tracker_2.27_11_10_2017 < C:\Users\HISP\Desktop\hivtracker_09102017_1.sql


Bhutan

pg_dump -U postgres -d hiv_tracker_22_08_2017 > C:\Users\HISP\Desktop\hiv_tracker.sql

pg_dump -U postgres -d bhutan_pro_24_08_2017 > C:\Users\HISP\Desktop\bhutan_updated.sql

psql -U postgres bhutan_pro_29_08_2017 < C:\Users\HISP\Desktop\bhutan_26082017-29082017_1.sql


psql -U postgres bhutan_local_24_08_2017 < C:\Users\HISP\Desktop\bhutan_integrated_24082017_1.sql

psql -U postgres bhutan_pro_24_08_2017 < C:\Users\HISP\Desktop\bhutan_final_24082017.sql


psql -U postgres bhutan_local_11_07_2017 < C:\Users\HISP\Desktop\bhutan_training_Jul-10-17_1.sql

psql -U postgres bhutan_pro_10_07_2017 < C:\Users\HISP\Desktop\dhis.sql

psql  -U postgres -d hp_07_04_2016_2.20 -t sqlview < C:\Users\HISP\Desktop\sqlview_14_04_2016.sql

psql  -U postgres -d mp_13_11_2015_v20 -t sqlview < C:\Users\HISP\Desktop\sqlview.sql

scale
psql -U postgres scale_04_01_2015 < C:\Users\HISP\Desktop\dhis_scale_04-Jan-2016.sql
scale_04_01_2015


PSI
psql -U postgres 3si_psi_28_12_2016 < C:\Users\HISP\Desktop\3si.psi-mis.org_db.sql
pg_dump -U postgres -d 3si_psi_28_12_2016 > C:\Users\HISP\Desktop\3si.psi-mis_updated_29_12_2016.sql

psql -U postgres psi_test < C:\Users\HISP\Desktop\psi.sql

HKI

psql -U postgres hki_06_06_2017 < C:\Users\HISP\Desktop\suaahara2_05062017.sql

psql -U postgres suaahara_26_04_2017 < C:\Users\HISP\Desktop\suaahara2_2017-04-25.sql

psql -U postgres hki_06_02_2017 < C:\Users\HISP\Desktop\suaahara.sql
pg_dump -U postgres -d hki_06_02_2017 > C:\Users\HISP\Desktop\suaahara_updated.sql


NIE

psql -U postgres nie_odk_15_05_2018 < "C:\Users\Mithilesh Thakur\Desktop\DHIS-NIEODK_nieodk_db_20180514_1700_1.sql"


pg_dump -U postgres -d nie_23_01_2017 > C:\Users\HISP\Desktop\nie_updated_25_01_2017.sql

pg_dump -U postgres -d nie_04_01_2017 > C:\Users\HISP\Desktop\nie_updated_04_01_2017.sql


psql -U postgres nie_08_03_2017 < C:\Users\HISP\Desktop\nie.sql

psql -U postgres nie_09_01_2017 < C:\Users\HISP\Desktop\nie.sql

psql -U postgres nie_09_01_2017 < C:\Users\HISP\Desktop\nie.sql

psql -U postgres nie_04_01_2017 < C:\Users\HISP\Desktop\nie_dev.sql

pg_dump -U postgres -d nie_27_10_2016 > C:\Users\HISP\Desktop\nie_updated_28_10_2016.sql

psql -U postgres nie_04_01_2017 < C:\Users\HISP\Desktop\nie_dev_Oct-26-16.sql


TIBET


tibet_pro_14_02_2019

psql -U postgres tibet_pro_14_02_2019 < C:\Users\HISP\Desktop\tibet_pro_Apr-12-18_1.sql


psql -U postgres tibet_pro_09_01_2018 < C:\Users\HISP\Desktop\tibet_pro_Jan-09-18.sql

pg_dump -U postgres -d tibet_pro_09_01_2018 > C:\Users\HISP\Desktop\tibet_pro_updated.sql

psql -U postgres tibet_pro_09_01_2018 < C:\Users\HISP\Desktop\tibet_pro_Jan-09-18.sql

psql -U postgres tibet_pro_02_01_2018 < C:\Users\HISP\Desktop\tibet_pro_Jan-02-18.sql

psql -U postgres tibet_28_09_2017 < C:\Users\HISP\Desktop\tibet_pro_28-Sep-17.sql






AKROSH

ORISSA_Japiogo

psql -U postgres orissa_10_12_2018 < 



psql -U postgres japigo_05_03_2018 < C:\Users\HISP\Desktop\mwmis_odhisa_24112017_Mar-05-18_1.sql

pg_dump -U postgres -d japigo_12_10_2017 > C:\Users\HISP\Desktop\mwmis_odisha_12_10_2017.sql

MSF

$S2i0;h1d6


pg_dump -U postgres -d msf_23_07_2018 > C:\Users\HISP\Desktop\msf_updated_db.sql

C:\Users\Mithilesh Thakur\Desktop\msf>pg_dump -U postgres msf_23_07_2018 > msf_23_07_2018.sql

psql -U postgres msf_23_07_2018 < C:\Users\HISP\Desktop\msf_embu_db_30012018.sql

psql -U postgres msf_embu_01_02_2017 < C:\Users\HISP\Desktop\msf_embu_db_30012018.sql

psql -U postgres shatila_29_01_2018 < C:\Users\HISP\Desktop\shatila_dhis_224_2018-01-23.sql


psql -U postgres msf_23_01_2018 < C:\Users\HISP\Desktop\dhis2_backup_Jan-15-2018-15h27.sql

pg_dump -U postgres -d msf_final_18_01_2018 > C:\Users\HISP\Desktop\msf_final_db.sql

psql -U postgres msf_final_18_01_2018 < C:\Users\HISP\Desktop\MSF_Final_Destination_DB.sql





psql -U postgres msf_15_01_2018 < C:\Users\HISP\Desktop\dhis2_backup_Jan-08-2018-23h55.Fc.sql

psql -U postgres backup_demo_10_11_2017 < C:\Users\HISP\Desktop\bkpdemo.sql

pg_dump -U postgres -d msf_akkar_16_10_2017 > C:\Users\HISP\Desktop\msf_akkar_13_10_2017_updated.sql

psql -U postgres msf_akkar_16_10_2017 < C:\Users\HISP\Desktop\akkar_dhis_224_2017-10-16_1.sql


pg_dump -U postgres -d msf_shatila_13_10_2017 > C:\Users\HISP\Desktop\msf_shatila_13_10_2017_updated.sql

psql -U postgres msf_shatila_13_10_2017 < C:\Users\HISP\Desktop\shatila_dhis_224_2017-10-13_1.sql


psql -U postgres msf_burj_11_10_2017 < C:\Users\HISP\Desktop\burj_DB_11102017_1.sql

pg_dump -U postgres -d msf_burj_11_10_2017 > C:\Users\HISP\Desktop\msf_burj_11_10_2017.sql


pg_dump -U postgres -d msf_barelias_10_10_2017 > C:\Users\HISP\Desktop\barelias_updated.sql
psql -U postgres msf_barelias_10_10_2017 < C:\Users\HISP\Desktop\barelias_dhis_224_2017-11-02.sql



pg_dump -U postgres -d msf_shatila_10_10_2017 > C:\Users\HISP\Desktop\msf_shatila_10_10_2017_after_delete.sql

pg_dump -U postgres -d msf_shatila_10_10_2017 > C:\Users\HISP\Desktop\msf_shatila_10_10_2017_before_delete.sql

psql -U postgres msf_2.24_10_10_2017 < C:\Users\HISP\Desktop\barelias_dhis_224_2017-10-10.sql


psql -U postgres msf_shatila_10_10_2017 < C:\Users\HISP\Desktop\shatila_dhis_224_2017-10-08.sql

psql -U postgres msf_05_10_2017_sumit < C:\Users\HISP\Desktop\msf_pro_-05-10-2017-.sql

psql -U postgres msf_kenya_29_09_2017 < C:\Users\HISP\Desktop\mfs_29092017.sql
pg_dump -U postgres -d msf_kenya_29_09_2017 > C:\Users\HISP\Desktop\msf-hisp-V-1.sql

psql -U postgres tibet_28_09_2017 < C:\Users\HISP\Desktop\tibet_pro_28-Sep-17.sql


psql -U postgres akrosh_11_11_2016 < C:\Users\HISP\Desktop\clts.dhis2.net_db_dhis2_2.22-22015_20160926T031703-0400.sql

pg_dump -U postgres -d msf_2.27_21_09_2017 > C:\Users\HISP\Desktop\msf_2.27_updated.sql

psql -U postgres msf_2.27_21_09_2017 < C:\Users\HISP\Desktop\msf_Sep-20-17.sql

pg_dump -U postgres -d msf_08_09_2017 > C:\Users\HISP\Desktop\msf_2.27_updated.sql

pg_dump -U postgres -d msf_kenya_31_08_2017 > C:\Users\HISP\Desktop\msf_2.27_kenya.sql


MSF-2.24

msf_08_09_2017

psql -U postgres msf_08_09_2017 < C:\Users\HISP\Desktop\msf_2.27converted_backup.sql

psql -U postgres msf_kenya_31_08_2017 < C:\Users\HISP\Desktop\msf_local_29082017.sql



psql -U postgres msf_2.26_11_08_2017 < C:\Users\HISP\Desktop\msf_11082017.sql


psql -U postgres msf_test < C:\Users\HISP\Desktop\msf_May-31-17.sql

psql -U postgres msf_19_10_2016 < C:\Users\HISP\Desktop\msf_19102016.sql
psql -U postgres msf_13_10_2016 < C:\Users\HISP\Desktop\msf_Oct-13-16.sql

pg_dump -U postgres -d msf_19_10_2016 > C:\Users\HISP\Desktop\msf_updated.sql
pg_dump -U postgres -d msf_13_10_2016 > C:\Users\HISP\Desktop\msf_updated.sql


// LIBYA

psql -U postgres libya_19_03_2018 < C:\Users\HISP\Desktop\libya_DB.sql

pg_dump -U postgres -d libya_19_03_2018 > C:\Users\HISP\Desktop\libya_DB_Updated.sql

libya_DB


SAINT-LUCIA 2.24

// for IPPF 2.23

bzr branch lp:~dhis2-devs-core/dhis2/2.24 lp:~dhis2-devs-core/dhis2/sluhmis2.24

bzr checkout lp:~dhis2-devs-core/dhis2/sluhmis2.24

bzr merge lp:~dhis2-devs-core/dhis2/2.24

pg_dump -U postgres -d saint_lucia_13_09_2016 > C:\Users\HISP\Desktop\sluhmis_updated.sql


pg_dump -U postgres -d sluhmis_29_07_2016 > C:\Users\HISP\Desktop\sluhmis_updated.sql



pg_dump -U postgres -d haryana_2.20_testing_18_01_2018 > C:\Users\HISP\Desktop\haryana_testing.sql

ippf_FPAIMIS_05_04_2018


ippf_pro_2.27_06_03_2019

ippf_pro_08_05_2019
ippf_afga_26_06_2019

psql -U postgres ippf_afga_26_06_2019 < C:\Users\HISP\Desktop\fpan_pro_Apr-23-18_1.sql

psql -U postgres ippf_pro_08_05_2019 < C:\Users\HISP\Desktop\fpan_pro_Apr-23-18_1.sql

psql -U postgres ippf_RENEWB_26_07_2018 < C:\Users\HISP\Desktop\fpan_pro_Apr-23-18_1.sql

psql -U postgres fpan_qty_ippf_19_06_2018 < C:\Users\HISP\Desktop\fpan_pro_Apr-23-18_1.sql


psql -U postgres fpaidb_qty_ippf_14_06_2018 < C:\Users\HISP\Desktop\fpan_pro_Apr-23-18_1.sql

psql -U postgres ippf_2.27_26_04_2018 < C:\Users\HISP\Desktop\fpan_pro_Apr-23-18_1.sql

pg_dump -U postgres -d ippf_FPAIMIS_05_04_2018 > C:\Users\HISP\Desktop\ippf_2.27_updated.sql

psql -U postgres ippf_FPAIMIS_05_04_2018 < C:\Users\HISP\Desktop\fpaidb_pro_Apr-05-18_1.sql

pg_dump -U postgres -d ippf_pro_02_04_2018 > C:\Users\HISP\Desktop\ippf_2.27_updated.sql

psql -U postgres ippf_pro_02_04_2018 < C:\Users\HISP\Desktop\fpan_pro_Apr-02-18.sql

pg_dump -U postgres -d ippf_sri_19_03_2018 > C:\Users\HISP\Desktop\ippf_2.27_updated.sql

psql -U postgres ippf_sri_19_03_2018 < C:\Users\HISP\Desktop\fpasl_16march2018_backup.sql

pg_dump -U postgres -d ippf_pro_12_03_2018 > C:\Users\HISP\Desktop\ippf_2.27_updated.sql


psql -U postgres ippf_pro_12_03_2018 < C:\Users\HISP\Desktop\fpaidb_pro_Mar-12-18_1.sql

psql -U postgres saint_lucia_09_12_2016 < C:\Users\HISP\Desktop\dhisdb_9_12_2016_optioncodes.sql

psql -U postgres sluhmis_06_10_2016 < C:\Users\HISP\Desktop\dhisdb_5_10_2016_postgres.backup

psql -U postgres test_saint_lucia_hynek < C:\Users\HISP\Desktop\dhisdb_29_9_2016_15_40_postgres.sql

psql -U postgres sluhmis_31_08_2016 < C:\Users\HISP\Desktop\sluhmis_30082016.sql

psql -U postgres sluhmis_19_08_2016 < C:\Users\HISP\Desktop\sluhmis_18082016.sql


CCMP2

for backup

pg_dump -U postgres -d ccmp2_config_25_12_2016 > C:\Users\HISP\Desktop\ccmp_final.sql
pg_dump -U postgres -d ccmp2_config_15_12_2016 > C:\Users\HISP\Desktop\ccmp_final.sql
pg_dump -U postgres -d ccmp2_config_22_06_2016 > C:\Users\HISP\Desktop\ccmp_final.sql

pg_dump -U postgres -d ccmp2_config_15_06_2016 > C:\Users\HISP\Desktop\ccmp_config_final.sql


for import

psql -U postgres ccmp2_config_25_12_2016 < C:\Users\HISP\Desktop\ccmp2_config_Dec-25-16.sql

psql -U postgres ccmp2_config_15_12_2016 < C:\Users\HISP\Desktop\ccmp2_config_14122016.sql

psql -U postgres ccmp2_config_26_10_2016 < C:\Users\HISP\Desktop\ccmp2_config_Oct-26-16.sql
psql -U postgres ccmp2_config_22_06_2016 < C:\Users\HISP\Desktop\ccmp2_16042016-22062016.sql



psql -U postgres ccmp2_config_15_06_2016 < C:\Users\HISP\Desktop\_ccmp2_config_20160608_1750.sql
psql -U postgres CCMP_16_05_2016 < C:\Users\HISP\Desktop\ccmp2_config_13-May-2016_1722.sql



psql -U postgres asha_hry_11_07_2016 < C:\Users\HISP\Desktop\asha_portal_22062015-11072016.sql

psql -U postgres idsp_08_03_2017 < C:\Users\HISP\Desktop\idsp.sql

psql -U postgres idsp_old_09_03_2017 < C:\Users\HISP\Desktop\idsp.sql

pg_dump -U postgres -d idsp_08_03_2017 > C:\Users\HISP\Desktop\idsp_updated.sql


psql -U postgres idsp_14_03_2018 < C:\Users\HISP\Desktop\idsp_demo_Mar-14-18_1.sql


UP-HMIS




uphmis_meta_31_08_2019


psql -U postgres uphmis_meta_31_08_2019 < C:\Users\HISP\Desktop\uphmis_225.sql


psql -U postgres uphmis_2.25_07_03_2017 < C:\Users\HISP\Desktop\uphmis_225.sql

IPPF

psql -U postgres fpan_03_01_2018 < C:\Users\HISP\Desktop\fpan_pro_Jan-02-18_1.sql

psql -U postgres fpan_01_12_2017 < C:\Users\HISP\Desktop\fpan_pro_Nov-29-17.sql


for backup


psql -U postgres fpan_pro_29_08_2017 < C:\Users\HISP\Desktop\fpan_pro_Aug-27-17.sql

C:\Users\HISP>pg_dump -U postgres  ippf_Production_18_05_2016 > C:\Users\HISP\Desktop\ippf_production_2.19.sql

pg_dump -U postgres -d ippf_Production_07_06_2016_upgrade > C:\Users\HISP\Desktop\ippf_2.23_08_06_2016.sql


psql -U postgres ippf_production_21_07_2016 < C:\Users\HISP\Desktop\fpaidb_pro_21072016.sql

psql -U postgres ippf_production_07__07_2016 < C:\Users\HISP\Desktop\fpaidb_pro_Jul-06-16.sql


psql -U postgres ippf_Production_07_06_2016_upgrade < C:\Users\HISP\Desktop\fpaidb_pro_07-June-2016_1405.sql


psql -U postgres ippf_Production_27_05_2016_V_215 < C:\Users\HISP\Desktop\fpaidb_pro_26-May-2016_1537.sql

psql -U postgres ippf_Production_19_05_2016_V_215 < C:\Users\HISP\Desktop\fpaidb_pro_18-May-2016_1556.sql

psql -U postgres ippf_Production_18_05_2016 < C:\Users\HISP\Desktop\fpaidb_pro_18-May-2016_1556.sql


psql -U postgres ippf_Production_11_04_2016 < C:\Users\HISP\Desktop\fpaidb_pro_11-Apr-2016_1102.sql
psql -U postgres ippf_07_03_2016 < C:\Users\HISP\Desktop\fpaidb_pro_07-Mar-2016.sql


BHUTAN

pg_dump -U postgres -d bhutan_pro_10_07_2017 > C:\Users\HISP\Desktop\bhutan_server.sql

pg_dump -U postgres -d bhutan_local_11_07_2017 > C:\Users\HISP\Desktop\bhutan_local.sql



RWANDA MINAGRI

pg_dump -U postgres -d rwanda_minagri_10_01_2017 > C:\Users\HISP\Desktop\rwanda_minagri_10_01_2017.sql

psql -U postgres rwanda_minagri_10_01_2017 < C:\Users\HISP\Desktop\db_backup_sept_2.sql

psql -U postgres scale_04_01_2015 < C:\Users\HISP\Desktop\db_backup_abyot_feb_19

bihar

psql -U postgres bihar_test_01_01_2016 < C:\Users\HISP\Desktop\bihar_v220_6964.sql


hap

psql -U postgres hpa_06_01_2017 < C:\Users\HISP\Desktop\hpa.sql
psql -U postgres hpa_18_02_2016 < C:\Users\HISP\Desktop\hpa_v223.sql
psql -U postgres hpa_08_03_2016 < C:\Users\HISP\Desktop\hpa_07-Mar-2016.sql



HP

psql -U postgres hp_test_01_09_2016_2.23 < C:\Users\HISP\Desktop\hp_213_meta_01092016.sql
psql -U postgres hp_test_22_06_2016_2.20 < C:\Users\HISP\Desktop\hp_v220_testing.sql




psql -U postgres hp_07_04_2016_2.20 < C:\Users\HISP\Desktop\hp_v220_06-Apr-2016_1504.sql

psql -U postgres hp_04_03_2016_2.20 < C:\Users\HISP\Desktop\hp_v220_04-Mar-2016.sql

psql -U postgres sa_data_sync_10_03_2016 < C:\Users\HISP\Desktop\gp_20151021_123.sql

sa_data_sync_10_03_2016

up

psql -U postgres up_15_02_2015_2.20 < C:\Users\HISP\Desktop\up_1.sql

mp

psql -U postgres mp_23_02_2016 < C:\Users\HISP\Desktop\mp_v220_23-Feb-2016.sql
psql -U postgres mp_test_08_02_2016 < C:\Users\HISP\Desktop\mp_v220_08-Feb-2016.sql



leprosy

psql -U postgres leprosy_source_20_03_2018 < C:\Users\HISP\Desktop\leprosy__source_2018-03-08.sql


psql -U postgres leprosy_07_04_2017 < C:\Users\HISP\Desktop\leprosy_07042017.sql


plan


plan_pro_02_07_2018


plan_13_09_2018


psql -U postgres plan_232_06_08_2019 <

psql -U postgres plan_2.29_31_01_2019 < C:\Users\HISP\Desktop\dhis_dbms_Feb-01-18_1.sql

pg_dump -U postgres -d plan_232_06_08_2019 > "C:\Users\Mithilesh Thakur\Desktop\plan_232.sql"

pg_dump -U postgres -d plan_pro_06_08_2018 > "C:\Users\Mithilesh Thakur\Desktop\plan_updated_db.sql"

pg_dump -U postgres -d plan_28_06_2018 > "C:\Users\Mithilesh Thakur\Desktop\plan_updated_db.sql"


 C:\Users\HISP\Desktop\dhis_dbms_13042018.sql


pg_dump -U postgres -d plan_01_02_2018 > C:\Users\HISP\Desktop\plan_updated_2.27.sql

psql -U postgres plan_13_09_2018 < C:\Users\HISP\Desktop\dhis_dbms_Feb-01-18_1.sql

pg_dump -U postgres -d plan_updated_07_12_2017 > C:\Users\HISP\Desktop\plan_updated_2.27.sql

psql -U postgres plan_updated_07_12_2017 < C:\Users\HISP\Desktop\dhis_dbms_Dec-07-17.sql

psql -U postgres plan_2.26_09_05_2017 < C:\Users\HISP\Desktop\dhis_dbms_May-07-17.sql

pg_dump -U postgres -d plan_2.26_09_05_2017 > C:\Users\HISP\Desktop\plan_updated.sql

psql -U postgres plan_10_06_2016 < C:\Users\HISP\Desktop\dhis_dbms_li264-205_10-June-2016_1.sql

psql -U postgres plan_28_12_2015 < C:\Users\HISP\Desktop\dhis_dbms_28-Dec-2015_1451.sql

pg_dump -U postgres -d plan_10_06_2016 > C:\Users\HISP\Desktop\plan_10_06_2016.sql


psql -U postgres test_db_harsh < C:\Users\HISP\Desktop\pgDump.sql





psql -U postgres indonesia_25_09_2018 <
maharashtra



psql -U postgres bihar_2.27_17_06_2019 < 

psql -U postgres mh_227_04_09_2019 < 

psql -U postgres mh_2.27_29_05_2019 < C:\Users\HISP\Desktop\dhis_turkey_13-Nov-2015.sql

psql -U postgres mh_25_09_2018 < C:\Users\HISP\Desktop\dhis_turkey_13-Nov-2015.sql

psql -U postgres mh_pro_2.27_meta_26_03_2018 < C:\Users\HISP\Desktop\mh_pg_metadata_new_22032018.sql

psql -U postgres mh_22_08_2016_2.23 < C:\Users\HISP\Desktop\mh_pg_blank_meta_21082016.sql


psql -U postgres mh_18_12_2015_2.20 < C:\Users\HISP\Desktop\mh_final_pg_v220.sql

psql -U postgres mh_11_02_2016_2.20 < C:\Users\HISP\Desktop\mh_v220_05-Feb-2016.sql

mh_18_12_2015_2.20

Nepal HIV Tracker



pg_dump -U postgres -d hiv_tracker_22_08_2017 > C:\Users\HISP\Desktop\hivtracker_updated_db.sql

psql -U postgres hiv_tracker_10_01_2019 < C:\Users\HISP\Desktop\hivtracker_22082017.sql


pg_dump -U postgres -d nepal_01_08_2017 > C:\Users\HISP\Desktop\nepal_updated_db.sql

psql -U postgres nepal_01_08_2017 < C:\Users\HISP\Desktop\nhssp_meta_25072017.sql


psql -U postgres pbf_rowanda_v27_upgrade < C:\Users\HISP\Desktop\pbf_rowanda_2.27_22_02_2018_1.sql


pg_dump -U postgres pbf_rowanda_v27_upgrade > C:\Users\HISP\Desktop\pbf_rowanda_2.27_22_02_2018.sql

pg_dump -U postgres pbf_rowanda_v27_12_12_2017 > C:\Users\HISP\Desktop\pbf_rowanda_2.27.sql

pg_dump -U postgres pbf_rowanda_v27_12_12_2017 > C:\Users\HISP\Desktop\pbf_rowanda_2.27.sql

SELECT ds.name,de.name,dse.dataelementid from dataset ds
INNER JOIN datasetelement dse ON dse.datasetid = ds.datasetid
INNER JOIN dataelement de ON de.dataelementid = dse.dataelementid where dse.datasetid in ( 6425, 1156990)
order by dse.datasetid


psql -U postgres pbf_rowanda_upgrade < C:\Users\HISP\Desktop\pbfrwanda218v.sql



pg_dump -U postgres pbf_rowanda_v26_13_11_2017 > C:\Users\HISP\Desktop\pbf_rowanda_2.26.sql

pg_dump -U postgres pbf_rwanda_14_08_2017_v2.26 > C:\Users\HISP\Desktop\pbf_rowanda_2.26.sql

psql -U postgres pbf_rowanda_v26_13_11_2017 < C:\Users\HISP\Desktop\pbf_2017_10_11.sql

psql -U postgres pbf_test < C:\Users\HISP\Desktop\pbf_rowanda_2.26.sql


TIBET

psql -U postgres tibet_26_09_2017 < C:\Users\HISP\Desktop\tibet_pro_26-Sep-2017.sql

psql -U postgres tibet_21_08_2017 < C:\Users\HISP\Desktop\tibet_21082017.sql


pg_dump -U postgres tibet_14_08_2017 > C:\Users\HISP\Desktop\tibet.sql


psql -U postgres tibet_14_08_2017 < C:\Users\HISP\Desktop\tibet_14082017_1.sql

psql -U postgres tibet_27_07_2017 < C:\Users\HISP\Desktop\tibet_25072017.sql


AES

aes_08_08_2018

psql -U postgres aes_08_08_2018 < C:\Users\HISP\Desktop\aes_Apr-11-18_1.sql



psql -U postgres aes_06_04_2018 < C:\Users\HISP\Desktop\aes_Mar-14-18_1.sql


psql -U postgres aes_01_03_2018_pro < C:\Users\HISP\Desktop\aes_Mar-01-18.sql

psql -U postgres aes_26_12_2017_pro < C:\Users\HISP\Desktop\aes_Dec-21-17.sql

psql -U postgres aes_04_09_2017 < C:\Users\HISP\Desktop\aes_04092017_1.sql

psql -U postgres aes_28_07_2017 < C:\Users\HISP\Desktop\aes_Jul-19-17.sql
psql -U postgres aes_28_06_2017 < C:\Users\HISP\Desktop\aes_Jun-27-17_1.sql

pg_dump -U postgres -d aes_21_06_2017 > C:\Users\HISP\Desktop\aes_updated_db.sql

psql -U postgres aes_21_06_2017 < C:\Users\HISP\Desktop\Latest_AES_db_21_06_2017.sql

psql -U postgres aes_16_06_2017 < C:\Users\HISP\Desktop\aes_Jun-15-17_1.sql
psql -U postgres aes_29_05_2017 < C:\Users\HISP\Desktop\aes_tes_25052017.sql




green_star

psql -U postgres green_star_09_06_2017 < C:\Users\HISP\Desktop\green_star.sql

psql -U postgres green_star_production_13_07_2016 < C:\Users\HISP\Desktop\greenstar_crm_13072017.sql

psql -U postgres green_star_production_01_06_2016 < C:\Users\HISP\Desktop\greenstar_crm_103.sql

psql -U postgres green_star_09_05_2016 < C:\Users\HISP\Desktop\greenstar2_07-May-2016+1800.sql
psql -U postgres green_star_18_04_2016 < C:\Users\HISP\Desktop\dhis_greenstar_11-Apr-2016_1406.sql
psql -U postgres green_star_25_02_2016 < C:\Users\HISP\Desktop\greenstar_pakistan_25-Feb-2016.sql

ovc

psql -U postgres ovc_27_10_2015 < C:\Users\HISP\Desktop\ovc_08042015_27-Oct-2015.sql

psql -U postgres bihar_06_11_2015_meta_data < C:\Users\HISP\Desktop\bihar_v220_pg_final.sql

psql -U postgres bihar_06_11_2015_meta_data < C:\Users\HISP\Desktop\bihar_v220_pg_final.sql

postGress data Import command

ccei_tracker_07_10_2015


shatila_test

psql -U postgres shatila_test < C:\Users\HISP\Desktop\shatila_dhis_224_2017-11-01.sql

psql -U postgres bangla_desh_ccei_01_07_2016 < C:\Users\HISP\Desktop\dhis2_bd.sql


psql -U postgres nvbdcp_21_09_2017 < C:\Users\HISP\Desktop\nvbdcp_new_part2_20092017.sql





psql -U postgres turkey_13_11_2015 < C:\Users\HISP\Desktop\dhis_turkey_13-Nov-2015.sql


psql -U postgres scale_26_10_2015 < C:\Users\HISP\Desktop\dhis_scale_20-Oct-2015_1518.sql


psql -U postgres quic_18_10_2015 < C:\Users\HISP\Desktop\dhis_quic_17-Oct-2015_1750.sql


psql -U postgres ccei_tracker_23_10_2015 < C:\Users\HISP\Desktop\ccei_tracker_23102015.sql


psql -U postgres hry_meta_data_05_10_2015_2.17 < C:\Users\HISP\Desktop\hry_pro_pg_metadata_05-Oct-2015.sql

psql -U postgres scale_30_09_2015 < C:\Users\HISP\Desktop\dhis_scale_30-Sep-2015.sql

psql -U postgres cse_24_09_2015 < C:\Users\HISP\Desktop\fpai_cse_Sep-23-15.sql

psql -U postgres mp_18_09_2015_v20 < C:\Users\HISP\Desktop\mp_v220_18-Sep-2015.sql

psql -U postgres bihar_ihris_14_09_2015 < C:\Users\HISP\Desktop\dhis_ihris_sept6.sql

psql -U postgres haryana_2.20_testing < C:\Users\HISP\Desktop\hry_v220_16092015.sql

psql -U postgres haryana_2.20_testing_18_01_2018 < C:\Users\HISP\Desktop\hry_v220_meta_18012018.sql


psql -U postgres hry_04_06_2018 < C:\Users\HISP\Desktop\hry_v220_meta_18012018.sql




C:\Users\HISP\Desktop\deskTop\CCEM\ccei>psql -U postgres ccei_01_10_2013 < ccei.sql

or

C:\Users\HISP>psql -U postgres ovc_11_04_2014_imported < "C:\Users\HISP\Desktop\ovc 11 April 2014.sql"

C:\Users\HISP\Downloads\spis_hisp-odoo_09-Feb-2015_1506.sql>psql -U postgres spis < spis_hisp-odoo_09-Feb-2015_1506.sql
 
or 

C:\Users\HISP>psql -U postgres ccem_n_21_09_2013 < C:\Users\HISP\Desktop\deskTop\CCEM\ccem_n\21-09-2013\ccem_nigeria_Sep-21-13.sql

or

INPART

intpart_2.28_14_02_2019

intpart_2.30_14_02_2019

psql -U postgres intpart_2.28_21_02_2019 < C:\Users\HISP\Desktop\pcs_8march_08.sql

pg_dump -U postgres intpart_2.30_23_01_2019 > C:\Users\HISP\Desktop\ippf_updated.sql

psql -U postgres intpart_new_26_06_2018 < C:\Users\HISP\Desktop\pcs_8march_08.sql

psql -U postgres intpart_2.30_14_02_2019 < C:\Users\HISP\Desktop\pcs_8march_08.sql

C:\Users\HISP>psql -U postgres inpart_20_11_2017 < C:\Users\HISP\Desktop\pcs_dhis_2017-11-18.sql

C:\Users\HISP>pg_dump -U postgres inpart_20_11_2017 > C:\Users\HISP\Desktop\inpart_updated_2.28.sql

C:\Users\HISP>pg_dump -U postgres INPART_04_07_2017 > C:\Users\HISP\Desktop\inpart.sql

C:\Users\HISP>psql -U postgres INPART_04_07_2017 < C:\Users\HISP\Desktop\Updated_intpart.sql

PBF

pg_dump -U postgres pbf_rowanda_v27_12_12_2017 > C:\Users\HISP\Desktop\pbf_rowanda_2.27.sql


C:\Users\HISP>psql -U postgres pbf_rwanda_14_08_2017_v2.26 < C:\Users\HISP\Desktop\pbf_rwanda.sql

C:\Users\HISP>pg_dump -U postgres pbf_rwanda_17_11_2016 > C:\Users\HISP\Desktop\pbf_rwanda.sql


C:\Users\HISP>psql -U postgres pbf_rwanda_17_11_2016 < C:\Users\HISP\Desktop\pbfrwanda.sql

C:\Users\HISP>pg_dump -U postgres pbf_rwanda_17_11_2016 > C:\Users\HISP\Desktop\pbf_rwanda.sql


C:\Users\HISP>psql -U postgres pbf_10_03_2014 < C:\Users\HISP\Desktop\pbf_Mar-10-14.sql

psql -U postgres quic_nigeria_23_07_2015 < C:\Users\HISP\Desktop\quic_HISP-APPS-3_23-July-2015_1119.sql

psql -U postgres quic_tanzania_23_07_2015 < C:\Users\HISP\Desktop\tanzania_hisp-odoo_23-July-2015_1121.sql


or

C:\Users\HISP>psql -U postgres ippf_07_07_2014 < C:\Users\HISP\Desktop\deskTop\IPPF\data_base\05_07_2014\ippf_05072014\ippf_05072014.backup


pg_dump -U postgres ippf_28_03_2017 > C:\Users\HISP\Desktop\ippf_updated.sql

C:\Users\HISP>psql -U postgres pbf_laos_28_04_2013 < C:\Users\HISP\Desktop\pbf_laos_28-Apr-14.sql
or

C:\Users\HISP>psql -U postgres quic_13_05_2015 < C:\Users\HISP\Desktop\quic_siera_leone_13052015.sql

psql -U postgres test_db_08_05_2017 < C:\Users\HISP\Desktop\dhis2_25.sql



// for taking postgres backup backup

C:\Users\HISP\Desktop>pg_dump -U postgres ccei_tracker_13_05_2015 > ccei_tracker_13_05_2015.sql
C:\Users\HISP>pg_dump -U postgres quic_malawi_20_05_2015 > quic_malawi.sql


C:\Users\HISP>psql -U postgres haryana_2.17_testing < C:\Users\HISP\Desktop\haryana_v212_pro_PowerEdgeT100_14-Mar-2015_1154.sql



or


psql -U postgres maleria_16_01_2018 < C:\Users\HISP\Desktop\mmis_pilot_16012018.sql

C:\Users\HISP>psql -U postgres maleria_10_10_2014 < C:\Users\HISP\Desktop\mmis_10-Oct-2014.sql

or
C:\Users\HISP>psql -U postgres ovc_20_03_2014 < C:\Users\HISP\Desktop\ovc_Mar-20-14.sql
C:\Users\HISP>psql -U postgres ovc_production_07_04_2015 < C:\Users\HISP\Desktop\ovc_09012015_04-Apr-2015_1123.sql
0r
C:\Users\HISP>psql -U postgres ippf_linod_17_02_2015 < C:\Users\HISP\Desktop\ippf_215.sql

or
C:\Users\HISP>psql -U postgres ovc_13_05_2013 < C:\Users\HISP\Desktop\deskTop\OVC\warFile_13_05_2013\ovc_13-05-2013.backup

or
C:\Users\HISP>psql -U postgres ccei_malawi_24_12_2013 < C:\Users\HISP\Desktop\deskTop\CCEM\24_12_2013_Malawi_db\ccei_malawi_211213.sql

or
C:\Users\HISP\Desktop\deskTop\OVC\dataBase\28_01_2014\ovc_Jan-28-14.sql>psql -U postgres ovc_28_01_2014 < ovc_Jan-28-14.sql

or

c:\Users\HISP\Desktop\deskTop\CCEM\ccei_laos\06_02_2014_db\laos_Feb-06-14.sql>psql -U postgres ccei_laos_06_02_2014 < laos_Feb-06-14.sql



command for backup in postgres sql

C:\Users\HISP>pg_dump -U postgres  ccei_laos_09_01_2014 > C:\Users\HISP\Desktop\deskTop\CCEM\ccei_laos\10_01_2014_db_backup\ccei_laos_10012014.sql

C:\Users\HISP>pg_dump -U postgres  plan_28_12_2015 > C:\Users\HISP\Desktop\plan_db.sql

or
C:\Users\HISP>pg_dump -U postgres  ccei_laos_06_02_2014 > C:\Users\HISP\Desktop\deskTop\CCEM\ccei_laos\06_02_2014_db_backup\ccei_laos_06Feb2014.sql


my sql database backup
C:\Users\HISP>mysqldump -u root -p asha_hry_03_07_2014 > asha_hry_03_07_2014.sql





C:\Users\HISP>pg_dump -U postgres ovc_production_28_07_2014 > ovc_production_28_07_2014.sql


or
C:\Users\HISP>pg_dump -U postgres ccei_malawi_24_12_2013 > C:\Users\HISP\Desktop\deskTop\CCEM\24_12_2013_Malawi_db\ccei_malawi_211213.sql

or
C:\Users\HISP>psql -U postgres ccei_malawi_24_12_2013 < C:\Users\HISP\Desktop\deskTop\CCEM\24_12_2013_Malawi_db\ccei_malawi_211213.sql

You can now set a "dhis.skip.startup" system property to skip the startup routines during web app development. Shaves 5 sec on the startup time here.

mvn jetty:run -Ddhis.skip.startup=true


// for update/add patch in source code

 patch -p1 --verbose < /c/Users/HISP/Downloads/java.patch


Launchpad userID : mithilesh.hisp@gmail.com

Password : 



Dhis2 CCEI Details

Gmail Id : dhis2.ccei.dev@gmail.com
password : hispindia
Dob: 01/01/1984  Male
Phone: 9560163563
mithilesh.hisp@gmail.com

Launchpad.net

Full name : DHIS2 CCEI DEV
email: dhis2.ccei.dev@gmail.com
password: hispindia


// 23/04/2015

For DHIS2 HISP INDIA DEVELOPER

Gmail-Account
Gmail Name : DHIS2 HISP INDIA
gmail-id : dhis.devs.india@gmail.com
password : hispindia
dob : 01/01/1984 Male
alternate e-mail - mithilesh.hisp@gmail.com

// for Reverting command

bzr revert -r 21536


Launchpad.net Account

Full name : dhis-devs-india
email: dhis.devs.india@gmail.com
password: hispindia

Bazar login : bzr whoami "dhis-devs-india<dhis.devs.india@gmail.com>"
Bazar Login : bzr lp-login dhis-devs-india
for key generation
type this command in cygwin window : ssh-keygen -t rsa

for create branch from trunk
bzr branch lp:~dhis2-devs-core/dhis2/trunk lp:~dhis2-devs-core/dhis2/india-trunk

bzr checkout lp:~dhis2-devs-core/dhis2/india-trunk	


Then once we have checked-out the branch with the command

bzr checkout lp:~dhis2-devs-core/dhis2/india-trunk

bzr checkout lp:~dhis2-devs-india/dhis2/india-trunk

http://bazaar.launchpad.net/~dhis2-devs-india/dhis2/india-trunk/changes


Checkout: bzr checkout lp:~dhis2-devs-india/dhis2/india-trunk

Bind: bzr bind lp:~dhis2-devs-india/dhis2/india-trunk


We need to set the commit destination with the following command - the command ensures commits are sent to launchpad server not to local machine.

bzr bind lp:~dhis2-devs-core/dhis2/india-trunk


http://bazaar.launchpad.net/~dhis2-devs-india/dhis2/india-trunk/changes



// form any branch
 bzr branch lp:~dhis2-devs-core/dhis2/2.18 lp:~dhis2-devs-core/dhis2/emro_ir

 bzr checkout lp:~dhis2-devs-core/dhis2/emro_ir





/**
 * @author Mithilesh Kumar Thakur
 */


System Variable
Variable name : DHIS2_HOME
Variable value : c:\DHIS2_HOME
		
		JAVA_HOME :	C:\Program Files\Java\jdk1.7.0_25
		JAVA_OPTS : -Xms1024m -Xmx1536m -XX:MaxPermSize=512m
		MAVEN_HOME : C:\maven
                MAVEN_OPTS : -Xms1024m -Xmx1536m -XX:MaxPermSize=512m
		M2_REPO : c:\users\hisp\.m2
		Path : C:\Program Files\Common Files\Microsoft Shared\Windows Live;C:\Program Files (x86)\Common Files\Microsoft Shared\Windows Live;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;%SystemRoot%\system32;%SystemRoot%;%SystemRoot%\System32\Wbem;%SYSTEMROOT%\System32\WindowsPowerShell\v1.0\;%MAVEN_HOME%\bin;C:\Program Files (x86)\Intel\OpenCL SDK\2.0\bin\x86;C:\Program Files (x86)\Intel\OpenCL SDK\2.0\bin\x64;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Common Files\Lenovo;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files (x86)\Symantec\VIP Access Client\;C:\SWTOOLS\ReadyApps;C:\Program Files (x86)\Common Files\Lenovo;C:\Program Files (x86)\Bazaar;C:\Program Files\PostgreSQL\9.2\bin;C:\Program Files\R\R-3.0.1\bin;C:\Program Files\MySQL\MySQL Server 5.5\bin;C:\Program Files\SQLyog Community



to run source code or checkout for run all bzr command in command promt

add public key in Pageant( PuTTY authentication agent )


// postgres SQL Query alter the database sequence id

SELECT c.relname FROM pg_class c WHERE c.relkind = 'S';

return 

SELECT last_value FROM hibernate_sequence;

ALTER SEQUENCE hibernate_sequence RESTART WITH 4412;

nextval('hibernate_sequence') // for generating next hibernate sequence


SELECT MIN(p.startdate), MAX(p.startdate) FROM datavalue dv 
                   INNER JOIN period p ON dv.periodid = p.periodid 
                   INNER JOIN datasetmembers dsm 
                   ON dsm.dataelementid = dv.dataelementid WHERE dsm.datasetid = 1;


// remove duplicate period related query

(SELECT p.startdate,p.enddate, COUNT(*)
FROM period p
GROUP BY p.startdate,p.enddate
HAVING COUNT(*) > 1);


// manualy remove duplicate period
SELECT periodid, periodtypeid, startdate, enddate
  FROM period where startdate = '2012-04-01' and  enddate = '2012-06-30';

// select from data value

SELECT dataelementid, periodid, sourceid, categoryoptioncomboid, value, 
       storedby, lastupdated, comment, followup, created, attributeoptioncomboid
  FROM datavalue where periodid in ( select periodid FROM period where periodtypeid in ( 4,5 ));


// not required if data is not present in datavalue table

UPDATE datavalue dv SET periodid = 375291
WHERE periodid IN (375292,375293);


after delete duplicate period run query 

ALTER TABLE period ADD CONSTRAINT period_periodtypeid_key UNIQUE(periodtypeid, startdate, enddate);

// not-in query

SELECT  tei.* from trackedentityinstance tei
WHERE   NOT EXISTS
(

SELECT  NULL FROM    programinstance pi
WHERE   pi.trackedentityinstanceid = tei.trackedentityinstanceid

)

// query for show all tables in database in postgres sql


SELECT table_schema,table_name
FROM information_schema.tables
ORDER BY table_schema,table_name

SELECT table_name FROM information_schema.tables WHERE table_schema ='public' AND table_type='BASE TABLE';

SELECT table_name, table_type FROM information_schema.tables WHERE table_schema ='public' AND table_type='BASE TABLE' order by table_name;

// for my sql

"SHOW FULL TABLES";












$ bzr help commands
add                  Add specified files or directories.
add-pipe             Add a pipe to the pipeline. [pipeline]
alias                Set/unset and display aliases.
annotate             Show the origin of each line in a file.
bind                 Convert the current branch into a checkout of the supplied
                     branch.
branch               Create a new branch that is a copy of an existing branch.
branch-history       Display the development history of a branch. [bzrtools]
branches             List the branches available at the current location.
break-lock           Break a dead lock.
bug-url              Print full URL to a specific bug, or open it in your
                     browser. [qbzr]
cat                  Write the contents of a file as of a given revision to
                     standard output.
cbranch              Create a new checkout, associated with a new repository
                     branch. [bzrtools]
cdiff                A color version of bzr's diff [bzrtools]
check                Validate working tree structure, branch consistency and
                     repository history.
checkout             Create a new checkout of an existing branch.
clean-tree           Remove unwanted files from working tree.
colo-branch          Make a new branch from the currently active branch. [colo]
colo-branches        List all of the branches in a colocated workspace. [colo]
colo-checkout        Create a checkout of this branch in a new directory.
                     [colo]
colo-clean           Clean unused revisions from the repository. [colo]
colo-fetch           Fetch an external project into a new colocated workspace.
                     [colo]
colo-fixup           Fix the checkout reference after moving a colocated
                     workspace. [colo]
colo-ify             Convert an existing branch into a colocated workspace.
                     [colo]
colo-init            Create a working tree with colocated branches. [colo]
colo-mv              Rename a colocated branch. [colo]
colo-prune           Remove a branch from the colocated workspace. [colo]
colo-pull            Update all remote branches. [colo]
colo-sync-from       Synchronize this colocated workspace from the state of
                     another one. [colo]
colo-sync-to         Synchronize this colocated workspace to another one.
                     [colo]
combine-thread       Combine the current thread with the thread below it.
                     [loom]
commit               Commit changes into a new revision.
config               Display, set or remove a configuration option.
conflict-diff        Compare a conflicted file against BASE. [bzrtools]
conflicts            List files with conflicts.
create-mirror        Create a mirror of another branch. [bzrtools]
create-thread        Add a thread to this loom. [loom]
deleted              List files deleted in the working tree.
diff                 Show differences in the working tree, between revisions or
                     branches.
down-thread          Move the branch down a thread in the loom. [loom]
dpush                Push into a different VCS without any custom bzr metadata.
explorer             Desktop application for Bazaar. [explorer]
export               Export current or past revision to a destination directory
                     or archive.
export-loom          Export loom threads as a full-fledged branches. [loom]
fast-export          Generate a fast-import stream from a Bazaar branch.
                     [fastimport]
fast-import          Backend for fast Bazaar data importers. [fastimport]
fast-import-filter   Filter a fast-import stream to include/exclude files &
                     directories. [fastimport]
fast-import-info     Output information about a fast-import stream.
                     [fastimport]
fetch-ghosts         Attempt to retrieve ghosts from another branch. [bzrtools]
fix-svn-ancestry     Fix the SVN ancestry of a repository. [svn]
git-apply            Apply a series of git-am style patches. [git]
git-import           Import all branches from a git repository. [git]
graph-ancestry       Produce ancestry graphs using dot. [bzrtools]
heads                Show all revisions in a repository not having descendants.
                     [bzrtools]
help                 Show help on a command or other topic.
ignore               Ignore specified files or patterns.
ignored              List ignored files and the patterns that matched them.
import               Import sources from a directory, tarball or zip file
                     [bzrtools]
info                 Show information about a working tree, branch or
                     repository.
init                 Make a directory into a versioned branch.
init-repository      Create a shared repository for branches to share storage
                     space.
init-workspace       Start a new workspace. [explorer]
join                 Combine a tree into its containing tree.
launchpad-login      Show or set the Launchpad user ID. [launchpad]
launchpad-mirror     Ask Launchpad to mirror a branch now. [launchpad]
launchpad-open       Open a Launchpad branch page in your web browser.
                     [launchpad]
link-tree            Hardlink matching files to another tree. [bzrtools]
list-branches        Scan a location for branches [bzrtools]
log                  Show historical log for a branch or subset of a branch.
loomify              Add a loom to this branch. [loom]
lp-find-proposal     Find the proposal to merge this revision. [launchpad]
lp-propose-merge     Propose merging a branch on Launchpad. [launchpad]
ls                   List files in a tree.
merge                Perform a three-way merge. [pipeline]
missing              Show unmerged/unpulled revisions between two branches.
mkdir                Create a new versioned directory.
multi-pull           Pull all the branches under a location, e.g. a repository.
                     [bzrtools]
mv                   Move or rename a file.
nick                 Print or set the branch nickname.
pack                 Compress the data within a repository.
patch                Apply a named patch to the current tree. [bzrtools]
pipe-patches         Export the pipeline as a collection of patches, one per
                     pipe. [pipeline]
plugins              List the installed plugins.
pull                 Turn this branch into a mirror of another branch.
pump                 From this pipe onward, merge all pipes into their next
                     pipe and commit. [pipeline]
push                 Update a mirror of this branch.
qadd                 GUI for adding files or directories. [qbzr]
qannotate            Show the origin of each line in a file. [qbzr]
qbind                Convert the current branch into a checkout of the supplied
                     branch. [qbzr]
qbranch              Create a new copy of a branch. [qbzr]
qbranches            List colocated branches. [colo]
qbrowse              Show inventory or working tree. [qbzr]
qcat                 View the contents of a file as of a given revision. [qbzr]
qcoloswitch          Switch between colocated branches graphically. [colo]
qcommit              GUI for committing revisions. [qbzr]
qconfig              Configure Bazaar and QBzr. [qbzr]
qconflicts           Show conflicts. [qbzr]
qdiff                Show differences in working tree in a GUI window. [qbzr]
qexport              Export current or past revision to a destination directory
                     or archive. [qbzr]
qgetnew              Creates a new working tree (either a checkout or full
                     branch). [qbzr]
qgetupdates          Fetches external changes into the working tree. [qbzr]
qignore              Ignore files or patterns. [qbzr]
qinfo                Shows information about the current location. [qbzr]
qinit                Initializes a new branch or shared repository. [qbzr]
qinit-workspace      Start a new workspace using a GUI. [explorer]
qlog                 Show log of a repository, branch, file, or directory in a
                     Qt window. [qbzr]
qmerge               Perform a three-way merge. [qbzr]
qplugins             Show information about installed plugins. [qbzr]
qprune               Remove colocated branches. [colo]
qpull                Turn this branch into a mirror of another branch. [qbzr]
qpush                Update a mirror of this branch. [qbzr]
qrevert              Revert changes files. [qbzr]
qrun                 Run arbitrary bzr command. [qbzr]
qsend                Mail or create a merge-directive for submitting changes.
                     [qbzr]
qshelve              Shelve selected changes away. [qbzr]
qswitch              Set the branch of a checkout and update. [qbzr]
qtag                 Edit tags. [qbzr]
qunbind              Convert the current checkout into a regular branch. [qbzr]
quncommit            Move the tip of a branch to an earlier revision. [qbzr]
qunshelve            Restore shalved changes. [qbzr]
qupdate              Update working tree with latest changes in the branch.
                     [qbzr]
qverify-signatures   Shows digital signature statuses for branch commits [qbzr]
qversion             Show version/system information. [qbzr]
qviewer              Simple file viewer. [qbzr]
rebase               Re-base a branch. [rewrite]
rebase-abort         Abort an interrupted rebase. [rewrite]
rebase-continue      Continue an interrupted rebase after resolving conflicts.
                     [rewrite]
rebase-foreign       Rebase revisions based on a branch created with a
                     different import tool. [rewrite]
rebase-todo          Print list of revisions that still need to be replayed as
                     part of the [rewrite]
reconcile            Reconcile bzr metadata in a branch.
reconfigure          Reconfigure the type of a bzr directory.
reconfigure-pipeline Reconfigure a tree with branch into a lightweight checkout
                     of a pipe. [pipeline]
record               Record the current last-revision of this tree into the
                     current thread. [loom]
register-branch      Register a branch with launchpad.net. [launchpad]
remerge              Redo a merge.
remove               Remove files or directories.
remove-branch        Remove a branch.
remove-pipe          Remove a pipe from the pipeline. [pipeline]
remove-tree          Remove the working tree from a given branch/checkout.
rename-pipe          Rename a pipe to a different name. [pipeline]
renames              Show list of renamed files.
resolve              Mark a conflict as resolved.
revert               Revert files to a previous revision.
revert-loom          Revert part or all of a loom. [loom]
revno                Show current revision number.
root                 Show the tree root directory.
rspush               Upload this branch to another location using rsync.
                     [bzrtools]
send                 Mail or create a merge-directive for submitting changes.
serve                Run the bzr server.
shelf1               Perform various operations on your shelved patches. See
                     also shelve1. [bzrtools]
shell                Begin an interactive shell tailored for bzr. [bzrtools]
shelve               Temporarily set aside some changes from the current tree.
shelve1              Temporarily set aside some changes from the current tree.
                     [bzrtools]
show-loom            Show the threads in this loom. [loom]
show-pipeline        Show the current pipeline. [pipeline]
sign-my-commits      Sign all commits by a given committer.
split                Split a subdirectory of a tree into a separate tree.
status               Display status summary.
svn-import           Convert a Subversion repository to a Bazaar repository.
                     [svn]
svn-layout           Print the repository layout in use for a Subversion
                     repository. [svn]
switch               Set the branch of a checkout and update. [loom]
switch-pipe          Switch from one pipe to another. [pipeline]
sync-pipeline        Synchronise the contents of this pipeline with another
                     copy. [pipeline]
tag                  Create, remove or modify a tag naming a revision.
tags                 List tags.
testament            Show testament (signing-form) of a revision.
trees                Scan a location for trees [bzrtools]
unbind               Convert the current checkout into a regular branch.
uncommit             Remove the last committed revision.
unshelve             Restore shelved changes.
unshelve1            Restore shelved changes. [bzrtools]
up-thread            Move the branch up to the top thread in the loom. [loom]
update               Update a working tree to a new revision.
upgrade              Upgrade a repository, branch or working tree to a newer
                     format.
upload               Upload a working tree, as a whole or incrementally.
                     [upload]
verify-signatures    Verify all commit signatures.
version              Show version of bzr.
version-info         Show version information about this tree.
view                 Manage filtered views.
whoami               Show or set bzr user id.
zap                  Remove a lightweight checkout, if it can be done safely.
                     [bzrtools]


// generate uid usiging dhis
 http://localhost:8080/dhis/api/system/id.json
 http://localhost:8090/dhis/api/system/id.json?limit=10


github Detais

Lars created branch for trunk/local/in
url : https://github.com/dhis2/dhis2-local-in
Last Commit No - 553 date 29/12/2015

My self Created Branch
url : https://github.com/mithileshhisp/dhis-local-in
Username or email address  : mithilesh.hisp@gmail.com  usename - mithileshhisp
Password : 
Create Own Organisation name dhis2hispindia

url : https://github.com/dhis2hispindia

Commit in GitHub following Files:
Branches are : DHIS-Apps,CCEI-2.14,CCEI
Total Commit/Revision - 27,28
Last Commit date 23/11/2015 Excel Import app new, bzar command file
Last Commit No - 29 date 29/12/2015 "Add CCEI App and QUIC New App and Report"
Last Commit No - 31 date 29/12/2015 "Add CCMP App"
Last Commit No - 31 date 29/12/2015 "Add DashBoard"



GIT Hub Commit Command
 Git Bash
go to the directory


adding date column in sql query making in excel

=TEXT(F2,"yyyy-MM-DD")

=TEXT(F2,"yyyy-MM-DD HH-MM-SS")



begin;
DELETE FROM trackedentitydatavalue
 WHERE programstageinstanceid in (
            select programstageinstanceid 
            from programstageinstance 
            where programstageid in (
                        select programstageid 
                        from programstage 
                        where uid = 'DQCCgUfyDTR'
                        )
                );
DELETE FROM programstageinstance
 WHERE programstageid in (
            select programstageid from programstage where uid = 'DQCCgUfyDTR'
            );
commit; 


SELECT  dataelement.dataelementid,dataelement.name, dataelement.uid as dataElement_Uid,categories_categoryoptions.categoryoptionid, dataelementcategoryoption.name,dataelementcategoryoption.uid as dataelementcategoryoption_uid from dataelement
INNER JOIN categorycombos_categories ON categorycombos_categories.categorycomboid = dataelement.categorycomboid
INNER JOIN categories_categoryoptions ON categories_categoryoptions.categoryid = categorycombos_categories.categoryid
INNER JOIN dataelementcategoryoption ON dataelementcategoryoption.categoryoptionid = categories_categoryoptions.categoryoptionid

order by dataelement.dataelementid;


SELECT  dataelement.dataelementid,dataelement.name, categories_categoryoptions.categoryoptionid, dataelementcategoryoption.name from dataelement
INNER JOIN categorycombos_categories ON categorycombos_categories.categorycomboid = dataelement.categorycomboid
INNER JOIN categories_categoryoptions ON categories_categoryoptions.categoryid = categorycombos_categories.categoryid
INNER JOIN dataelementcategoryoption ON dataelementcategoryoption.categoryoptionid = categories_categoryoptions.categoryoptionid
order by dataelement.dataelementid;

SELECT _categoryoptioncomboname.categoryoptioncomboid, categoryoptioncombo.uid,  _categoryoptioncomboname.categoryoptioncomboname FROM _categoryoptioncomboname
INNER JOIN categoryoptioncombo ON categoryoptioncombo.categoryoptioncomboid = _categoryoptioncomboname.categoryoptioncomboid;



SELECT distinct (dataelement.dataelementid),dataelement.name
as deName, categories_categoryoptions.categoryoptionid, dataelementcategoryoption.name from dataelement
INNER JOIN categorycombos_categories ON categorycombos_categories.categorycomboid = dataelement.categorycomboid
INNER JOIN categories_categoryoptions ON categories_categoryoptions.categoryid = categorycombos_categories.categoryid
INNER JOIN dataelementcategoryoption ON dataelementcategoryoption.categoryoptionid = categories_categoryoptions.categoryoptionid
INNER JOIN datasetelement  ON  datasetelement.dataelementid = dataelement.dataelementid where dataelement.dataelementid in 
( select datasetelement.dataelementid from datasetelement where datasetelement.datasetid = 6191 )
order by dataelement.dataelementid


// categorycombo and categoryoptioncombo map

SELECT cc.uid as categorycombo_uid,cc.categorycomboid as categorycomboid,cc.name as categorycombo_name, _categoryoptioncomboname.categoryoptioncomboid, categoryoptioncombo.uid,  _categoryoptioncomboname.categoryoptioncomboname 
FROM _categoryoptioncomboname
INNER JOIN categoryoptioncombo ON categoryoptioncombo.categoryoptioncomboid = _categoryoptioncomboname.categoryoptioncomboid
INNER JOIN categorycombos_optioncombos coc_cc ON coc_cc.categoryoptioncomboid = categoryoptioncombo.categoryoptioncomboid
INNER JOIN categorycombo cc ON cc.categorycomboid = coc_cc.categorycomboid;



// final categorycombo name uid query

SELECT _categoryoptioncomboname.categoryoptioncomboid, categoryoptioncombo.uid,  
_categoryoptioncomboname.categoryoptioncomboname FROM _categoryoptioncomboname
INNER JOIN categoryoptioncombo ON categoryoptioncombo.categoryoptioncomboid = 
_categoryoptioncomboname.categoryoptioncomboid;

select * from categorycombos_optioncombos


select dse.*,ccombo.categoryoptioncomboid from datasetelement dse
INNER JOIN categorycombos_optioncombos ccombo on ccombo.categorycomboid = dse.categorycomboid
where dse.datasetid=6191


// dataelement-category-and combination


select de.dataelementid as dataElementID,de.uid as dataElementUID,de.name as dataElementName,cc.uid as categoryUID,
cc.name as categoryName,coc.categoryoptioncomboid as categoryoptioncomboid,coc.uid as categoryoptionUID,cocname.categoryoptioncomboname as categoryOptionComboName
from dataelement as de
inner join categorycombo as cc on cc.categorycomboid = de.categorycomboid
inner join categorycombos_optioncombos as cc_coc on cc_coc.categorycomboid = de.categorycomboid
inner join categoryoptioncombo as coc on coc.categoryoptioncomboid = cc_coc.categoryoptioncomboid
inner join _categoryoptioncomboname as cocname on coc.categoryoptioncomboid = cocname.categoryoptioncomboid
group by de.dataelementid,de.uid,cc.uid,de.name,cc.name,coc.categoryoptioncomboid ,coc.uid,cocname.categoryoptioncomboname
order by de.name,cc.name,cocname.categoryoptioncomboname

// catrgory-combo-and category-and option

SELECT cat_catoption.categoryid, cat_catoption.categoryoptionid, catCombo.categorycomboid,deCateOption.name
FROM public.categories_categoryoptions cat_catoption
INNER JOIN categorycombos_categories catCombo ON catCombo.categoryid = cat_catoption.categoryid
INNER JOIN dataelementcategoryoption deCateOption ON deCateOption.categoryoptionid = cat_catoption.categoryoptionid
where catCombo.categorycomboid in( 588773,52240, 588773);












// complusery_count_dataElements_for dataStatus app

select dse.datasetelementid from datasetelement dse
INNER JOIN categorycombos_optioncombos ccombo on ccombo.categorycomboid = dse.categorycomboid
where dse.datasetid='${datasetelementid}'


// Query for Levelwise OrgUnit

SELECT organisationunitid, organisationunituid, level, idlevel1, uidlevel1, 
       idlevel2, uidlevel2, idlevel3, uidlevel3, idlevel4, uidlevel4, 
       idlevel5, uidlevel5, idlevel6, uidlevel6, idlevel7, uidlevel7
  FROM _orgunitstructure;


SELECT organisationunit.organisationunitid, organisationunit.name, organisationunit.shortname, organisationunit.uid, organisationunit.code FROM organisationunit 
INNER JOIN _orgunitstructure ON _orgunitstructure.organisationunitid = organisationunit.organisationunitid
and _orgunitstructure.level = 4;




SELECT ou1.name, _orgunitstructure.idlevel1, _orgunitstructure.uidlevel1,  
ou2.name,_orgunitstructure.idlevel2, _orgunitstructure.uidlevel2, 
ou3.name,_orgunitstructure.idlevel3, _orgunitstructure.uidlevel3,
ou4.name,_orgunitstructure.idlevel4, _orgunitstructure.uidlevel4
FROM _orgunitstructure 
left JOIN organisationunit ou1 ON ou1.uid = _orgunitstructure.uidlevel1
left JOIN organisationunit ou2 ON ou2.uid = _orgunitstructure.uidlevel2
left JOIN organisationunit ou3 ON ou3.uid = _orgunitstructure.uidlevel3
left JOIN organisationunit ou4 ON ou4.uid = _orgunitstructure.uidlevel4
where level < 5
order by level;


select count(*) from _orgunitstructure
where level < 5


delete query for tracker data

// start
select * from trackedentityinstance;
delete from trackedentityinstance;

select * from trackedentityattributevalueaudit;
delete from trackedentityattributevalueaudit;

select * from trackedentityaudit;
delete from  trackedentityaudit;


select * from trackedentityattributevalue;
delete from  trackedentityattributevalue;

select * from programinstance; 
delete from programinstance; 

select * from programinstancecomments;
delete from programinstancecomments;


select * from programstageinstance;
delete from programstageinstance;

select * from trackedentitydatavalueaudit;
delete from trackedentitydatavalueaudit;

SELECT * FROM trackedentitydatavalue;
delete from trackedentitydatavalue;

// end

// orgUnit hierarchy Query

select
ou1.uid as uid1,max(ou1.name) as Level1,
ou2.uid as uid2,max(ou2.name) as Level2,
ou3.uid as uid3,max(ou3.name) as Level3,
ou4.uid as uid4,max(ou4.name) as Level4,
ou5.uid as uid5,max(ou5.name) as Level5,
ou6.uid as uid6,max(ou6.name) as Level6,
ou7.uid as uid7,max(ou7.name) as Level7,
ou8.uid as uid8,max(ou8.name) as Level8

from _orgunitstructure ous
inner join organisationunit ou1 on ou1.organisationunitid = ous.idlevel1
inner join organisationunit ou2 on ou2.organisationunitid = ous.idlevel2
inner join organisationunit ou3 on ou3.organisationunitid = ous.idlevel3
inner join organisationunit ou4 on ou4.organisationunitid = ous.idlevel4
inner join organisationunit ou5 on ou5.organisationunitid = ous.idlevel5
inner join organisationunit ou6 on ou6.organisationunitid = ous.idlevel6
inner join organisationunit ou7 on ou7.organisationunitid = ous.idlevel7
inner join organisationunit ou8 on ou8.organisationunitid = ous.idlevel8
group by ou1.uid,ou2.uid,ou3.uid,ou4.uid,ou5.uid,ou6.uid,ou7.uid,ou8.uid

// for all ou


select
ou1.uid as Level1uid1, ou1.organisationunitid, max(ou1.name) as Level1Name,
ou2.uid as Level2uid2, ou2.organisationunitid, max(ou2.name) as Level2Name,
ou3.uid as Level3uid3, ou3.organisationunitid, max(ou3.name) as Level3Name,
ou4.uid as Level4uid4, ou4.organisationunitid, max(ou4.name) as Level4Name,
ou5.uid as Level5uid5, ou5.organisationunitid, max(ou5.name) as Level5Name,
ou6.uid as Level6uid6, ou6.organisationunitid, max(ou6.name) as Level6Name
from _orgunitstructure ous
LEFT  JOIN organisationunit ou1 on ou1.organisationunitid = ous.idlevel1
LEFT  join organisationunit ou2 on ou2.organisationunitid = ous.idlevel2
LEFT  join organisationunit ou3 on ou3.organisationunitid = ous.idlevel3
LEFT  join organisationunit ou4 on ou4.organisationunitid = ous.idlevel4
LEFT  join organisationunit ou5 on ou5.organisationunitid = ous.idlevel5
LEFT  join organisationunit ou6 on ou6.organisationunitid = ous.idlevel6
group by ou1.uid,ou1.organisationunitid,ou2.uid,ou2.organisationunitid,ou3.uid,ou3.organisationunitid,
ou4.uid,ou4.organisationunitid,ou5.uid,ou5.organisationunitid,ou6.uid,ou6.organisationunitid;

// for all ou with code
// Level wise org unit hierarchy with id,uid,name,code

select
ou1.uid as Level1uid1, ou1.organisationunitid as ou1Id, max(ou1.code) as Level1Code, max(ou1.name) as Level1Name,
ou2.uid as Level2uid2, ou2.organisationunitid as ou2Id, max(ou2.code) as Level2Code, max(ou2.name) as Level2Name,
ou3.uid as Level3uid3, ou3.organisationunitid as ou3Id, max(ou3.code) as Level3Code, max(ou3.name) as Level3Name,
ou4.uid as Level4uid4, ou4.organisationunitid as ou4Id, max(ou4.code) as Level4Code, max(ou4.name) as Level4Name,
ou5.uid as Level5uid5, ou5.organisationunitid as ou5Id, max(ou5.code) as Level5Code, max(ou5.name) as Level5Name,
ou6.uid as Level6uid6, ou6.organisationunitid as ou6Id, max(ou6.code) as Level6Code, max(ou6.name) as Level6Name
from _orgunitstructure ous
LEFT  JOIN organisationunit ou1 on ou1.organisationunitid = ous.idlevel1
LEFT  join organisationunit ou2 on ou2.organisationunitid = ous.idlevel2
LEFT  join organisationunit ou3 on ou3.organisationunitid = ous.idlevel3
LEFT  join organisationunit ou4 on ou4.organisationunitid = ous.idlevel4
LEFT  join organisationunit ou5 on ou5.organisationunitid = ous.idlevel5
LEFT  join organisationunit ou6 on ou6.organisationunitid = ous.idlevel6
group by ou1.uid,ou1.organisationunitid,ou2.uid,ou2.organisationunitid,ou3.uid,ou3.organisationunitid,
ou4.uid,ou4.organisationunitid,ou5.uid,ou5.organisationunitid,ou6.uid,ou6.organisationunitid;

// for AES OrganisationunitHierarchylevel


select
ou1.uid as Level1uid1, ou1.organisationunitid as ou1Id, max(ou1.code) as Level1Code, max(ou1.name) as Level1Name,
ou2.uid as Level2uid2, ou2.organisationunitid as ou2Id, max(ou2.code) as Level2Code, max(ou2.name) as Level2Name,
ou3.uid as Level3uid3, ou3.organisationunitid as ou3Id, max(ou3.code) as Level3Code, max(ou3.name) as Level3Name,
ou4.uid as Level4uid4, ou4.organisationunitid as ou4Id, max(ou4.code) as Level4Code, max(ou4.name) as Level4Name,
ou5.uid as Level5uid5, ou5.organisationunitid as ou5Id, max(ou5.code) as Level5Code, max(ou5.name) as Level5Name,
ou6.uid as Level6uid6, ou6.organisationunitid as ou6Id, max(ou6.code) as Level6Code, max(ou6.name) as Level6Name,
ou7.uid as Level7uid7, ou7.organisationunitid as ou7Id, max(ou7.code) as Level7Code, max(ou7.name) as Level7Name, max(ou7.coordinates) as Level7coordinates
from _orgunitstructure ous
LEFT  JOIN organisationunit ou1 on ou1.organisationunitid = ous.idlevel1
LEFT  join organisationunit ou2 on ou2.organisationunitid = ous.idlevel2
LEFT  join organisationunit ou3 on ou3.organisationunitid = ous.idlevel3
LEFT  join organisationunit ou4 on ou4.organisationunitid = ous.idlevel4
LEFT  join organisationunit ou5 on ou5.organisationunitid = ous.idlevel5
LEFT  join organisationunit ou6 on ou6.organisationunitid = ous.idlevel6
LEFT  join organisationunit ou7 on ou7.organisationunitid = ous.idlevel7
group by ou1.uid,ou1.organisationunitid,ou2.uid,ou2.organisationunitid,ou3.uid,ou3.organisationunitid,
ou4.uid,ou4.organisationunitid,ou5.uid,ou5.organisationunitid,ou6.uid,ou6.organisationunitid,ou7.uid,ou7.organisationunitid;



select
ou1.uid as Level1uid1, ou1.organisationunitid as ou1Id, max(ou1.code) as Level1Code, max(ou1.name) as Level1Name,
ou2.uid as Level2uid2, ou2.organisationunitid as ou2Id, max(ou2.code) as Level2Code, max(ou2.name) as Level2Name,
ou3.uid as Level3uid3, ou3.organisationunitid as ou3Id, max(ou3.code) as Level3Code, max(ou3.name) as Level3Name,
ou4.uid as Level4uid4, ou4.organisationunitid as ou4Id, max(ou4.code) as Level4Code, max(ou4.name) as Level4Name,
ou5.uid as Level5uid5, ou5.organisationunitid as ou5Id, max(ou5.code) as Level5Code, max(ou5.name) as Level5Name,
ou6.uid as Level6uid6, ou6.organisationunitid as ou6Id, max(ou6.code) as Level6Code, max(ou6.name) as Level6Name,
ou7.uid as Level7uid7, ou7.organisationunitid as ou7Id, max(ou7.code) as Level7Code, max(ou7.name) as Level7Name,
ou8.uid as Level8uid8, ou8.organisationunitid as ou8Id, max(ou8.code) as Level8Code, max(ou8.name) as Level8Name
from _orgunitstructure ous
LEFT  JOIN organisationunit ou1 on ou1.organisationunitid = ous.idlevel1
LEFT  join organisationunit ou2 on ou2.organisationunitid = ous.idlevel2
LEFT  join organisationunit ou3 on ou3.organisationunitid = ous.idlevel3
LEFT  join organisationunit ou4 on ou4.organisationunitid = ous.idlevel4
LEFT  join organisationunit ou5 on ou5.organisationunitid = ous.idlevel5
LEFT  join organisationunit ou6 on ou6.organisationunitid = ous.idlevel6
LEFT  join organisationunit ou7 on ou7.organisationunitid = ous.idlevel7
LEFT  join organisationunit ou8 on ou8.organisationunitid = ous.idlevel8

group by ou1.uid,ou1.organisationunitid,ou2.uid,ou2.organisationunitid,ou3.uid,ou3.organisationunitid,
ou4.uid,ou4.organisationunitid,ou5.uid,ou5.organisationunitid,ou6.uid,ou6.organisationunitid,
ou7.uid,ou7.organisationunitid,ou8.uid,ou8.organisationunitid;



select
ou1.uid as Level1uid1, ou1.organisationunitid as ou1Id, max(ou1.code) as Level1Code, max(ou1.name) as Level1Name,
ou2.uid as Level2uid2, ou2.organisationunitid as ou2Id, max(ou2.code) as Level2Code, max(ou2.name) as Level2Name,
ou3.uid as Level3uid3, ou3.organisationunitid as ou3Id, max(ou3.code) as Level3Code, max(ou3.name) as Level3Name,
ou4.uid as Level4uid4, ou4.organisationunitid as ou4Id, max(ou4.code) as Level4Code, max(ou4.name) as Level4Name,
ou5.uid as Level5uid5, ou5.organisationunitid as ou5Id, max(ou5.code) as Level5Code, max(ou5.name) as Level5Name,
ou6.uid as Level6uid6, ou6.organisationunitid as ou6Id, max(ou6.code) as Level6Code, max(ou6.name) as Level6Name,
ou7.uid as Level7uid7, ou7.organisationunitid as ou7Id, max(ou7.code) as Level7Code, max(ou7.name) as Level7Name
from _orgunitstructure ous
LEFT  JOIN organisationunit ou1 on ou1.organisationunitid = ous.idlevel1
LEFT  join organisationunit ou2 on ou2.organisationunitid = ous.idlevel2
LEFT  join organisationunit ou3 on ou3.organisationunitid = ous.idlevel3
LEFT  join organisationunit ou4 on ou4.organisationunitid = ous.idlevel4
LEFT  join organisationunit ou5 on ou5.organisationunitid = ous.idlevel5
LEFT  join organisationunit ou6 on ou6.organisationunitid = ous.idlevel6
LEFT  join organisationunit ou7 on ou7.organisationunitid = ous.idlevel7


group by ou1.uid,ou1.organisationunitid,ou2.uid,ou2.organisationunitid,ou3.uid,ou3.organisationunitid,
ou4.uid,ou4.organisationunitid,ou5.uid,ou5.organisationunitid,ou6.uid,ou6.organisationunitid,
ou7.uid,ou7.organisationunitid;




SELECT organisationunitid, orgunitgroupid
  FROM public.orgunitgroupmembers;






//
select
ou1.uid as uid1,max(ou1.name) as Level1,
ou2.uid as uid2,max(ou2.name) as Level2,
ou3.uid as uid3,max(ou3.name) as Level3,
ou4.uid as uid4,max(ou4.name) as Level4,
ou5.uid as uid5,max(ou5.name) as Level5,
ou6.uid as uid6,max(ou6.name) as Level6,
ou7.uid as uid7,max(ou7.name) as Level7,
ou8.uid as uid8,max(ou8.name) as Level8,
ou8.code as villageCode
from _orgunitstructure ous
inner join organisationunit ou1 on ou1.organisationunitid = ous.idlevel1
inner join organisationunit ou2 on ou2.organisationunitid = ous.idlevel2
inner join organisationunit ou3 on ou3.organisationunitid = ous.idlevel3
inner join organisationunit ou4 on ou4.organisationunitid = ous.idlevel4
inner join organisationunit ou5 on ou5.organisationunitid = ous.idlevel5
inner join organisationunit ou6 on ou6.organisationunitid = ous.idlevel6
inner join organisationunit ou7 on ou7.organisationunitid = ous.idlevel7
inner join organisationunit ou8 on ou8.organisationunitid = ous.idlevel8
where ou4.uid in ('I5thpfRseUa' )
group by ou1.uid,ou2.uid,ou3.uid,ou4.uid,ou5.uid,ou6.uid,ou7.uid,ou8.uid,ou8.code;


select
ou1.uid as uid1,max(ou1.name) as Level1,
ou2.uid as uid2,max(ou2.name) as Level2,
ou3.uid as uid3,max(ou3.name) as Level3,
ou4.uid as uid4,max(ou4.name) as Level4,
ou5.uid as uid5,max(ou5.name) as Level5,
ou6.uid as uid6,max(ou6.name) as Level6

from _orgunitstructure ous
inner join organisationunit ou1 on ou1.organisationunitid = ous.idlevel1
inner join organisationunit ou2 on ou2.organisationunitid = ous.idlevel2
inner join organisationunit ou3 on ou3.organisationunitid = ous.idlevel3
inner join organisationunit ou4 on ou4.organisationunitid = ous.idlevel4
inner join organisationunit ou5 on ou5.organisationunitid = ous.idlevel5
inner join organisationunit ou6 on ou6.organisationunitid = ous.idlevel6

where ou4.uid in ('I5thpfRseUa' )
group by ou1.uid,ou2.uid,ou3.uid,ou4.uid,ou5.uid,ou6.uid;




//

select
ou5.uid as uid5, max(ou5.code) as level5Code, max(ou5.name) as Level5,
ou6.uid as uid6, max(ou6.code) as level6Code, max(ou6.name) as Level6,
ou7.uid as uid7, max(ou7.code) as level7Code, max(ou7.name) as Level7
from _orgunitstructure ous
inner join organisationunit ou3 on ou3.organisationunitid = ous.idlevel3
inner join organisationunit ou5 on ou5.organisationunitid = ous.idlevel5
inner join organisationunit ou6 on ou6.organisationunitid = ous.idlevel6
inner join organisationunit ou7 on ou7.organisationunitid = ous.idlevel7
where ou3.uid in ('btqqHOcHenl' )
group by ou5.uid,ou6.uid,ou7.uid;


// orgUnit hierarchy Query with code uid and name

select
ou1.uid as uid1,max(ou1.name) as Level1,ou1.code as code1,
ou2.uid as uid2,max(ou2.name) as Level2 , ou2.code as code2,
ou3.uid as uid3,max(ou3.name) as Level3 , ou3.code as code3,
ou4.uid as uid4,max(ou4.name) as Level4, ou4.code as code4,
ou5.uid as uid5,max(ou5.name) as Level5, ou5.code as code5,
ou6.uid as uid6,max(ou6.name) as Level6, ou6.code as code6
from _orgunitstructure ous
inner join organisationunit ou1 on ou1.organisationunitid = ous.idlevel1
inner join organisationunit ou2 on ou2.organisationunitid = ous.idlevel2
inner join organisationunit ou3 on ou3.organisationunitid = ous.idlevel3
inner join organisationunit ou4 on ou4.organisationunitid = ous.idlevel4
inner join organisationunit ou5 on ou5.organisationunitid = ous.idlevel5
inner join organisationunit ou6 on ou6.organisationunitid = ous.idlevel6
where ou2.uid in ('LpfSRXWPPRz' )
group by ou1.uid,ou1.code,ou2.uid,ou2.code,ou3.uid,ou3.code,ou4.uid,ou4.code,ou5.uid,ou5.code,ou6.uid,ou6.code;











// up to level_9

select
ou1.uid as uid1,max(ou1.name) as Level1,
ou2.uid as uid2,max(ou2.name) as Level2,
ou3.uid as uid3,max(ou3.name) as Level3,
ou4.uid as uid4,max(ou4.name) as Level4,
ou5.uid as uid5,max(ou5.name) as Level5,
ou6.uid as uid6,max(ou6.name) as Level6,
ou7.uid as uid7,max(ou7.name) as Level7,
ou8.uid as uid8,max(ou8.name) as Level8,
ou9.uid as uid9,max(ou9.name) as Level9

from _orgunitstructure ous
inner join organisationunit ou1 on ou1.organisationunitid = ous.idlevel1
inner join organisationunit ou2 on ou2.organisationunitid = ous.idlevel2
inner join organisationunit ou3 on ou3.organisationunitid = ous.idlevel3
inner join organisationunit ou4 on ou4.organisationunitid = ous.idlevel4
inner join organisationunit ou5 on ou5.organisationunitid = ous.idlevel5
inner join organisationunit ou6 on ou6.organisationunitid = ous.idlevel6
inner join organisationunit ou7 on ou7.organisationunitid = ous.idlevel7
inner join organisationunit ou8 on ou8.organisationunitid = ous.idlevel8
inner join organisationunit ou9 on ou9.organisationunitid = ous.idlevel9
group by ou1.uid,ou2.uid,ou3.uid,ou4.uid,ou5.uid,ou6.uid,ou7.uid,ou8.uid,ou9.uid;





select

ou3.uid as uid3,max(ou3.name) as Level3,
ou4.uid as uid4,max(ou4.name) as Level4,
ou5.uid as uid5,max(ou5.name) as Level5,
ou6.uid as uid6,max(ou6.name) as Level6,
ou7.uid as uid7,max(ou7.name) as Level7,
ou8.uid as uid8,max(ou8.name) as Level8,
ou9.uid as uid9,max(ou9.name) as Level9

from _orgunitstructure ous

inner join organisationunit ou3 on ou3.organisationunitid = ous.idlevel3
inner join organisationunit ou4 on ou4.organisationunitid = ous.idlevel4
inner join organisationunit ou5 on ou5.organisationunitid = ous.idlevel5
inner join organisationunit ou6 on ou6.organisationunitid = ous.idlevel6
inner join organisationunit ou7 on ou7.organisationunitid = ous.idlevel7
inner join organisationunit ou8 on ou8.organisationunitid = ous.idlevel8
inner join organisationunit ou9 on ou9.organisationunitid = ous.idlevel9
where ou3.uid in ('SNQGLnYiMBE' )
group by ou3.uid,ou4.uid,ou5.uid,ou6.uid,ou7.uid,ou8.uid,ou9.uid;



// orgUnit herarchy by uid and complete path_name

select
ous.organisationunituid as orgunituid,
CONCAT (ou2.name,'/',ou3.name,'/',ou4.name ,'/',ou5.name ,'/',ou6.name) as heirarchy   
from _orgunitstructure ous
LEFT join organisationunit ou2 on ou2.organisationunitid = ous.idlevel2
LEFT join organisationunit ou3 on ou3.organisationunitid = ous.idlevel3
LEFT join organisationunit ou4 on ou4.organisationunitid = ous.idlevel4
LEFT join organisationunit ou5 on ou5.organisationunitid = ous.idlevel5
LEFT join organisationunit ou6 on ou6.organisationunitid = ous.idlevel6
group by ous.organisationunituid,ou2.name,ou3.name,ou4.name,ou5.name,ou6.uid,ou6.name;




















select
ou1.uid as uid1,max(ou1.name) as Level1,
ou2.uid as uid2,max(ou2.name) as Level2,
ou3.uid as uid3,max(ou3.name) as Level3
from _orgunitstructure ous
inner join organisationunit ou1 on ou1.organisationunitid = ous.idlevel1
inner join organisationunit ou2 on ou2.organisationunitid = ous.idlevel2
inner join organisationunit ou3 on ou3.organisationunitid = ous.idlevel3
group by ou1.uid,ou2.uid,ou3.uid;


disable/ebnable key in postgres sql

BEGIN;
ALTER TABLE b DISABLE TRIGGER ALL;
-- now the RI over table b is disabled
ALTER TABLE b ENABLE TRIGGER ALL;
COMMIT;


select coc.categoryoptioncomboid from categoryoptioncombo coc 
            inner join categorycombos_optioncombos cco on coc.categoryoptioncomboid=cco.categoryoptioncomboid
            inner join categorycombo cc on cco.categorycomboid=cc.categorycomboid where cc.name='default';



select pg.name,pg.programid,psde.programstageid, ps.name, count(psde.dataelementid) from programstagedataelement psde
INNER JOIN programstage ps ON ps.programstageid = psde.programstageid
INNER JOIN program pg ON pg.programid = ps.programid
group by pg.name,pg.programid,psde.programstageid,ps.name;



//Level wise org unit hierarchy with coordinates

SELECT
ou1.uid as Level1uid1, ou1.organisationunitid as ou1Id, max(ou1.code) as Level1Code, max(ou1.name) as Level1Name,
ou2.uid as Level2uid2, ou2.organisationunitid as ou2Id, max(ou2.code) as Level2Code, max(ou2.name) as Level2Name,
ou3.uid as Level3uid3, ou3.organisationunitid as ou3Id, max(ou3.code) as Level3Code, max(ou3.name) as Level3Name,
ou4.uid as Level4uid4, ou4.organisationunitid as ou4Id, max(ou4.code) as Level4Code, max(ou4.name) as Level4Name, max(ou4.featuretype) as Level4Featuretype, max(ou4.coordinates) as Level4Coordinates

from _orgunitstructure ous
LEFT  JOIN organisationunit ou1 on ou1.organisationunitid = ous.idlevel1
LEFT  join organisationunit ou2 on ou2.organisationunitid = ous.idlevel2
LEFT  join organisationunit ou3 on ou3.organisationunitid = ous.idlevel3
LEFT  join organisationunit ou4 on ou4.organisationunitid = ous.idlevel4

group by ou1.uid,ou1.organisationunitid,ou2.uid,ou2.organisationunitid,ou3.uid,ou3.organisationunitid,
ou4.uid,ou4.organisationunitid;





// link for User Details from API

api/users.xml?fields=*,userCredentials[name,lastLogin]&filter=userCredentials.lastLogin:le:2017-06-02&paging=false




Git Command

//add for logpaths
git config core.longpaths true

// set user name and e-mail in git bush
git config --global user.email "you@example.com"
git config --global user.name "Your Name"

git config --global user.email "mithilesh.hisp@gmail.com"
git config --global user.name "Mithilesh Kumar Thakur"

https://github.com/dhis2/dhis2-core
https://github.com/hispindia/dhis2-core

$ git branch
$ git -b branch node  // for creat branch
$ git checkout -b node // for checkout branch


git clone https://github.com/hispindia/dhis2-core.git    // for clone to local machine
git checkout 2.23
git branch // to show branch
git branch --all // to show all branchs
git checkout -b dhis2.23_in // creating new branch
Switched to a new branch 'dhis2.23_in'
git push origin dhis2.23_in // push code to new branch
git pull // for updating branch which are forked forks 

git status // for status
git add main.js package.json // add files
git commit -a -m "initial for node" // -a used for commit modified files
git push origin dhis2.23_in // after commit push to that branch


$ git clone https://github.com/hispindia/dhis-core-2.23.git // checkout branch

git merge https://github.com/dhis2/dhis2-core/tree/2.23
git subtree add --prefix=rails git://github.com/rails/rails.git master

// for new branch

url for core
https://github.com/dhis2/dhis2-core.git // upstream
url for hispIndia
https://github.com/hispindia/dhis2-Core.git

// for merging with golbal branch to hispindia branch
git branch
git checkout master
git remote -v

// for add upstream
git remote add upstream https://github.com/dhis2/dhis2-core.git
git fetch upstream master
git merge upstream/master
git push origin master

// for remove upstream

git remote rm upstream

// for tracker capture and its builds

git remote add upstream https://github.com/dhis2/tracker-capture-app.git
// for builds
git remote add upstream https://github.com/d2-ci/tracker-capture-app

// for event-capture and its builds
git remote add upstream https://github.com/dhis2/event-capture-app
//for buids
git remote add upstream https://github.com/d2-ci/event-capture-app





// for data-admin app

git remote add upstream https://github.com/dhis2/data-administration-app
git remote add upstream https://github.com/d2-ci/data-administration-app

// for dashboard app

git remote add upstream https://github.com/dhis2/data-administration-app
git remote add upstream https://github.com/d2-ci/data-administration-app


// for user-profile-app 

git remote add upstream https://github.com/dhis2/user-profile-app.git
git remote add upstream https://github.com/d2-ci/user-profile-app.git


// for interpretation-app

git remote add upstream https://github.com/dhis2/interpretation-app.git
git remote add upstream https://github.com/d2-ci/interpretation-app.git


// for data-quality-app

git remote add upstream https://github.com/dhis2/data-quality-app // app
git remote add upstream https://github.com/d2-ci/data-quality-app // build


// for maintenance-app
git remote add upstream https://github.com/dhis2/maintenance-app.git
git remote add upstream https://github.com/d2-ci/maintenance-app // build


// commands for reset the branch

$ git reset --hard HEAD~1
$ git push origin master --force




for merge in local
// https://github.com/hispindia/dhis-launchpad-code/tree/dhis2.20_in
// for haryana 2.20 take referance from dhis2.20_in
git branch HRY-2.20
git checkout HRY-2.20
git push origin HRY-2.20


git merge origin/destination-branch origin/source-branch
git merge origin/searo-dahboard-2.21 origin/2.21

git merge origin/MSF-2.24   origin/2.24 -m "Updete MSF 2.24 Branch"

git push origin MSF-2.24

git worktree add -f /e/gitHub_source_code/interpretation-app/builds/uphmis_v30 UPHMIS-v30

git worktree add /e/scm/git_ippf_2.23 IPPF-2.23
git merge origin/IPPF-2.23    origin/2.23 -m "Updete IPPF 2.23 Branch"
git push origin IPPF-2.23

git merge origin/PBF-2.25    origin/2.25 -m "Merge PBF 2.25 Branch with parent branch"
git push origin PBF-2.25


$ git worktree add /e/scm/git_trunk master

// for sain_lucia
$ git worktree add /e/scm/git_saint_lucia_2.24 sluhmis2.24

git merge origin/sluhmis2.24	origin/2.24 -m "9800:update and Merge sluhmis2.24 Branch with parent branch"
git push origin sluhmis2.24


$ git worktree add /e/scm/git_nie_2.25 NIE-2.25
git merge origin/NIE-2.25    origin/2.25 -m "9772:Merge NIE-2.25 Branch with parent branch"
git push origin NIE-2.25

$ git worktree add /e/scm/git_ivb_2.25 IVB-2.25
git merge origin/IVB-2.25    origin/2.25 -m "Merge and update IVB-2.25 Branch with parent branch"



git worktree add /e/scm/git_uphmis_2.25 UPHMIS-2.25
git merge origin/UPHMIS-2.25    origin/2.25 -m "Merge and update UPHMIS-2.25 Branch with parent branch"
git push origin UPHMIS-2.25

// for PBF-2.26
git branch PBF-2.26 // for create new branch
git checkout PBF-2.26
git push origin PBF-2.26
git worktree add /e/scm/git_pbf_2.26 PBF-2.26
git merge origin/PBF-2.26 origin/2.26 -m "Merge and update PBF-2.26 Branch with parent branch"
git push origin PBF-2.26



// for TIBET-2.26
git branch TIBET-2.26 // for create new branch
git checkout TIBET-2.26
git push origin TIBET-2.26
git worktree add /e/scm/git_tibet_2.26 TIBET-2.26
git merge origin/TIBET-2.26 origin/2.26 -m "Merge and update TIBET-2.26 Branch with parent branch"
git push origin TIBET-2.26


// for INPART-2.26
git branch INPART-2.26 // for create new branch
git checkout INPART-2.26
git push origin INPART-2.26
# git worktree add /e/scm/git_tibet_2.26 TIBET-2.26
git merge origin/INPART-2.26 origin/2.26 -m "Merge and update INPART-2.26 Branch with parent branch"
git push origin INPART-2.26


git worktree add /e/scm/git_aes_2.26 AES
git merge origin/AES origin/2.26 -m "Merge and update AES Branch with parent branch"
git push origin AES



// for SUAAHARA2-2.26
git branch SUAAHARA2-2.26 // for create new branch
git checkout SUAAHARA2-2.26
git push origin SUAAHARA2-2.26
# git worktree add /e/scm/git_suaahara2_2.26 SUAAHARA2-2.26
git merge origin/SUAAHARA2-2.26 origin/2.26 -m "Merge and update SUAAHARA2-2.26 Branch with parent branch"
git push origin SUAAHARA2-2.26





// for MSF-2.27
git branch MSF-2.27 // for create new branch
git checkout MSF-2.27
git push origin MSF-2.27
# git worktree add /e/scm/git_tibet_2.26 TIBET-2.26
git merge origin/MSF-2.27 origin/2.27 -m "Merge and update MSF-2.27 Branch with parent branch"
git push origin MSF-2.27


// for PLAN-2.27
git branch PLAN-2.27 // for create new branch
git checkout PLAN-2.27
git push origin PLAN-2.27
git worktree add /e/scm/git_plan_2.27 PLAN-2.27
git merge origin/PLAN-2.27 origin/2.27 -m "Merge and update PLAN-2.27 Branch with parent branch"
git push origin PLAN-2.27



// for SAVE-CHILD-2.27
git branch SAVE-CHILD-2.27 // for create new branch
git checkout SAVE-CHILD-2.27
git push origin SAVE-CHILD-2.27
git worktree add /e/scm/git_save_child_2.27 SAVE-CHILD-2.27
git merge origin/SAVE-CHILD-2.27 origin/2.27 -m "Merge and update SAVE-CHILD-2.27 Branch with parent branch"
git push origin SAVE-CHILD-2.27

// for STATE-2.27
git branch STATE-2.27 // for create new branch
git checkout STATE-2.27
git push origin STATE-2.27
git worktree add /e/scm/git_state_2.27 STATE-2.27
git merge origin/STATE-2.27 origin/2.27 -m "Merge and update STATE-2.27 Branch with parent branch"
git push origin STATE-2.27


// for MH_STATE-2.27

git checkout MH_STATE-2.27
git push origin MH_STATE-2.27
git worktree add /e/scm/git_mh_2.27 MH_STATE-2.27
git merge origin/MH_STATE-2.27 origin/STATE-2.27 -m "Merge and update MH_STATE-2.27 Branch with STATE-2.27 branch"
git push origin MH_STATE-2.27

git branch ODISHA_STATE-2.27 // for create new branch for orisha 2.27
git checkout ODISHA_STATE-2.27
git push origin ODISHA_STATE-2.27
git worktree add /e/scm/git_odisha_2.27 ODISHA_STATE-2.27
git merge origin/ODISHA_STATE-2.27 origin/STATE-2.27 -m "Merge and update ODISHA_STATE-2.27 Branch with STATE-2.27 branch"
git push origin ODISHA_STATE-2.27


git worktree add /e/scm/git_bihar_2.27 BR_STATE-2.27
git merge origin/BR_STATE-2.27 origin/STATE-2.27 -m "Merge and update BR_STATE-2.27 Branch with STATE-2.27 branch"
git push origin BR_STATE-2.27


//SUAAHARA2-2.27
git branch SUAAHARA2-2.27 // for create new branch
git checkout SUAAHARA2-2.27
git push origin SUAAHARA2-2.27
git worktree add /e/scm/git_suaahara2_2.27 SUAAHARA2-2.27
git merge origin/SUAAHARA2-2.27 origin/2.27 -m "Merge and update SUAAHARA2-2.27 Branch with parent branch"
git push origin SUAAHARA2-2.27

git pull origin SUAAHARA2-2.27


// for PBF-2.27
git branch PBF-2.27 // for create new branch
git checkout PBF-2.27
git push origin PBF-2.27
git worktree add /e/scm/git_pbf_2.27 PBF-2.27
git merge origin/PBF-2.27 origin/2.27 -m "Merge and update PBF-2.27 Branch with parent branch"
git push origin PBF-2.27


// for TIBET-2.27
git branch TIBET-2.27 // for create new branch
git checkout TIBET-2.27
git push origin TIBET-2.27
git worktree add /e/scm/git_tibet_2.27 TIBET-2.27
git merge origin/TIBET-2.27 origin/2.27 -m "Merge and update TIBET-2.27 Branch with parent branch"
git push origin TIBET-2.27


// for IPPF-2.27
git branch IPPF-2.27 // for create new branch
git checkout IPPF-2.27
git push origin IPPF-2.27
git worktree add /e/scm/git_ippf_2.27 IPPF-2.27
git merge origin/IPPF-2.27 origin/2.27 -m "Merge and update IPPF-2.27 Branch with parent branch"
git push origin IPPF-2.27




// for INPART-2.28
git branch INPART-2.28 // for create new branch
git checkout INPART-2.28
git push origin INPART-2.28
git worktree add /e/scm/git_inpart_2.28 INPART-2.28
git merge origin/INPART-2.28 origin/2.28 -m "Merge and update INPART-2.28 Branch with parent branch"
git push origin INPART-2.28


// for INTPART-KHERA-2.28
git branch INTPART-KHERA-2.28 // for create new branch
git checkout INTPART-KHERA-2.28
git push origin INTPART-KHERA-2.28
git pull origin INTPART-KHERA-2.28
git worktree add /e/scm/git_intart_khera_2.28 INTPART-KHERA-2.28
git merge origin/INTPART-KHERA-2.28 origin/INPART-2.28 -m "Merge and update INTPART-KHERA-2.28 Branch with parent branch"
git push origin INTPART-KHERA-2.28


// for ICMR-2.28
git branch ICMR-2.28 // for create new branch
git checkout ICMR-2.28
git push origin ICMR-2.28
git worktree add /e/scm/git_icmr_2.28 ICMR-2.28
git merge origin/ICMR-2.28 origin/2.28 -m "Merge and update ICMR-2.28 Branch with parent branch"
git push origin ICMR-2.28


// for ICMR-HEARING-2.28
git branch ICMR-HEARING-2.28 // for create new branch
git checkout ICMR-HEARING-2.28
git push origin ICMR-HEARING-2.28
git worktree add /e/scm/git_icmr_hearing_2.28 ICMR-HEARING-2.28
git merge origin/ICMR-HEARING-2.28 origin/2.28 -m "Merge and update ICMR-HEARING-2.28 Branch with parent branch"
git push origin ICMR-HEARING-2.28




// for ICMR-LEP-2.28
git branch ICMR-LEP-2.28 // for create new branch
git checkout ICMR-LEP-2.28
git push origin ICMR-LEP-2.28
git worktree add /e/scm/git_icmr_lep_2.28 ICMR-LEP-2.28
git merge origin/ICMR-LEP-2.28 origin/2.28 -m "Merge and update ICMR-LEP-2.28 Branch with parent branch"
git push origin ICMR-LEP-2.28





// for LIBIA-2.29
git branch LIBIA-2.29 // for create new branch
git checkout LIBIA-2.29
git push origin LIBIA-2.29
git worktree add /e/scm/git_libia_2.29 LIBIA-2.29
git pull origin LIBIA-2.29
git merge origin/LIBIA-2.29 origin/2.29 -m "Merge and update LIBIA-2.29 Branch with parent branch"
git push origin LIBIA-2.29


// for PLAN-2.29
git branch PLAN-2.29 // for create new branch
git checkout PLAN-2.29
git push origin PLAN-2.29
git worktree add /e/scm/git_plan_2.29 PLAN-2.29
git merge origin/PLAN-2.29 origin/2.29 -m "Merge and update PLAN-2.29 Branch with parent branch"
git push origin PLAN-2.29


// for ICMR-AMR-2.29
git branch ICMR-AMR-2.29 // for create new branch
git checkout ICMR-AMR-2.29
git push origin ICMR-AMR-2.29
git worktree add /e/scm/git_icmr_amr_2.29 ICMR-AMR-2.29
git merge origin/ICMR-AMR-2.29 origin/2.29 -m "Merge and update ICMR-AMR-2.29 Branch with parent branch"
git push origin ICMR-AMR-2.29




// for LIBYA-2.30
git branch LIBYA-2.30 // for create new branch
git checkout LIBYA-2.30
git push origin LIBYA-2.30
git worktree add /e/scm/git_libya_2.30 LIBYA-2.30
git pull origin LIBYA-2.30
git merge origin/LIBYA-2.30 origin/2.30 -m "Merge and update LIBYA-2.30 Branch with parent branch"
git push origin LIBYA-2.30


// for UPHMIS-2.30
git branch UPHMIS-2.30 // for create new branch
git checkout UPHMIS-2.30
git push origin UPHMIS-2.30
git worktree add /e/scm/git_uphmis_2.30 UPHMIS-2.30
git pull origin UPHMIS-2.30
git merge origin/UPHMIS-2.30 origin/2.30 -m "Merge and update UPHMIS-2.30 Branch with parent branch"
git push origin UPHMIS-2.30


// for INTPART-2.30
git branch INTPART-2.30 // for create new branch
git checkout INTPART-2.30
git push origin INTPART-2.30
git pull origin INTPART-2.30
git worktree add /e/scm/git_intpart_2.30 INTPART-2.30
git merge origin/INTPART-2.30 origin/2.30 -m "Merge and update INTPART-2.30 Branch with parent branch"
git push origin INTPART-2.30


// for PUNJAB-2.30
git branch PUNJAB-2.30 // for create new branch
git checkout PUNJAB-2.30
git push origin PUNJAB-2.30
git pull origin PUNJAB-2.30
git worktree add /e/scm/git_punjab_2.30 PUNJAB-2.30
git merge origin/PUNJAB-2.30 origin/2.30 -m "Merge and update PUNJAB-2.30 Branch with parent branch"
git push origin PUNJAB-2.30



// for Nepa-Hmis-2.30

git worktree add /e/scm/git_nepal_hmis_2.30 nepal
git merge origin/nepal origin/2.30 -m "Merge and update nepal Branch with parent branch"
git push origin nepal





$ git worktree add /e/scm/git_plan_2.26 PLAN-2.26
git merge origin/PLAN-2.26   origin/2.26 -m "Merge PLAN-2.26 Branch with parent branch"
git push origin PLAN-2.26


$ git worktree add /e/scm/git_ivb_2.21 IVB-2.21


git worktree add /e/scm/git_aes_2.26 AES-2.26
git merge origin/AES   origin/2.26 -m "Merge AES Branch with parent branch"
git push origin AES


git merge origin/AES   origin/v26 -m "Merge AES Tracker Capture App with parent branch"
git push origin AES



$ git worktree add /e/scm/gitHub_source_code/msf_tracker_capture_2.26 MSF-2.26
git merge origin/MSF-2.26   origin/v26 -m "Merge MSF Tracker Capture App with parent branch"


$ git worktree add /e/scm/gitHub_source_code/inpart_tracker_capture_v2.26 INPART-2.26



// for tracker capture


git branch TIBET-2.26 // for create new branch for tracker capture
git checkout TIBET-2.26
git push origin TIBET-2.26
git worktree add /e/scm/gitHub_source_code/tibet_tracker_capture_2.26 TIBET-2.26
git merge origin/TIBET-2.26   origin/v26 -m "Merge TIBET Tracker Capture App with parent branch"

git branch MSF-2.27 // for create new branch for tracker capture
git checkout MSF-2.27
git push origin MSF-2.27
git worktree add /e/gitHub_source_code/msf_tracker_capture_2.27 MSF-2.27
git merge origin/MSF-2.27   origin/v27 -m "Merge MSF Tracker Capture App with parent branch"
git push origin MSF-2.27


git branch PLAN-v27 // for create new branch for tracker capture
git checkout PLAN-v27
git push origin PLAN-v27
git worktree add /e/gitHub_source_code/plan_tracker_capture_2.27 PLAN-v27
git merge origin/PLAN-v27   origin/v27 -m "Merge PLAN Tracker Capture App with parent branch"
git push origin PLAN-v27

git branch SAVE-CHILD-v27 // for create new branch for tracker capture
git checkout SAVE-CHILD-v27
git push origin SAVE-CHILD-v27
git worktree add /e/gitHub_source_code/save_child-v27 SAVE-CHILD-v27
git pull origin SAVE-CHILD-v27
git merge origin/SAVE-CHILD-v27   origin/v27 -m "Merge SAVE-CHILD Tracker Capture App with parent branch"
git push origin SAVE-CHILD-v27


git branch TIBET-v27 // for create new branch for tracker capture
git checkout TIBET-v27
git push origin TIBET-v27
git worktree add /e/gitHub_source_code/tibet_tracker_capture_v27 TIBET-v27
git merge origin/TIBET-v27   origin/v27 -m "Merge TIBET-v27 Tracker Capture App with parent branch"
git push origin TIBET-v27


git branch ODISHA-v27 // for create new branch for tracker capture
git checkout ODISHA-v27
git push origin ODISHA-v27
git worktree add /e/gitHub_source_code/odisha_tracker_capture_v27 ODISHA-v27
git merge origin/ODISHA-v27   origin/v27 -m "Merge ODISHA-v27 Tracker Capture App with parent branch"
git push origin ODISHA-v27






// not used
git branch SAVE-CHILD-2.28-SNAPSHOT // for create new branch for tracker capture
git checkout SAVE-CHILD-2.28-SNAPSHOT
git push origin SAVE-CHILD-2.28-SNAPSHOT
git worktree add /e/scm/gitHub_source_code/save_child-2.28-snapshot SAVE-CHILD-2.28-SNAPSHOT
git pull origin


git branch INPART-v28 // for create new branch for tracker capture
git checkout INPART-v28
git push origin INPART-v28
git worktree add /e/gitHub_source_code/inpart-v28 INPART-v28
git merge origin/INPART-v28   origin/v28 -m "Merge INPART Tracker Capture App with parent branch"
git push origin INPART-v28
git pull origin INPART-v28


git branch INTPART-KHERA-v28 // for create new branch for tracker capture
git checkout INTPART-KHERA-v28
git push origin INTPART-KHERA-v28
git worktree add /e/gitHub_source_code/intpart-khera-v28 INTPART-KHERA-v28
git merge origin/INTPART-KHERA-v28   origin/INPART-v28 -m "Merge INTPART-KHERA-v28 Tracker Capture App with parent branch"
git push origin INTPART-KHERA-v28
git pull origin INTPART-KHERA-v28


git branch ICMR_V28 // for create new branch for tracker capture
git checkout ICMR_V28
git push origin ICMR_V28
git worktree add /e/gitHub_source_code/icmr_tracker_capture_2.28 ICMR_V28
git merge origin/ICMR_V28  origin/v28 -m "Merge ICMR Tracker Capture App with parent branch"
git push origin ICMR_V28




git branch MWMIS-Jhpiego-v28 // for create new branch for tracker capture
git checkout MWMIS-Jhpiego-v28
git push origin MWMIS-Jhpiego-v28
git worktree add /e/gitHub_source_code/jhpiego_tracker_capture_2.28 MWMIS-Jhpiego-v28
git merge origin/MWMIS-Jhpiego-v28  origin/v28 -m "Merge MWMIS-Jhpiego Tracker Capture App with parent branch"
git push origin MWMIS-Jhpiego-v28



git worktree add /e/gitHub_source_code/icmr_lep_tracker_capture_2.28 ICMR_Leprosy_2.28

/ for sensation
https://github.com/hispindia/dhis-tracker-capture-app/commits/ICMR_Leprosy_2.28

change in file
https://github.com/hispindia/dhis-tracker-capture-app/blob/ICMR_Leprosy_2.28/components/dataentry/default-form.html
add method name pointerLocation()
https://github.com/hispindia/dhis-tracker-capture-app/blob/ICMR_Leprosy_2.28/components/dataentry/dataentry-controller.js
and 
 $scope.pointerLocation = function () {

git worktree add /e/gitHub_source_code/icmr_tracker_capture_2.28 icmr_v28_merge_futuredate

// PLAN-v29  for tracker-capture
git branch PLAN-v29 // for create new branch for tracker capture
git checkout PLAN-v29
git push origin PLAN-v29
git worktree add /e/gitHub_source_code/plan_tracker_capture_2.29 PLAN-v29
git merge origin/PLAN-v29   origin/v29 -m "Merge PLAN Tracker Capture App with parent branch"
git push origin PLAN-v29


// for plan-v29 build

git branch PLAN-v29 // / for create new branch for tracker capture plan-v29 build
git checkout PLAN-v29
git push origin PLAN-v29
git pull origin PLAN-v29
git worktree add /e/gitHub_source_code/tracker_build/plan-v29 PLAN-v29
git merge origin/PLAN-v29  origin/v29 -m "Merge PLAN-v29 Tracker Capture App with parent branch"
git push origin PLAN-v29




// for ICMR-AMR-v29
git branch ICMR-AMR-v29 // for create new branch for tracker capture ICMR-AMR-v29
git checkout ICMR-AMR-v29
git push origin ICMR-AMR-v29
git worktree add /e/gitHub_source_code/icmr_amr_v29 ICMR-AMR-v29
git merge origin/ICMR-AMR-v29   origin/v29 -m "Merge ICMR-AMR-v29 Tracker Capture App with parent branch"
git push origin ICMR-AMR-v29
git pull origin ICMR-AMR-v29


// for ICMR-AMR-v29 build

git branch ICMR-AMR-v29 // / for create new branch for tracker capture ICMR-AMR-v29 build
git checkout ICMR-AMR-v29
git push origin ICMR-AMR-v29
git pull origin ICMR-AMR-v29
git worktree add /e/gitHub_source_code/tracker_build/icmr-amr-v29 ICMR-AMR-v29
git merge origin/ICMR-AMR-v29  origin/v29 -m "Merge ICMR-AMR-v29 Tracker Capture App with parent branch"
git push origin ICMR-AMR-v29




// for v30
git branch ICMR-AMR-v30 // for create new branch for tracker capture ICMR-AMR-v30
git checkout ICMR-AMR-v30
git push origin ICMR-AMR-v30
git worktree add /e/gitHub_source_code/icmr_amr_v30 ICMR-AMR-v30
git merge origin/ICMR-AMR-v30   origin/v30 -m "Merge ICMR-AMR-v30 Tracker Capture App with parent branch"
git push origin ICMR-AMR-v30
git pull origin ICMR-AMR-v30


// for v30
git branch UPHMIS-v30 // for create new branch for tracker capture UPHMIS-v30
git checkout UPHMIS-v30
git push origin UPHMIS-v30
git worktree add /e/gitHub_source_code/uphmis_v30 UPHMIS-v30
git merge origin/UPHMIS-v30   origin/v30 -m "Merge UPHMIS-v30 Tracker Capture App with parent branch"
git push origin UPHMIS-v30
git pull origin UPHMIS-v30



// for UPHMIS Build v30
git branch UPHMIS-v30 // for create new branch for tracker capture UPHMIS-v30
git checkout UPHMIS-v30
git push origin UPHMIS-v30
git worktree add /e/gitHub_source_code/tracker_build/uphmis_v30 UPHMIS-v30
git merge origin/UPHMIS-v30   origin/v30 -m "Merge UPHMIS-v30 Tracker Capture Builds App with parent branch"
git push origin UPHMIS-v30
git pull origin UPHMIS-v30


// for INTPART-v30
git branch INTPART-v30 // for create new branch for tracker capture INTPART-v30
git checkout INTPART-v30
git push origin INTPART-v30
git worktree add /e/gitHub_source_code/intpart_v30 INTPART-v30
git merge origin/INTPART-v30   origin/v30 -m "Merge INTPART-v30 Tracker Capture App with parent branch"
git push origin INTPART-v30
git pull origin INTPART-v30


// for INTPART-KHERA-v30
git branch INTPART-KHERA-v30 // for create new branch for tracker capture INTPART-KHERA-v30
git checkout INTPART-KHERA-v30
git push origin INTPART-KHERA-v30
git worktree add /e/gitHub_source_code/intpart_khera_v30 INTPART-KHERA-v30
git merge origin/INTPART-KHERA-v30   origin/v30 -m "Merge INTPART-KHERA-v30 Tracker Capture App with parent branch"
git push origin INTPART-KHERA-v30
git pull origin INTPART-KHERA-v30

// for v30
git branch PUNJAB-v30 // for create new branch for tracker capture PUNJAB-v30
git checkout PUNJAB-v30
git push origin PUNJAB-v30
git worktree add /e/gitHub_source_code/punjab_v30 PUNJAB-v30
git merge origin/PUNJAB-v30   origin/v30 -m "Merge PUNJAB-v30 Tracker Capture App with parent branch"
git push origin PUNJAB-v30
git pull origin PUNJAB-v30



// for v30
git branch LIBYA-v30 // for create new branch for tracker capture LIBYA-v30
git checkout LIBYA-v30
git push origin LIBYA-v30
git worktree add /e/gitHub_source_code/libya_tracker_capture_v30 LIBYA-v30
git merge origin/LIBYA-v30   origin/v30 -m "Merge LIBYA-v30 Tracker Capture App with parent branch"
git push origin LIBYA-v30
git pull origin LIBYA-v30




// for v32

WHO Leprosy-Indonesia

who-leprosy-indonesia-v32

git branch who-leprosy-indonesia-v32 // for create new branch for tracker capture WHO Leprosy-Indonesia
git checkout who-leprosy-indonesia-v32
git push origin who-leprosy-indonesia-v32

git worktree add /e/gitHub_source_code/who_leprosy_indonesia_v32 who-leprosy-indonesia-v32
git merge origin/who-leprosy-indonesia-v32   origin/v32 -m "Merge WHO Leprosy-Indonesia Tracker Capture App with parent branch"
git push origin who-leprosy-indonesia-v32
git pull origin who-leprosy-indonesia-v32







// event-capture

tibet-event-capture-2.27
git merge origin/tibet-v27  origin/v27 -m "Merge tibet Event Capture App with parent branch"
git push origin tibet-v27


git branch orissa-v27 // for create new branch for event capture
git checkout orissa-v27
git push origin orissa-v27
git worktree add /e/gitHub_source_code/orissa_event_capture_2.27 orissa-v27
git merge origin/orissa-v27  origin/v27 -m "Merge ORISSA Event Capture App with parent branch"
git push origin idsp-v28







git branch idsp-v28 // for create new branch for event capture
git checkout idsp-v28
git push origin idsp-v28
git worktree add /e/gitHub_source_code/idsp_event_capture_2.28 idsp-v28
git merge origin/idsp-v28  origin/v28 -m "Merge IDSP Event Capture App with parent branch"
git push origin idsp-v28


git branch libia-v29 // for create new branch for event capture
git checkout libia-v29
git push origin libia-v29
git pull origin libia-v29
git worktree add /e/gitHub_source_code/libia_event_capture_2.29 libia-v29
git merge origin/libia-v29  origin/v29 -m "Merge LIBIA Event Capture App with parent branch"
git push origin libia-v29

git branch punjab-v30 // for create new branch for event capture
git checkout punjab-v30
git push origin punjab-v30
git pull origin punjab-v30
git worktree add /e/gitHub_source_code/punjab_event_capture_v30 punjab-v30
git merge origin/punjab-v30  origin/v30 -m "Merge PUNJAB Event Capture App with parent branch"
git push origin punjab-v30



git branch punjab-v30 // for create new branch for event capture build
git checkout punjab-v30
git push origin punjab-v30
git pull origin punjab-v30
git worktree add /e/gitHub_source_code/event_capture_build/punjab_v30 punjab-v30
git merge origin/punjab-v30  origin/v30 -m "Merge PUNJAB Event Capture App Build with parent branch"
git push origin punjab-v30




// dhis-data-administration-app

git branch UPHMIS-v30 // for create new branch for data-administration-app
git checkout UPHMIS-v30
git push origin UPHMIS-v30
git pull origin UPHMIS-v30
git worktree add /e/gitHub_source_code/data-admin/uphmis_v30 UPHMIS-v30
git merge origin/UPHMIS-v30  origin/v30 -m "Merge UPHMIS DATA-ADMIN App with parent branch"
git push origin UPHMIS-v30

// for build

git branch UPHMIS-v30 // for create new branch for data-administration-app-builds
git checkout UPHMIS-v30
git push origin UPHMIS-v30
git pull origin UPHMIS-v30
git worktree add /e/gitHub_source_code/data-admin/builds/uphmis_v30 UPHMIS-v30
git merge origin/UPHMIS-v30  origin/v30 -m "Merge UPHMIS DATA-ADMIN App with parent branch"
git push origin UPHMIS-v30



// for user-profile-app

git branch UPHMIS-v30 // for create new branch for user-profile-app
git checkout UPHMIS-v30
git push origin UPHMIS-v30
git pull origin UPHMIS-v30
git worktree add /e/gitHub_source_code/user-profile/uphmis_v30 UPHMIS-v30
git merge origin/UPHMIS-v30  origin/v30 -m "Merge UPHMIS User-profile App with parent branch"
git push origin UPHMIS-v30


// for INTERPRETATION-app

git branch UPHMIS-v30 // for create new branch for for INTERPRETATION-app
git checkout UPHMIS-v30
git push origin UPHMIS-v30
git pull origin UPHMIS-v30
git worktree add /e/gitHub_source_code/interpretation-app/uphmis_v30 UPHMIS-v30
git merge origin/UPHMIS-v30  origin/v30 -m "Merge UPHMIS INTERPRETATION App with parent branch"
git push origin UPHMIS-v30

// for build INTERPRETATION-app

git branch UPHMIS-v30 // for create new branch for INTERPRETATION-app-builds
git checkout UPHMIS-v30
git push origin UPHMIS-v30
git pull origin UPHMIS-v30
git worktree add /e/gitHub_source_code/interpretation-app/builds/uphmis_v30 UPHMIS-v30
git merge origin/UPHMIS-v30  origin/v30 -m "Merge UPHMIS INTERPRETATION App with parent branch"
git push origin UPHMIS-v30



// for maintenance-app

git branch UPHMIS-v30 // for create new branch for for maintenance-app
git checkout UPHMIS-v30
git push origin UPHMIS-v30
git pull origin UPHMIS-v30
git worktree add /e/gitHub_source_code/maintenance_app/uphmis_v30 UPHMIS-v30
git merge origin/UPHMIS-v30  origin/v30 -m "Merge UPHMIS Maintenance App with parent branch"
git push origin UPHMIS-v30


// for build maintenance-app-build

git branch UPHMIS-v30 // for create new branch for maintenance-app-build
git checkout UPHMIS-v30
git push origin UPHMIS-v30
git pull origin UPHMIS-v30

git merge origin/UPHMIS-v30  origin/v30 -m "Merge UPHMIS maintenance-app-build with parent branch"
git push origin UPHMIS-v30




build user-profile-app module ( in react-js)
on command promt run the commands

npm install yarn -g
yarn install
yarn build
yarn start

build data-quality-app module ( in react-js)
on command promt run the commands

node -v
npm - v
yarn -v

npm install yarn -g // run for data-quality-app
yarn install

npm run lint -- --fix // run for data-quality-app

yarn build
yarn start

// maintenance-app-build command

 npm install --global yarn
 yarn install
 yarn start
	
npm install -g win-node-env // for NODE_ENV' is not recognized as an internal or external command
yarn add react-select
npm install react-select




build user-profile-app module ( in react-js)
on command promt run the commands

npm install yarn -g
yarn install
yarn build
yarn start



// tracker-event-report

libya-tracker-event-report-v30

// create brnch for 2.30 master

git branch tracker-event-report-v30  // create brnch for 2.30 master
git checkout tracker-event-report-v30
git push origin tracker-event-report-v30


punjab-hmis-tracker-event-report-v30

git branch punjab-hmis-tracker-event-report-v30
git checkout punjab-hmis-tracker-event-report-v30
git push origin punjab-hmis-tracker-event-report-v30

// for app development

git branch dhis-report-data-status-app-default-v30
git checkout dhis-report-data-status-app-default-v30
git push origin dhis-report-data-status-app-default-v30


// create branch for maharashtra-api integration

git branch mh_api_integration_v27
git checkout mh_api_integration_v27
git push origin mh_api_integration_v27



// for hisp-india-website

git branch v1
git checkout v1
git push origin v1


// for biometric nepal-save - save-child

https://github.com/hispindia/Biometrics-Nepal/tree/master

git branch client-updated // for create new branch for event capture
git checkout client-updated
git add *
git push origin client-updated

git branch finger-print-set-up
git checkout finger-print-set-up
git add *
git push origin finger-print-set-up





// for PhantomJS Setup
git branch PhantomJS-tibet


// git commamd for revision No ---

git rev-parse --short HEAD

// for reset

git reset HARD revision-no
git push -f



// for clean
$ git clean -xdf


// for git Reset command
git log -3
$ git checkout 4d9e5(revision no)
$ git reset --hard
git push origin sluhmis2.24

git reset --hard f097b63
git reset --soft HEAD@{1}
git commit -m "Reverting to the state of the project at f097b63"
git push origin sluhmis2.24 -f



for take commit from another branch and revision no

git cherry-pick f20cd15
git cherry-pick 56794a
git push origin NIE-2.27






// custom app build 

1- Biometric - Nepal - Java
https://github.com/hispindia/Biometrics-Nepal

2 - Libya Reporting App Angular - 6
npm i or npm install/ and npm install text-encoding then npm run build
https://github.com/hispindia/Apps-Development/tree/libya-reports-app-angular6

3 - tracker event data exporter-app -- Angular JS no npm build
https://github.com/hispindia/tracker-data-exporter-app

4 - Explore dictionary -- Angular JS no npm build
https://github.com/hispindia/Apps-Development/tree/explore-dictionary

5 - Tracker-Event Reporting Rate App Angular JS no npm build
https://github.com/hispindia/Apps-Development/tree/Tracker-reporting-rate-app

6 - GBD dashboard App Vue-js npm install / npm install vue/ npm run build
https://github.com/hispindia/interactive-dashboard-vuejs


// git show revision no - 

git rev-parse --short HEAD

node -v
npm -v
// node.js and webpack related for tracker capture v2.26

for window install cygwin with bash,shell and net and select rsync
 install node js and run the command on node shell

npm install webpack or 
npm install webpack - g or
npm install --no-optional or

npm install express -g 

or
npm i
or npm i npm --for latest dowmloads

or
npm i npm@latest -g

//
npm i (inside node command promt)

and open cygwin

and run command 

npm run build

npm audit fix
npm audit fix --force
and take bundle from build folder

// for deploy in sona type

mvn clean install deploy


// delete from sonatype
curl -X DELETE -u mithilesh.hisp:hisp123 http://hospdev.hispindia.org/nexus/content/repositories/org.hispindia.dhis2/org/hisp/dhis/dhis-app-tracker-capture-plan


// revert command

git revert HEAD~2 // revert 
git revert HEAD~2 -m "Revert 2 commmits"

 git push origin IVB-2.21


git checkout b39e7a5

git reset --hard b39e7a5
git commit -m "Reverted back to b39e7a5"
git push --force origin IVB-2.21
git commit -m "Reverted back to b39e7a5"

\"user\" for add double quotes in side string


Inside Package.json

  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1",
    "prebuild": "(rm -r build && mkdir build) || mkdir build",
    "build": "webpack && cp -r i18n build/i18n && cp -r core build/core && cp -r views build/views && cp -r styles build/styles && find ./components -iname \"*.html\" -exec rsync -R  ./build/ ;",
    "start": "webpack-dev-server"
  },


curl -X DELETE -u mithilesh.hisp:hisp123 http://hospdev.hispindia.org/nexus/content/repositories/org.hispindia.dhis2/org/hisp/dhis/dhis-app-tracker-capture-inpart


C:\Program Files\Chrome\Chrome.exe --disable-web-security


// maintenance-app build process

Requirements for maintenance-app to work:

    Run dhis-core (tomcat/jetty) on port 8080
    Maintenance-app will run on port 8081

 

In the environment for $DHIS2_HOME you need a setup a configuration file config.js to get access to dhis-core.

    Create authentication OAuth2 on dhis-core: access localhost:8080(/dhis) -> System settings -> OAuth2 Clients -> create OAuth2 client
    Setup configuration file located at $DHIS2_HOME/config.js based on the OAuth2 details above.


in config.js


module.exports = {
	"name" : "yarn",
	"cid" : "yarn",
	"secret" : "57cd518f8-f706-4138-39f2-6a909dc3eeb",
	"grantTypes" : [
		"password" : "district",
		"refresh_token",
		"authorization_code"
		
	],

};
 

To run the maintenance-app youll need to run dhis-core file first, and then the maintenance-app:

    git clone https://github.com/dhis2/maintenance-app.git
    cd maintenance-app
    npm install --global yarn
    yarn install
    yarn start

 npm install -g win-node-env // for NODE_ENV' is not recognized as an internal or external command
yarn add react-select
npm install react-select

When everything is configured and running:

    Go to http://localhost:8080 and login with from the dhis-core first.
    Go to http://localhost:8081 which will redirect you to the separated maintenance-app itself.
        If it doesnt show up try to disable web security for the browser: https://stackoverflow.com/questions/24290149/creating-google-chrome-shortcut-with-disable-web-security
        Check browser Inspector->Console for debugging.



disable chrome command

 "C:\Program Files\Google\Chrome\Application\chrome.exe" --disable-web-security


build data-admin module ( in react-js)

on command promt run the command or either run on node.js prompt

// for install yarn globally
npm install yarn -g or npm install --global yarn

then build

yarn install

// for [npm run lint -- --fix ] to get rid of current CRLF(Carriage Return (ASCII 13, \r) Line Feed (ASCII 10, \n))

npm run lint -- --fix

then
yarn build

build user-profile-app module ( in react-js)
on command promt run the commands

npm install yarn -g
yarn install
yarn build
yarn start

// pivotel app build

node --version

yarn install
npm run build
npm install yarn -g
npm install -g webpack

for syntex error

npm install babel-preset-es2015 --save-dev
npm install --save-dev babel-plugin-syntax-dynamic-import
npm install uglifyjs-webpack-plugin --save-dev

or
npm install -g webpack-dev-server

npm install -g webpack-cli // not use
npm install --save-dev webpack

npm i -g webpack webpack-cli
or
npm i webpack webpack-cli // for loc
yarn install








// Run analytics 1 hourly command

 #!/bin/sh /usr/bin/curl "localhost:8080/api/resourceTables/analytics?skipResourceTables=true&lastYears=2" -X POST -u admin:district >/dev/null 2>&1





New Password for All Except Git-Hub and launchpad.net password - 

+Password : <s3cur1ty>


https://jira.dhis2.org

usename - mithilesh


// SQL view/QUERY for Custom ID Generation and issue realted to duplicate ID

TEI_COUNT_ORGUNIT_WISE

SELECT COUNT(tei.trackedentityinstanceid) from trackedentityinstance tei
INNER JOIN programinstance pi ON pi.trackedentityinstanceid = tei.trackedentityinstanceid
INNER JOIN organisationunit orgUnit ON orgUnit.organisationunitid = pi.organisationunitid
WHERE orgUnit.uid = '${orgUnitUid}';

TEI_ID_VALIDATION

SELECT teav.value FROM trackedentityattributevalue teav
INNER JOIN programinstance pi on pi.trackedentityinstanceid = teav.trackedentityinstanceid
INNER JOIN organisationunit org ON org.organisationunitid = pi.organisationunitid
where teav.trackedentityattributeid = 93 and org.uid = '${orgUnitUid}';

for tibet

TEI_COUNT_ORGUNIT_PROGRAM_WISE

SELECT COUNT(tei.trackedentityinstanceid) from trackedentityinstance tei
INNER JOIN programinstance pi ON pi.trackedentityinstanceid = tei.trackedentityinstanceid
INNER JOIN organisationunit orgUnit ON orgUnit.organisationunitid = pi.organisationunitid
INNER JOIN program prg ON prg.programid = pi.programid
WHERE orgUnit.uid = '${orgUnitUid}' and prg.uid = '${programUid}';

TEI_ID_VALIDATION

SELECT teav.value FROM trackedentityattributevalue teav
INNER JOIN programinstance pi on pi.trackedentityinstanceid = teav.trackedentityinstanceid
INNER JOIN organisationunit org ON org.organisationunitid = pi.organisationunitid
INNER JOIN program prg ON prg.programid = pi.programid
where teav.trackedentityattributeid = 647 and org.uid = '${orgUnitUid}' and prg.uid = '${programUid}';


// for pLAN SQL-VIEW

name : TEI_ID_VALIDATION

SELECT teav.value FROM trackedentityattributevalue teav
INNER JOIN programinstance pi on pi.trackedentityinstanceid = teav.trackedentityinstanceid
INNER JOIN organisationunit org ON org.organisationunitid = pi.organisationunitid
INNER JOIN program prg ON prg.programid = pi.programid
where teav.trackedentityattributeid = 8374 and org.uid = '${orgUnitUid}' and prg.uid = '${programUid}';


SQL View Parameters

var param = "var=program:"+program.id + "&var=orgunit:"+$scope.selectedOrgUnitName_level_id+"&var=startdate:"+$scope.startdateSelected+"&var=enddate:"+$scope.enddateSelected;

https://uphmis.in/uphmis/api/sqlViews/yHR3u7imDlB/data.json?var=deuid:qYpFbVo8WsL&var=orgunituid:N5WWbRtsjWp


/api/sqlViews/{id}/data?var=key1:value1&var=key2:value2

// lepmpa script

SELECT ds.state_id,ds.state_code, ds.district_id, ds.district_code, ds.district_name,bphc.bphc_id,
bphc.block_code,bphc.bphc_name,bphc.latitude,bphc.longitude FROM mst_district AS ds
INNER JOIN mst_bphc AS bphc ON ds.district_id = bphc.district_id
ORDER BY ds.state_id;

SELECT mst.*,state.state_name,dis.district_name,bphc.bphc_name FROM mst_suspect mst
INNER JOIN mst_state state ON state.state_id = mst.state
INNER JOIN mst_district dis ON dis.district_id = mst.district
INNER JOIN mst_bphc bphc ON bphc.bphc_id = mst.block_phc


dataSets.json?filter=id:eq:' + $scope.DataSet + "&fields=id,name,periodType,organisationUnits[id,name,code,attributeValues[attribute[id,name,code],value]&paging=false

// for UPHMIS

select * from programstageinstance where completeddate::date <=now() and  status = 'COMPLETED';
select * from programstageinstance where completeddate < CURRENT_TIMESTAMP - INTERVAL '7 days' and status = 'COMPLETED';

select * from programstageinstance where completeddate between current_date and current_date - interval '7 day' and status = 'COMPLETED';


CURRENT_TIMESTAMP - INTERVAL '100 days'

date between current_date and current_date - interval '10 day';

select psi.programstageinstanceid,psi.completeddate,tedv.value from programstageinstance psi
INNER JOIN trackedentitydatavalue tedv ON tedv.programstageinstanceid = psi.programstageinstanceid
where psi.completeddate between current_date and current_date - interval '7 day' and psi.status = 'COMPLETED' and tedv.dataelementid = 38576348
and tedv.value != 'Approved';


select psi.programstageinstanceid,psi.completeddate,tedv.value from programstageinstance psi
INNER JOIN trackedentitydatavalue tedv ON tedv.programstageinstanceid = psi.programstageinstanceid
where psi.completeddate < CURRENT_TIMESTAMP - INTERVAL '7 days' and psi.status = 'COMPLETED' and tedv.dataelementid = 38576348
and tedv.value != 'Approved';



select psi.programstageinstanceid,psi.completeddate,tedv.value from programstageinstance psi
INNER JOIN trackedentitydatavalue tedv ON tedv.programstageinstanceid = psi.programstageinstanceid
where psi.completeddate <= current_date - interval '7 day' and psi.status = 'COMPLETED' and tedv.dataelementid = 38576348
and tedv.value not in( 'Approved', 'Rejected', 'Re-submitted');

select psi.programstageinstanceid,psi.completeddate,tedv.value from programstageinstance psi
INNER JOIN trackedentitydatavalue tedv ON tedv.programstageinstanceid = psi.programstageinstanceid
where psi.completeddate <= current_date - interval '7 day' and psi.status = 'COMPLETED' and tedv.dataelementid = 38576348
and tedv.value not in( 'Approved', 'Rejected', 'Re-submitted');

select psi.programstageinstanceid,psi.completeddate from programstageinstance psi
where psi.completeddate <= current_date - interval '7 day' and psi.status = 'COMPLETED' order by psi.completeddate desc


select psi.programstageinstanceid,psi.completeddate from programstageinstance psi
where psi.completeddate <= current_date and psi.status = 'COMPLETED' order by psi.completeddate desc

select current_date

select * from trackedentitydatavalue where programstageinstanceid in ( select psi.programstageinstanceid from programstageinstance psi
where psi.completeddate <= current_date - interval '7 day' and psi.status = 'COMPLETED') and dataelementid = 38576348
and dataelementid = 38576348
select value from trackedentitydatavalue where programstageinstanceid = 53579980 and dataelementid = 38576348


// IPPF

SELECT periodid, periodtypeid, startdate, enddate
  FROM public.period where periodtypeid = 2 and startdate >= '2018-02-01' and enddate <= '2018-05-01' order by startdate;

  select * from dataelement where code = 'SRV-373601203'
    select * from organisationunit where code = 'CL205HEA001'

    SELECT categoryoptioncomboid FROM categoryoptioncombo WHERE  uid = 'J1g7VOz80MM'

select * from datavalue where dataelementid = 1810 and sourceid = 1658 and 
periodid in ( select periodid from period where periodtypeid = 2 and startdate >= '2018-02-01' and enddate <= '2018-05-01' ) 
order by lastupdated desc




// event query

select * from (select psi.programstageinstanceid as psi_id, psi.uid as psi_uid, psi.code as psi_code, psi.status as psi_status, psi.executiondate as psi_executiondate, psi.duedate as psi_duedate, psi.completedby
 as psi_completedby, psi.storedby as psi_storedby, psi.longitude as psi_longitude, psi.latitude as psi_latitude, psi.created as psi_created, psi.lastupdated as
psi_lastupdated, psi.completeddate as psi_completeddate, psi.deleted as psi_deleted, coc.categoryoptioncomboid AS coc_categoryoptioncomboid, coc.code AS coc_categoryoptioncombocode, coc.uid AS coc_categoryoptioncombouid, 
cocco.categoryoptionid AS cocco_categoryoptionid, deco.uid AS deco_uid, pi.uid as pi_uid, pi.status
as pi_status, pi.followup as pi_followup, p.uid as p_uid, p.code as p_code, p.type as p_type, ps.uid as ps_uid, ps.code as ps_code, ps.capturecoordinates as ps_capturecoordinates, ou.uid as ou_uid, ou.code as ou_code, ou.name as ou_name, 
tei.trackedentityinstanceid as tei_id, tei.uid as tei_uid, teiou.uid as tei_ou, teiou.name as tei_ou_name, tei.created as tei_created, tei.inactive as tei_inactive from programstageinstance psi 
inner join programinstance pi on pi.programinstanceid=psi.programinstanceid 
inner join program p on p.programid=pi.programid 
inner join programstage ps on ps.programstageid=psi.programstageid 
inner join categoryoptioncombo coc on coc.categoryoptioncomboid=psi.attributeoptioncomboid 
inner join categoryoptioncombos_categoryoptions cocco on psi.attributeoptioncomboid=cocco.categoryoptioncomboid 
inner join dataelementcategoryoption deco on cocco.categoryoptionid=deco.categoryoptionid 
left join trackedentityinstance tei on tei.trackedentityinstanceid=pi.trackedentityinstanceid 
left join organisationunit ou on (psi.organisationunitid=ou.organisationunitid) 
left join organisationunit teiou on (tei.organisationunitid=teiou.organisationunitid) where p.programid = 9178 
and (psi.executiondate >= '2018-07-01' or (psi.executiondate is null and psi.duedate >= '2018-07-01')) 
and (psi.executiondate < '2018-08-01' or (psi.executiondate is null and psi.duedate < '2018-08-01'))and psi.deleted is false order by
 psi_executiondate asc  ) as event 
 left join (select pdv.programstageinstanceid as pdv_id, pdv.created as pdv_created, pdv.lastupdated as pdv_lastupdated, 
 pdv.value as pdv_value, pdv.storedby as pdv_storedby, pdv.providedelsewhere as pdv_providedelsewhere, de.uid as de_uid, de.code as de_code from trackedentitydatavalue pdv 
inner join dataelement de on pdv.dataelementid=de.dataelementid ) as dv on event.psi_id=dv.pdv_id 
 left join (select psic.programstageinstanceid as psic_id, psinote.trackedentitycommentid as psinote_id, psinote.commenttext as psinote_value, 
psinote.createddate as psinote_storeddate, psinote.creator as psinote_storedby from programstageinstancecomments psic 
inner join trackedentitycomment psinote on psic.trackedentitycommentid=psinote.trackedentitycommentid ) 
as cm on event.psi_id=cm.psic_id order by psi_executiondate asc


//

select * from (select psi.programstageinstanceid as psi_id, psi.uid as psi_uid, psi.code as psi_code, psi.status as psi_status, 
psi.executiondate as psi_executiondate, psi.duedate as psi_duedate, psi.completedby as psi_completedby, psi.storedby as psi_storedby, psi.longitude as psi_longitude, psi.latitude as psi_latitude, psi.created as psi_created, psi.lastupdated as
psi_lastupdated, psi.completeddate as psi_completeddate, psi.deleted as psi_deleted, coc.categoryoptioncomboid AS coc_categoryoptioncomboid, coc.code AS coc_categoryoptioncombocode, coc.uid AS coc_categoryoptioncombouid, cocco.categoryoptionid AS cocco_categoryoptionid, deco.uid AS 
deco_uid, deco.publicaccess AS deco_publicaccess, decoa.uga_access AS uga_access, decoa.ua_access AS ua_access, cocount.option_size AS option_size, pi.uid as pi_uid, pi.status as pi_status, pi.followup as pi_followup, p.uid as p_uid, p.code as p_code, p.type as p_type, ps.uid
as ps_uid, ps.code as ps_code, ps.capturecoordinates as ps_capturecoordinates, ou.uid as ou_uid, ou.code as ou_code, ou.name as ou_name, tei.trackedentityinstanceid as tei_id, tei.uid as tei_uid, teiou.uid as tei_ou, teiou.name as tei_ou_name, tei.created as tei_created, 
tei.inactive as tei_inactive from programstageinstance psi inner join programinstance pi on pi.programinstanceid=psi.programinstanceid 
inner join program p on p.programid=pi.programid 
inner join programstage ps on ps.programstageid=psi.programstageid inner join categoryoptioncombo coc on coc.categoryoptioncomboid=psi.attributeoptioncomboid 
inner join categoryoptioncombos_categoryoptions cocco on psi.attributeoptioncomboid=cocco.categoryoptioncomboid inner join dataelementcategoryoption deco on cocco.categoryoptionid=deco.categoryoptionid 
left join trackedentityinstance tei on tei.trackedentityinstanceid=pi.trackedentityinstanceid left join organisationunit ou on (psi.organisationunitid=ou.organisationunitid) left join organisationunit teiou on (tei.organisationunitid=teiou.organisationunitid)  
left join ( select categoryoptioncomboid, count(categoryoptioncomboid) as option_size from categoryoptioncombos_categoryoptions 
group by categoryoptioncomboid) as cocount on coc.categoryoptioncomboid = cocount.categoryoptioncomboid 
left join (select deco.categoryoptionid as deco_id,deco.uid as deco_uid, deco.publicaccess AS deco_publicaccess, couga.usergroupaccessid as uga_id, coua.useraccessid as ua_id, 
uga.access as uga_access, uga.usergroupid AS usrgrp_id, ua.access as ua_access, ua.userid as usr_id from dataelementcategoryoption deco 
left join dataelementcategoryoptionusergroupaccesses couga on deco.categoryoptionid = couga.categoryoptionid 
left join dataelementcategoryoptionuseraccesses coua on deco.categoryoptionid = coua.categoryoptionid 
left join usergroupaccess uga on couga.usergroupaccessid = uga.usergroupaccessid 
left join useraccess ua on coua.useraccessid = ua.useraccessid  
where ua.userid=202911 or uga.usergroupid in (14948)  ) as decoa on cocco.categoryoptionid = decoa.deco_id where p.programid = 9178 and 
(psi.executiondate >= '2018-07-01' or (psi.executiondate is null and psi.duedate >= '2018-07-01')) and (psi.executiondate < '2018-08-01' or (psi.executiondate is null and psi.duedate < '2018-08-01')) and psi.deleted is false order by psi_executiondate asc  ) as event 
left join (select pdv.programstageinstanceid as pdv_id, pdv.created as pdv_created, pdv.lastupdated as pdv_lastupdated, pdv.value as pdv_value, pdv.storedby as pdv_storedby, 
pdv.providedelsewhere as pdv_providedelsewhere, de.uid as de_uid, de.code as de_code from trackedentitydatavalue pdv inner join dataelement de on pdv.dataelementid=de.dataelementid ) as dv on event.psi_id=dv.pdv_id 
left join (select psic.programstageinstanceid as psic_id, psinote.trackedentitycommentid as psinote_id, psinote.commenttext as psinote_value, psinote.createddate as psinote_storeddate, psinote.creator as psinote_storedby from programstageinstancecomments psic 
inner join trackedentitycomment psinote on psic.trackedentitycommentid=psinote.trackedentitycommentid ) as cm on event.psi_id=cm.psic_id order by psi_executiondate asc



// javascript phone no validation

function phonenumber(inputtxt) {
  var phoneno = /^\+?([0-9]{2})\)?[-. ]?([0-9]{4})[-. ]?([0-9]{4})$/;
  if(inputtxt.value.match(phoneno)) {
    return true;
  }  
  else {  
    alert("message");
    return false;
  }
}



// geeting all analytics tables

SELECT table_name from information_schema.tables where table_name like 'analytics%' and table_type = 'BASE TABLE';

SELECT * from information_schema.tables where table_name like 'analytics%' and table_type = 'BASE TABLE';

// organisationunitattributevalues

  SELECT orgAttrValue.organisationunitid,attrValue.attributeid, attrValue.value from organisationunitattributevalues orgAttrValue
  INNER JOIN attributevalue attrValue ON attrValue.attributevalueid = orgAttrValue.attributevalueid
  WHERE attrValue.attributeid = 38115164;


SELECT attrValue.attributevalueid,  attrValue.value, attrValue.attributeid
	FROM public.attributevalue attrValue
	inner JOIN organisationunitattributevalues orgAttrValue ON attrValue.attributevalueid = orgAttrValue.attributevalueid
	inner JOIN organisationunit org ON org.organisationunitid = orgAttrValue.organisationunitid
    WHERE attrValue.attributeid = 38115164 and org.hierarchylevel = 8 and attrValue.value in (


// enrollment count query user-wise

select us.userid,us.username,org.name,org.uid,count(tei.trackedentityinstanceid) as count from trackedentityinstance tei
INNER JOIN users us ON us.userid = tei.lastupdatedby
INNER JOIN programinstance pi ON pi.trackedentityinstanceid = tei.trackedentityinstanceid
INNER JOIN organisationunit org ON org.organisationunitid = pi.organisationunitid
where pi.programid = 2437 and pi.enrollmentdate between '2018-01-01' and '2018-10-31'
group by us.userid,us.username,org.name,org.uid


select us.userid,us.username,org.name,org.uid,pg.name,pg.uid,count(tei.trackedentityinstanceid) as count from trackedentityinstance tei
INNER JOIN users us ON us.userid = tei.lastupdatedby
INNER JOIN programinstance pi ON pi.trackedentityinstanceid = tei.trackedentityinstanceid
INNER JOIN organisationunit org ON org.organisationunitid = pi.organisationunitid
INNER JOIN program pg ON pg.programid = pi.programid
where pi.enrollmentdate between '1990-01-01' and '2018-10-31'
group by us.userid,us.username,org.name,org.uid,pg.name,pg.uid;



SELECT us.userid,us.username as user_name,org.name as org_name,org.uid as org_uid,pg.name as program_name,pg.uid as program_uid,count(tei.trackedentityinstanceid) as count from trackedentityinstance tei
INNER JOIN users us ON us.userid = tei.lastupdatedby
INNER JOIN programinstance pi ON pi.trackedentityinstanceid = tei.trackedentityinstanceid
INNER JOIN organisationunit org ON org.organisationunitid = pi.organisationunitid
INNER JOIN program pg ON pg.programid = pi.programid
where pg.uid in ('y6lXVg8TdOj','Fcyldy4VqSt') and  pi.enrollmentdate between '1990-01-01' and '2018-10-31'
group by us.userid,us.username,org.name,org.uid,pg.name,pg.uid;

SELECT dv.sourceid,org1.name,org.name,count(dv.sourceid) from datavalue dv
INNER JOIN organisationunit org ON org.organisationunitid = dv.sourceid
INNER JOIN organisationunit org1 ON org1.organisationunitid = org.parentid
INNER JOIN datasetelement dse ON dse.dataelementid = dv.dataelementid
INNER JOIN dataelement de ON de.dataelementid = dv.dataelementid
where dse.datasetid = 10886 and dv.dataelementid not in ( 10871,10872,10870, 1774) and dv.periodid = 848 
group by dv.sourceid,org1.name,org.name order by org1.name;

// user-wise enrollment count

SELECT us.userinfoid,us.firstname,us.surname,org.name as org_name,org1.name as parent_name, org.uid as org_uid,count(tei.trackedentityinstanceid) as count from trackedentityinstance tei
left JOIN userinfo us ON us.userinfoid = tei.lastupdatedby
left JOIN programinstance pi ON pi.trackedentityinstanceid = tei.trackedentityinstanceid
left JOIN organisationunit org ON org.organisationunitid = pi.organisationunitid
left JOIN organisationunit org1 ON org1.organisationunitid = org.parentid
left JOIN program pg ON pg.programid = pi.programid
where pg.uid = 'y6lXVg8TdOj'  and pi.enrollmentdate::date between '2018-01-01' and '2018-12-31'  
and pi.organisationunitid IN ( select organisationunitid from organisationunit where
parentid in ( select organisationunitid from organisationunit where parentid in ( select organisationunitid from organisationunit  where uid = 'c1HbB4LCCcI') ) )
group by us.userinfoid,us.firstname,us.surname,org.name,org1.name,org.uid,pg.name,pg.uid order by us.firstname\



SELECT attvalue.attributevalueid, attvalue.created, attvalue.lastupdated, attvalue.value, attvalue.attributeid,orgUnit.name
  FROM public.attributevalue attvalue
INNER JOIN organisationunitattributevalues orgattvalue ON orgattvalue.attributevalueid = attvalue.attributevalueid
INNER JOIN organisationunit orgUnit ON orgUnit.organisationunitid = orgattvalue.organisationunitid

  where attvalue.attributeid = 38115164 and  orgUnit.hierarchylevel = 8 order by lastupdated desc;



select pss.name as section_name ,ps.name as ps_name,de.name,de.dataelementid as de_name from programstagesection pss
INNER JOIN programstage ps ON ps.programstageid = pss.programstageid
INNER JOIN programstagedataelement psde on psde.programstageid = pss.programstageid
INNER JOIN dataelement de ON de.dataelementid = psde.dataelementid where  de.dataelementid in(7710,
176701,
214872,
7739,
176739,
156025,
163594,
8693,
150033,
176700,
203837,
174673);


api/optionSets.json?fields=id,name,code,options[id,name,code]&filter=code:eq:"+code+"&rootJunction=OR&paging=false
https://amrtest.icmr.org.in/amr/api/optionSets.json?fields=id,name,code,options[id,name,code]&filter=code:eq:Uttar%20Pradesh&rootJunction=OR&paging=false

// section wise dataelements list

SELECT pg.name as programName, ps.name as programStageName, ps_se.name as sectionName, ps_de.dataelementid,de.name as dataElementName, ps_de.sort_order
FROM public.programstagesection_dataelements ps_de
INNER JOIN programstagesection ps_se ON ps_se.programstagesectionid = ps_de.programstagesectionid
INNER JOIN dataelement de On de.dataelementid = ps_de.dataelementid
INNER JOIN programstage ps ON ps.programstageid = ps_se.programstageid
INNER JOIN program pg ON pg.programid = ps.programid
WHERE pg.uid = 'ecIoUziI2Gb';


SELECT pg.name as programName, pg.programid,pg.uid as pg_uid, ps.name as programStageName, 
ps.programstageid,ps.uid as programStage_uid, ps_se.name as sectionName, 
ps_se.programstagesectionid, ps_se.uid as programstagesection_uid, 
ps_de.dataelementid, de.uid as dataElement_uid, de.name as dataElementName, ps_de.sort_order
FROM public.programstagesection_dataelements ps_de
INNER JOIN programstagesection ps_se ON ps_se.programstagesectionid = ps_de.programstagesectionid
INNER JOIN dataelement de On de.dataelementid = ps_de.dataelementid
INNER JOIN programstage ps ON ps.programstageid = ps_se.programstageid
INNER JOIN program pg ON pg.programid = ps.programid order by pg.name



SELECT de.name deName,de.uid deUid ,os.name optionsetName,os.uid optionsetUid ,ov.uid optionValueUid ,ov.name optionValueName,ov.code optionValueCode FROM optionvalue ov
INNEr JOIN optionset os ON os.optionsetid = ov.optionsetid
INNER JOIN dataelement de ON de.optionsetid = os.optionsetid;

select pg.name programname ,pg.programid,ps.name progrmStageName,ps.programstageid,pss.programstagesectionid,pss.name programstageSectionName from programstagesection pss 
INNER JOIN programstage ps ON ps.programstageid = pss.programstageid
INNER JOIN program pg ON pg.programid = ps.programid
order by pg.name


Excel import & Report app db key migration from systemsetting table to keyjsonvalue table

Excel-import-app-templates
Excel-import-app-orgunit-mapping
Excel-import-app-pool
Excel-import-app-history

http://localhost:8090/dhis/api/system/id.json?limit=10

insert into keyjsonvalue (keyjsonvalueid,,uid, created, lastupdated, namespace, namespacekey ) values
="(nextval('hibernate_sequence'),'2019-02-26','2019-02-26','"&A2&"','"&B2&"'),"


update keyjsonvalue set created = now()::timestamp where created ='2019-02-26';
update keyjsonvalue set lastupdated = now()::timestamp where lastupdated ='2019-02-26';

update keyjsonvalue set value = 
	( select right(value::text,length(value::text) - 22 )
	from systemsetting
	where name like 'Excel-import-app-orgunit-mapping%' )
where namespace = 'Excel-import-app-orgunit-mapping';


update keyjsonvalue set value = 
	(select right(value::text,length(value::text) - 25)
	from systemsetting
	where name like 'Excel-import-app-pool%'
)
where namespace = 'Excel-import-app-pool';

update keyjsonvalue set value = 
	(select right(value::text,length(value::text) - 25)
	from systemsetting
	where name like 'Excel-import-app-templates%'
)
where namespace = 'Excel-import-app-templates';


update keyjsonvalue set value = 
	( select right(value::text,length(value::text) - 22 )
	from systemsetting
	where name like 'Excel-import-app-history%' )
where namespace = 'Excel-import-app-history';



update keyjsonvalue set value = 
	(select right(value::text,length(value::text) - 22)
	from systemsetting
	where name like 'reportApp-section-json'
)
where namespace = 'reportApp-section-json';

update keyjsonvalue set value = 
	(select right(value::text,length(value::text) - 22)
	from systemsetting
	where name like 'reportApp-reports-json'
)
where namespace = 'reportApp-reports-json';


select de.name deName, coc.name COCName, org.name orgName, pe.startdate STARTDATE, dv.* from datavalue dv 
INNER JOIN dataelement de ON de.dataelementid = dv.dataelementid
INNER JOIN categoryoptioncombo coc ON coc.categoryoptioncomboid = dv.categoryoptioncomboid
INNER JOIN organisationunit org ON org.organisationunitid = dv.sourceid
INNER JOIN period pe ON pe.periodid = dv.periodid
where dv.dataelementid in ( 591,590,589,23596,23475 ) and 	dv.categoryoptioncomboid = 21520
and dv.sourceid in ( 17150,17180,17147,17175,17149,17151,17148,17176,17145,17146 ) and dv.periodid in 
( 38135545,38002029,37979107,38115491,40582909,39795112,33184716,37809045,33143771)


select de.name deName, coc.name COCName, org.name orgName, pe.startdate STARTDATE, dv.* from datavalueaudit dv 
INNER JOIN dataelement de ON de.dataelementid = dv.dataelementid
INNER JOIN categoryoptioncombo coc ON coc.categoryoptioncomboid = dv.categoryoptioncomboid
INNER JOIN organisationunit org ON org.organisationunitid = dv.organisationunitid
INNER JOIN period pe ON pe.periodid = dv.periodid
where dv.dataelementid in ( 591,590,589,23596,23475 ) and 	dv.categoryoptioncomboid = 21520
and dv.organisationunitid in ( 17150,17180,17147,17175,17149,17151,17148,17176,17145,17146 ) and dv.periodid in 
( 38135545,38002029,37979107,38115491,40582909,39795112,33184716,37809045,33143771) order by pe.startdate

// for datasetelement

select ds.name,de.name,dsm.datasetid,dsm.dataelementid,co.name,de.categorycomboid from datasetmembers dsm
INNER JOIN dataset ds ON ds.datasetid = dsm.datasetid
INNER JOIN dataelement de ON de.dataelementid = dsm.dataelementid
INNER JOIN categorycombo co ON co.categorycomboid = de.categorycomboid





select pet.name,pe.* from period pe
INNER JOIN periodtype pet ON pet.periodtypeid = pe.periodtypeid order by pe.startdate;
where pe.periodid in ( select periodid from datavalue )
order by pe.startdate;


// UPHMIS-Auto-Approve Query
SELECT psi.programstageinstanceid, psi.completeddate::date,psi.status, tedv.value from programstageinstance psi
INNER JOIN trackedentitydatavalue tedv ON tedv.programstageinstanceid = psi.programstageinstanceid
WHERE psi.programstageid in ( 38565722,38565580,38565712,38565696,73397819,73397876,
73397824,73337045,73337059,73337069,73397847,73397870,73397880,73397864,73397815,
73397885,73397828,73397894,73397890,73337065,87350569,87354729 ) AND 
psi.completeddate <= CURRENT_DATE - interval '7 day' AND psi.status = 'COMPLETED' AND
tedv.dataelementid = 38576348
order by psi.completeddate desc;



SELECT psi.programstageinstanceid, psi.completeddate::date,psi.status, tedv.value from programstageinstance psi
INNER JOIN trackedentitydatavalue tedv ON tedv.programstageinstanceid = psi.programstageinstanceid
WHERE psi.programstageid in ( SELECT programstageid from programstage where  programid in ( 73337033 ) ) AND 
psi.completeddate <= CURRENT_DATE - interval '30 day' AND psi.status = 'COMPLETED' AND
tedv.dataelementid = 88199674
order by psi.completeddate desc;



// UPHMIS-Auto-Approve Query Dr Diary

SELECT psi.programstageinstanceid, psi.completeddate from programstageinstance psi  
WHERE psi.programstageid in ( SELECT programstageid from programstage where  programid in ( 73337033 ) ) AND
psi.completeddate <= CURRENT_DATE - interval '30 day' AND psi.status = 'COMPLETED' order by psi.completeddate desc;

select tedv.* from trackedentitydatavalue tedv where tedv.programstageinstanceid in ( SELECT psi.programstageinstanceid from programstageinstance psi  
WHERE psi.programstageid in ( SELECT programstageid from programstage where  programid in ( 73337033 ) ) AND
psi.completeddate <= CURRENT_DATE - interval '30 day' AND psi.status = 'COMPLETED' order by psi.completeddate desc ) and tedv.dataelementid = 88199674



SELECT psi.programstageinstanceid, psi.completeddate::date,psi.status, tedv.value from programstageinstance psi
INNER JOIN trackedentitydatavalue tedv ON tedv.programstageinstanceid = psi.programstageinstanceid
WHERE psi.programstageid in ( SELECT programstageid from programstage where  programid in ( 38565572,38565588,38565704 ) ) AND 
psi.completeddate <= CURRENT_DATE - interval '7 day' AND psi.status = 'COMPLETED' AND
tedv.dataelementid = 38576348
order by psi.completeddate desc;


// source tree password reset link

https://community.atlassian.com/t5/Sourcetree-questions/How-to-update-HTTP-S-credentials-in-sourcetree/qaq-p/297564

// UID generation function

CREATE OR REPLACE FUNCTION uid()
RETURNS text AS $$
  SELECT substring('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ' 
    FROM (random()*51)::int +1 for 1) || 
    array_to_string(ARRAY(SELECT substring('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789' 
       FROM (random()*61)::int + 1 FOR 1) 
   FROM generate_series(1,10)), '') ;
$$ LANGUAGE sql;


// maharashtra advance analysis report query

SELECT  dss.datasetid,ds.name, count( dss.sourceid ) from datasetsource dss
INNER JOIN dataset ds ON ds.datasetid = dss.datasetid
where dss.datasetid in ( 72846,72845,72842,72843,72844 )
group by dss.datasetid,ds,name order by dss.datasetid;

SELECT  datasetid,count( sourceid ) from datasetsource
where datasetid in ( 72846,72845,72842,72843,72844 )
group by datasetid;


SELECT dsc.datasetid,ds.name, dsc.periodid, count( dsc.sourceid ) from completedatasetregistration dsc
INNER JOIN dataset ds ON ds.datasetid = dsc.datasetid
where dsc.datasetid in ( 72846,72845,72842,72843,72844 )
GROUP BY dsc.datasetid, ds.name, dsc.periodid order by dsc.datasetid;

SELECT datasetid,periodid, count( sourceid ) from completedatasetregistration
where datasetid in ( 72846,72845,72842,72843,72844 )
GROUP BY datasetid, periodid;

SELECT datasetid,periodid, attributeoptioncomboid,count( sourceid ) from completedatasetregistration
where datasetid in ( 72846,72845,72842,72843,72844 ) and periodid in ( 2241,95689,40582909,38135545 )
GROUP BY datasetid, periodid, attributeoptioncomboid;

//UPHMIS-III new tracker-report Dr.Diary

SELECT pi.trackedentityinstanceid, psi.programstageinstanceid,psi.executiondate::date,tedv.value from trackedentitydatavalue tedv
INNER JOIN programstageinstance psi ON psi.programstageinstanceid = tedv.programstageinstanceid
INNER JOIN programinstance pi ON pi.programinstanceid = psi.programinstanceid
where pi.trackedentityinstanceid in ( 88073536,102802294,88073550,88073608,88073589,88073590,102854204,
88073599,88069666,88073602,88069657,88073637,88069663,102859285,88069779,88069705,88070967,88073511,88073581,88070974,100891283,100542318,
102094078,100078041,103913070,103917592) and psi.programstageid = 87350569 and psi.executiondate between '2019-04-01' and '2019-06-01' 
and tedv.dataelementid = 38565556;






// SQLQUERY_TEI_DATA_VALUE_V1 HOnZ038FMkq  // for punjab

select tei.uid tei,ps.uid psuid,min(ps.name) psname,psi.uid ev ,psi.executiondate::date evdate,de.uid deuid,min(de.name) dename,min(tedv.value) devalue,ou.name, pi.enrollmentdate::date enrollDate from programstageinstance psi 
INNER JOIN programinstance pi ON  psi.programinstanceid = pi.programinstanceid 
INNER JOIN trackedentityinstance tei ON  pi.trackedentityinstanceid = tei.trackedentityinstanceid 
INNER JOIN trackedentitydatavalue tedv ON tedv.programstageinstanceid = psi.programstageinstanceid 
INNER JOIN dataelement de ON de.dataelementid = tedv.dataelementid 
INNER JOIN programstage ps ON ps.programstageid = psi.programstageid 
INNER JOIN organisationunit ou ON ou.organisationunitid = psi.organisationunitid 
WHERE psi.programstageid IN (select programstageid from programstage where programid IN 
(select programid from program where uid = '${program}')) and psi.organisationunitid IN 
(select organisationunitid from organisationunit where path like '%${orgunit}%') 
and psi.executiondate between '${startdate}' and '${enddate}' 
group by tei.uid,ps.uid,psi.uid,psi.executiondate,de.uid,ou.name, pi.enrollmentdate order by psi.executiondate;


// TRACKER_REPORTS_TEI_ATTR_V1 tCRklU6jMp7 // for punjab

select tei.uid tei ,min(tea.name) attrname,tea.uid attruid,min(teav.value) attrvalue,ou.name,tei.created,pi.enrollmentdate::date enrolldate from programstageinstance psi 
INNER JOIN programinstance pi ON  psi.programinstanceid = pi.programinstanceid 
INNER JOIN trackedentityinstance tei ON  pi.trackedentityinstanceid = tei.trackedentityinstanceid 
INNER JOIN trackedentityattributevalue teav ON  teav.trackedentityinstanceid = pi.trackedentityinstanceid 
INNER JOIN trackedentityattribute  tea ON teav.trackedentityattributeid = tea.trackedentityattributeid 
INNER JOIN programstage ps ON ps.programstageid = psi.programstageid 
INNER JOIN organisationunit ou ON ou.organisationunitid = psi.organisationunitid 
WHERE psi.programstageid IN (select programstageid from programstage 
where programid IN (select programid from program where uid = '${program}')) and 
psi.organisationunitid IN (select organisationunitid from organisationunit where path like '%${orgunit}%') 
and psi.executiondate between '${startdate}' and '${enddate}' 
group by tei.uid,pi.enrollmentdate,tea.uid,ou.name,tei.created order by pi.enrollmentdate;

// tanzania App

https://github.com/hisptz?utf8=%E2%9C%93&q=distr&type=&language=
https://github.com/hisptz/distribution-point-v2/tree/master
exit
  -- this app master branch is running 

npm install
npm install --save sweetalert
npm run build


"build": "ng build --prod --aot --output-hashing all --named-chunks false --build-optimizer --vendor-chunk  && cd dist && zip -r -D distribution-point.zip .",


// for TV
https://github.com/HISP-Uganda/dhis2-smart-display/tree/smart-displayV2

building process

npm install
npm run build


select sum(vil_max_pop.max::integer) from organisationunit village
inner join (
 select max(trackedentitydatavalue.value), parent.uid vil_uid
 from trackedentitydatavalue
 inner join dataelement using(dataelementid)
 inner join programstageinstance using(programstageinstanceid)
 inner join organisationunit using(organisationunitid)
 inner join organisationunit parent on parent.organisationunitid=organisationunit.parentid
 where dataelement.uid='XJRt4P9JgLQ' and organisationunit.hierarchylevel=6 and date(programstageinstance.executiondate) 
 between '2019-8-1' and '2019-8-31'
 group by parent.uid
) vil_max_pop on vil_max_pop.vil_uid=village.uid
where village.hierarchylevel=5 and village.path ilike '%TANZANIA001%';
